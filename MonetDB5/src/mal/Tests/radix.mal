# Mil compiler Version 1.0)
# Copyright (c) 1993-2002, CWI. All rights reserved.

# Predefined code segment
#The compiler can not guarantee an accurate compilation,
#because MIL unlike MAL is a dynamically typed language.
#A few guidelines to maximize usefullness.
#- make the type of variables explicit, in particular 'nil'
#- upon advice of M2m to remap identifiers, change it in your program directly
#- positional arguments, ie $1,$2,..., can not be compiled in isolation
#
#
#Perhaps someone will develop a complete MIL interpreter
#on top of the MAL kernel in the future
#
##line 688 "/ufs/mk/monet_4-3/src/modules/plain/radix.mx"
#module(radix);
#
	b:= reverse(bbp.getName);
#var b := view_bbp_name.reverse;
#
## create data tables
	aa_a := exist(b,"smaller_key");
barrier	ba_a:= not(aa_a);
#if (not(b.exist("smaller_key")))
	ca_a := uniform(1000000,1000000);
	da_a := reverse(ca_a);
	ea_a := mark(da_a,0@0);
	fa_a := reverse(ea_a);
	ga_a := bbp.setName(fa_a,"smaller_key");
	ha_a := bbp.{setPersistent,isPersistent,setTransient,isTransient,isCached}(ga_a,true);
	ia_a := mmap(ha_a,1);
#  uniform(1000000,1000000).reverse.mark(0@0).reverse.rename("smaller_key").persists(true).mmap(1);
end	ba_a;
	ja_a := exist(b,"smaller_a1");
barrier	ka_a:= not(ja_a);
#if (not(b.exist("smaller_a1")))
	smaller_key:= bbp.bind("smaller_key");
	la_a := mirror(smaller_key);
	ma_a := copy(la_a);
	na_a := bbp.setName(ma_a,"smaller_a1");
	oa_a := bbp.{setPersistent,isPersistent,setTransient,isTransient,isCached}(na_a,true);
	pa_a := mmap(oa_a,1);
#  smaller_key.mirror.copy.rename("smaller_a1").persists(true).mmap(1);  
end	ka_a;
	qa_a := exist(b,"smaller_aY");
barrier	ra_a:= not(qa_a);
#if (not(b.exist("smaller_aY")))
	sa_a := copy(smaller_key);
	ta_a := bbp.setName(sa_a,"smaller_aY");
	ua_a := bbp.{setPersistent,isPersistent,setTransient,isTransient,isCached}(ta_a,true);
	va_a := mmap(ua_a,1);
#  smaller_key.copy.rename("smaller_aY").persists(true).mmap(1);  
#
end	ra_a;
	wa_a := exist(b,"larger_key");
barrier	xa_a:= not(wa_a);
#if (not(b.exist("larger_key")))
	ya_a := bat(void,int,2000000);
	ab_a := insert(ya_a,smaller_key);
	bb_a := insert(ab_a,smaller_key);
	cb_a := bat.setSequenceBase(bb_a,0@0);
	db_a := bbp.setName(cb_a,"larger_key");
	eb_a := bbp.{setPersistent,isPersistent,setTransient,isTransient,isCached}(db_a,true);
	fb_a := mmap(eb_a,1);
#  bat(void,int,2000000).insert(smaller_key).insert(smaller_key).seqbase(0@0).rename("larger_key").persists(true).mmap(1);
end	xa_a;
	gb_a := exist(b,"larger_b1");
barrier	hb_a:= not(gb_a);
#if (not(b.exist("larger_b1")))
	larger_key:= bbp.bind("larger_key");
	ib_a := mirror(larger_key);
	jb_a := copy(ib_a);
	kb_a := bbp.setName(jb_a,"larger_b1");
	lb_a := bbp.{setPersistent,isPersistent,setTransient,isTransient,isCached}(kb_a,true);
	mb_a := mmap(lb_a,1);
#  larger_key.mirror.copy.rename("larger_b1").persists(true).mmap(1);  
end	hb_a;
	nb_a := exist(b,"larger_bZ");
barrier	ob_a:= not(nb_a);
#if (not(b.exist("larger_bZ")))
	pb_a := copy(larger_key);
	qb_a := bbp.setName(pb_a,"larger_bZ");
	rb_a := bbp.{setPersistent,isPersistent,setTransient,isTransient,isCached}(qb_a,true);
	sb_a := mmap(rb_a,1);
#  larger_key.copy.rename("larger_bZ").persists(true).mmap(1);  
#
end	ob_a;
	tb_a := exist(b,"smaller_all");
barrier	ub_a:= not(tb_a);
#if (not(b.exist("smaller_all")))
	vb_a := multiplex.tactics("integer",smaller_key,1);
	wb_a := reverse(vb_a);
	xb_a := multiplex.tactics("int",wb_a);
	yb_a := multiplex.tactics("integer",xb_a,16);
	ac_a := reverse(yb_a);
	bc_a := bbp.setName(ac_a,"smaller_all");
	cc_a := bbp.{setPersistent,isPersistent,setTransient,isTransient,isCached}(bc_a,true);
	dc_a := mmap(cc_a,1);
#   [integer]([int]([integer](smaller_key,1).reverse),16).reverse.rename("smaller_all").persists(true).mmap(1);
end	ub_a;
	ec_a := exist(b,"larger_all");
barrier	fc_a:= not(ec_a);
#if (not(b.exist("larger_all")))
	gc_a := multiplex.tactics("integer",larger_key,1);
	hc_a := reverse(gc_a);
	ic_a := multiplex.tactics("int",hc_a);
	jc_a := multiplex.tactics("integer",ic_a,16);
	kc_a := reverse(jc_a);
	lc_a := bbp.setName(kc_a,"larger_all");
	mc_a := bbp.{setPersistent,isPersistent,setTransient,isTransient,isCached}(lc_a,true);
	nc_a := mmap(mc_a,1);
#   [integer]([int]([integer](larger_key,1).reverse),16).reverse.rename("larger_all").persists(true).mmap(1);
#
## 0) SQL benchmark query
## ======================
##
## SELECT smaller.a1, smaller.aY, larger.b1, larger.bZ
## FROM   smaller, larger
## where  smaller.key = larger.key
#
## 1) cache-conscious-monet-join-strategy, optimized for a 256KB L2 cache of 32 bytes line width
## =============================================================================================
##
## first radix cluster both key columns on H bits (maybe different number of passes and bit settings)
##
## We have a 256KB cache, but want to fit comfortable in 128KB. Given a 8-byte relation width an 8-byte hash table, the 
## chunk size is 128KB/16 = 8192, and since we have a 1M inner relation this leads to 7 bits clustering, wich we do in 2 
## passes (4+3) to fit the 64-entry TLB
##
end	fc_a;
	cluster_larger := radix_cluster(larger_key,4,3);
#cluster_larger := radix_cluster(larger_key, 4, 3);
##250
	cluster_smaller := radix_cluster(smaller_key,4,3);
#cluster_smaller := radix_cluster(smaller_key, 4, 3);
##626
#
## phash, followed by radix-sort
##
## As we have 2M tuples with max value 2000000, we need to cluster on 21 bits (7+7+7) in order to achieve radix-sort.
##
	oc_a := reverse(cluster_smaller);
	pc_a := phash_join(cluster_larger,oc_a,7,2,false);
	qc_a := reverse(pc_a);
	rc_a := radix_cluster(qc_a,7,7,7);
	res_join := reverse(rc_a);
#res_join := phash_join(cluster_larger, cluster_smaller.reverse, 7, 2, false).reverse.radix_cluster(7,7,7).reverse;
##2.7
	sc_a := mark(res_join,0@0);
	res_larger_sorted := reverse(sc_a);
#res_larger_sorted := res_join.mark(0@0).reverse; 
#
## no longer needed
	cluster_larger := 0;
#cluster_larger := 0;
	cluster_smaller := 0;
#cluster_smaller := 0;
#
## positional-join projected columns from larger table into result
	larger_b1:= bbp.bind("larger_b1");
	res_b1 := join(res_larger_sorted,larger_b1);
#res_b1 := join(res_larger_sorted, larger_b1);
##570
	larger_bZ:= bbp.bind("larger_bZ");
	res_bZ := join(res_larger_sorted,larger_bZ);
#res_bZ := join(res_larger_sorted, larger_bZ);
##570
#
## no longer needed
	res_larger_sorted := 0;
#res_larger_sorted := 0;
#
## Given a 128KB of 'comfortable' L2, and 4-byte tuples in smaller_aX, we want chunk sizes of 32768. As we have a 
## cardinality of 2M, we create 64 chunks by partial radix-cluster on 6 bits. The maximum value is 1M, hence there 
## are 20 significant bits, so we ignore the lower 20-6=14 bits.
##
	tc_a := reverse(res_join);
	uc_a := mark(tc_a,0@0);
	vc_a := reverse(uc_a);
	res_smaller_clustered := radix_cluster(vc_a,-14,6);
#res_smaller_clustered := res_join.reverse.mark(0@0).reverse.radix_cluster(-14,6); 
##589
##344
#
## no longer needed
	res_join := 0;
#res_join := 0;
#
## positional-join and decluster projected columns from smaller table into result
##
## The window size of the matching window is again the comfortable 128KB, with 4 byte wide tuples its tuple size is 
## 32768. As we have 64 clusters, we can use a multiplier of 512. With 64 cluster, TLB trouble is avoided as well. 
##
	borders_smaller := radix_count(res_smaller_clustered,14,6);
#borders_smaller := res_smaller_clustered.radix_count(14, 6);
	smaller_a1:= bbp.bind("smaller_a1");
	wc_a := join(res_smaller_clustered,smaller_a1);
	res_a1 := radix_decluster(wc_a,borders_smaller,512);
#res_a1 := join(res_smaller_clustered, smaller_a1).radix_decluster(borders_smaller, 512);
	smaller_aY:= bbp.bind("smaller_aY");
	xc_a := join(res_smaller_clustered,smaller_aY);
	res_aY := radix_decluster(xc_a,borders_smaller,512);
#res_aY := join(res_smaller_clustered, smaller_aY).radix_decluster(borders_smaller, 512);
#
## no longer needed
	res_smaller_clustered := 0;
#res_smaller_clustered := 0;
#
	yc_a := slice(res_b1,1000000,1000100);
	ad_a := bbp.setColumn(yc_a,"b1");
	bd_a := bbp.setColumn(res_bZ,"bZ");
	cd_a := bbp.setColumn(res_a1,"a1");
	dd_a := bbp.setColumn(res_aY,"aY");
	ed_a := print(ad_a,bd_a,cd_a,dd_a);
#print(res_b1.slice(1000000,1000100).col_name("b1"), res_bZ.col_name("bZ"), res_a1.col_name("a1"), res_aY.col_name("aY"));
	fd_a := count(res_b1);
	gd_a := print(fd_a);
#print(res_b1.count);
#
## no longer needed
	res_a1 := 0;
#res_a1 := 0;
	res_aY := 0;
#res_aY := 0;
	res_b1 := 0;
#res_b1 := 0;
	res_bZ := 0;
#res_bZ := 0;
#
## 2) cache-conscious-relational-join-strategy 
## ===========================================
#
	smaller_all:= bbp.bind("smaller_all");
	hd_a := reverse(smaller_all);
	id_a := multiplex.tactics("integer",hd_a,2);
	smaller_view := reverse(id_a);
#smaller_view := [integer](smaller_all.reverse, 2).reverse;
	larger_all:= bbp.bind("larger_all");
	jd_a := reverse(larger_all);
	kd_a := multiplex.tactics("integer",jd_a,2);
	larger_view := reverse(kd_a);
#larger_view := [integer](larger_all.reverse, 2).reverse;
#
## the inner relation will be 12+8 = 24 bytes wide, we have 128KB of cache hence can have chunk sizes of 5000.
## given an inner relation size of 1M tuples, this leads to  256 clusters of 4096, hence 8 bytes.
	cluster_smaller := radix_cluster(smaller_view,4,4);
#cluster_smaller := radix_cluster(smaller_view, 4, 4);
	cluster_larger := radix_cluster(larger_view,4,4);
#cluster_larger := radix_cluster(larger_view, 4, 4);
	ld_a := reverse(cluster_smaller);
	res_join := phash_join(cluster_larger,ld_a,8,2,false);
#res_join := phash_join(cluster_larger, cluster_smaller.reverse, 8, 2, false);
#
## no longer needed
	cluster_smaller := 0;
#cluster_smaller := 0;
	cluster_larger := 0;
#cluster_larger := 0;
# 
	md_a := slice(res_join,1000000,1000100);
	nd_a := print(md_a);
#print(res_join.slice(1000000,1000100));
	od_a := count(res_join);
	pd_a := print(od_a);
#res_join.count.print;
#
## alternatively, we try without clustering
	qd_a := reverse(smaller_view);
	res_join := phash_join(larger_view,qd_a,0,2,false);
#res_join := phash_join(larger_view, smaller_view.reverse, 0, 2, false);
#
	rd_a := slice(res_join,1000000,1000100);
	sd_a := print(rd_a);
#print(res_join.slice(1000000,1000100));
	td_a := count(res_join);
	ud_a := print(td_a);
#res_join.count.print;
#
	vd_a := reverse(larger_all);
	wd_a := multiplex.tactics("integer",vd_a,2);
	xd_a := reverse(wd_a);
	larger_view := copy(xd_a);
#larger_view := [integer](larger_all.reverse, 2).reverse.copy;
	yd_a := reverse(smaller_all);
	ae_a := multiplex.tactics("integer",yd_a,2);
	smaller_view := reverse(ae_a);
#smaller_view := [integer](smaller_all.reverse, 2).reverse;
	be_a := reverse(smaller_view);
	res_join := phash_join(larger_view,be_a,0,2,false);
#res_join := phash_join(larger_view, smaller_view.reverse, 0, 2, false);
#
	ce_a := slice(res_join,1000000,1000100);
	de_a := print(ce_a);
#print(res_join.slice(1000000,1000100));
	ee_a := count(res_join);
	fe_a := print(ee_a);
#res_join.count.print;
#
#
##quick test
##==========
#
	ge_a := uniform(2000000,999999);
	res_join := multiplex.tactics("oid",ge_a);
#res_join := uniform(2000000,999999).[oid];
	he_a := reverse(res_join);
	ie_a := mark(he_a,0@0);
	je_a := reverse(ie_a);
	res_smaller_clustered := radix_cluster(je_a,-12,8);
#res_smaller_clustered := res_join.reverse.mark(0@0).reverse.radix_cluster(-12,8);
	borders_smaller := radix_count(res_smaller_clustered,12,8);
#borders_smaller := res_smaller_clustered.radix_count(12, 8);
#
	ke_a := reverse(res_join);
	le_a := mark(ke_a,0@0);
	res_smaller := reverse(le_a);
#res_smaller := res_join.reverse.mark(0@0).reverse;
	t := alarm.time();
	res_a1 := join(res_smaller,smaller_a1);
	me_a := alarm.time();
	ne_a := -(me_a,t);
	oe_a := print(ne_a);
#t := time; res_a1 := join(res_smaller, smaller_a1); print(time - t);
#
	pe_a := reverse(res_smaller_clustered);
	qe_a := mark(pe_a,0@0);
	cl_old := reverse(qe_a);
#cl_old := res_smaller_clustered.reverse.mark(0@0).reverse; 
	re_a := mark(res_smaller_clustered,0@0);
	cl_new := reverse(re_a);
#cl_new := res_smaller_clustered.mark(0@0).reverse; 
#
	t := alarm.time();
	cl_tmp := join(cl_old,smaller_a1);
	se_a := alarm.time();
	te_a := -(se_a,t);
	ue_a := print(te_a);
#t := time; cl_tmp := join(cl_old,  smaller_a1); print(time - t);
	t := alarm.time();
	res_a1 := radix_decluster2(cl_new,cl_old,borders_smaller,32);
	ve_a := alarm.time();
	we_a := -(ve_a,t);
	xe_a := print(we_a);
#t := time; res_a1 := radix_decluster2(cl_new, cl_old, borders_smaller, 32);print(time - t);
#
	t := alarm.time();
	b := join(res_smaller_clustered,smaller_a1);
	ye_a := alarm.time();
	af_a := -(ye_a,t);
	bf_a := print(af_a);
#t := time; b := join(res_smaller_clustered,  smaller_a1); print(time - t);
	t := alarm.time();
	res_a1 := radix_decluster(b,borders_smaller,16);
	cf_a := alarm.time();
	df_a := -(cf_a,t);
	ef_a := print(df_a);
#t := time; res_a1 := radix_decluster(b, borders_smaller, 16);print(time - t);
#
#
#Identifer 'col_name' mapped to 'bbp.setColumn'
#Identifer 'rename' mapped to 'bbp.setName'
#Identifer 'persists' mapped to 'bbp.{setPersistent,isPersistent,setTransient,isTransient,isCached}'
#Identifer 'view_bbp_name' mapped to 'bbp.getName'
#Identifer 'seqbase' mapped to 'bat.setSequenceBase'
#Identifer 'time' mapped to 'alarm.time()'
