@f mal_optimizer
@a M. Kersten
@* Introduction
One of the prime reasons to design the MAL intermediate language is to have
a high-level description for database queries, which is easy to generate by
a front-end compiler and easy to decode, optimize and interpret.

An optimizer needs several mechanisms to be effective. It should be able to
perform a symbolic evaluation of a code fragment and collect the result in
properties for further decision making. The prototypical case is where an 
optimizer estimates the result size of a selection.

Another major issue is to be able to generate and explore a space of 
alternative evaluation plans. This exploration may take place up front, 
but can also be ran at runtime for query fragments.

@+ What optimizers should be considered?
A query optimizer is often a large and complex piece of code, which
enumerates alternative evaluation plans from which 'the best' plan
is selected for evaluation. Limited progress has been made sofar to
decompose the optimizer into (orthogonal) components, because it is 
a common believe in research that a holistic view on the problem is 
a prerequisite to find the best plan. 
Conversely, commercial optimizers use a cost-model driven approach, which
explores part of the space using a limited (up to 300) rewriting rules.

Our hypothesis is that query optimization should be realized with
a collection of query optimizer transformers (QOT),
each targeted at a specific task.
Furthermore, they are assembled in scenarios to support specific application
domains or achieve a desired behavior. Such scenarios are selected on a
session bases, a query basis, or dynamically at
runtime; they are part of the query plan.

The query transformer list below is under consideration for development.
For each we consider its goal, approach, and expected impact.
Moreover, the minimal prerequisites identify the essential optimizers that 
should have done their work already. For example, it doesn;t make sense
to perform a static evaluation unless you have already propagated the
constants using Alias Removal.

@- Scalar expressions (SXoptimizer)
Goal: to remove scalar expressions which need be evaluated once during the
query lifetime.
Rationale: static expressions appear 
when variables used denote literal constants (e.g. 1+1),
when catalog information can be merged with the plan (e.g. max(B.salary)), 
when session variables are used which are initialized once (e.g. user()).
Early evaluation aids subsequent optimization.
Approach: inspect all instructions to locate static expressions. 
Whether they should be removed depends on the expected re-use,
which in most cases call for an explicit request upon query registration 
to do so. The result of a static evaluation provides a ground for AR.
Impact: relevant for stored queries (MAL functions)
Prereq: AR, CX

@- Alias Removal (ARoptimizer)
Goal: to reduce the number of  variables referenceing the same value,
thereby reducing the analysis complexity.
Rationale: query transformations often result in replacing
the right-hand side expression with a result variable. This pollutes the
code block with simple assignments e.g. V:=T. Within the descendant flow the
occurrence of V could be replaced by T, provided V is never assigned a new
value.
Approach: literal constants within a MAL block are already recognized and
replaced by a single variable. 
Impact: medium


@- Common Expression Optimizer (CXoptimizer)
Goal: to reduce the amount of work by avoiding calculation of the same
operation twice.
Rationale: to simplify code generation for front-ends, they do not have
to remember the subexpressions already evaluated. It is much easier to 
detect at the MAL level.
Approach: simply walk through the instruction sequence and locate identical
patterns.  (Enhance is with semantic equivalent instructions)
Impact: High
Prereq: AR

@- Dead Code Removal (DCoptimizer)
Goal: to remove all instructions whose result is not used
Rationale: due to sloppy coding or alternative execution paths
dead code may appear. Als XML Pathfinder is expected to produce
a large number of simple assignments.
Approach: Every instruction should produce a value used somewhere else.
Impact: low

@- Idempotent Removal (RRoptimizer)
Goal: combinations of reversals kan be removed
Rationale: reversal pairs may occur due to the processing scheme of a front-end
or as a side-effect from other optimization steps. Such reversal pairs should
be removed as quickly as possible, so as to reduce the complexity of finding
alternative optimization opportunities.
Another form of idempotency is performing selections/semijoins
that are bound to produce the operand. 
Approach: simple find the reverse combos.
Impact: low (peephole optimizer)

@- Selection Push Down (SPoptimizer)
Goal: to reduce the volume as quick as possible.
Rationale: most queries are focussed on a small part of the database.
To avoid carrying too many intermediates, the selection should be performed as
early as possible in the process. This assumes that selectivity factors are
known upfront, which in turn depends on histogram of the value distribution.
Approach: locate selections and push them back/forth through the flow graph.
Impact: high

@- Join Path Optimizer (JPOoptimizer)
Goal: to reduce the volume produced by a join sequence
Rationale: join paths are potentially expensive operations. Ideally the join
path is evaluated starting at the smallest component, so as to reduce the
size of the intermediate results.
Approach: to successfully reduce the volume we need to estimate their processing
cost. This calls for statistics over the value distribution, in particular,
correlation histograms. If statistics are not available upfront, we have to 
restore to an incremental algorithm, which decides on the steps using the
size of the relations.
Impact: high

@- Operator Sort (OSoptimizer)
Goal: to sort the dataflow graph in such a way as to reduce the
cost, or to assure locality of access for operands.
Rationale: A simple optimizer is to order the instructions for
execution by permutation of the query components 
Approach:
Impact:

@- Result Cacher (RCoptimizer)
Goal: to reduce the processing cost by keeping track of expensive to
compute intermediate results
Rationale: 
Approach: result caching becomes active after an instruction has been 
evaluated. The result can be cached as long as its underlying operands
remain unchanged. Result caching can be made transparent to the user, but
affects the other QOTs
Impact: high

@- Vector Execution (VEoptimizer)
Goal: to rewrite a query to use a cache-optimal vector implementation
Rationale: processing in the cache is by far the best you can get.
However, the operands may far exceed the cache size and should be broken
into pieces followed by a staged execution of the fragments involved.
Approach: replace the query plan with fragment streamers
Impact:

@- Staged Execution (SEoptimizer)
Goal: to split a query plan into a number of steps, such that the first
response set is delivered as quickly as possible. The remainder is only
produced upon request.
Rationale: interactive queries call for quick response and an indication
of the processing time involved to run it too completion. 
Approach: staged execution can be realized using a fragmentation scheme
over the database, e.g. each table is replaced by a union of fragments.
This fragmentation could be determined upfront by the user or is derived
from the query and database statistics.
impact: high

@- Code Parallizer (CPoptimizer)
Goal: to exploit parallel IO and cpu processing in both SMP and MPP settings.
Rationale: throwing more resources to solve a complex query helps, provided
it is easy to determine that parallel processing recovers the administrative
overhead
Approach: every flow path segment can be handled by an independent process thread.
Impact: high

@- Query Evaluation Maps (QEMoptimizer)
Goal: to avoid touching any tuple that is not relevant for answering a query.
Rationale: the majority of work in solving a query is to disgard tuples of
no interest and to find correlated tuples through join conditions. Ideally,
the database learns these properties over time and re-organizes (or builts
a map) to replace disgarding by map lookup.
Approach: piggyback selection and joins as database fragmentation instructions
Impact: high

@- Expression Compiler (ECoptimizer) (tactics)
Goal: to avoid interpretation of functional expressions
Rationale: interpretation of arithmetic expressions with an interpreter
is always expensive. Replacing a complex arithmetic expressin with a
simple dynamically compiled C-functions often pays off. Especially for
cached (MAL) queries
Approach:
Impact: high

@- Dynamic Query Scheduler (DQSoptimizer) (tactics)
Goal: to organize the work in a way so as to optimize resource usage
Rationale: straight interpretation of a query plan may not lead to the best
use of the underlying resources. For example, the content of the runtime
cache may provide an opportunity to safe time by accessing a cached source
Approach: query scheduling is the last step before a relation algebra interpreter
takes over control. The scheduling step involves a re-ordering of the 
instructions within the boundaries imposed by the flow graph.
impact: medium

@- Aggregate Groups (AGoptimizer)
Goal: to reduce the cost of computing aggregate expressions over times
Rationale: many of our applications call for calculation of aggregates
over dynamically defined groupings. They call for lengtly scans and it pays
to piggyback all aggregate calculates, leaving their result in the cache for
later consumption (eg the optimizers)
Approach:
Impact: High

@- Data Cube optimizer (DCoptimizer)
Goal: to recognize data cube operations
Rationale: 
Approach:
Impact:

@- Operator Cost Reduction (OCRoptimizer)
Goal: to locate sequences of operators and to replace them with cheaper ones.
Rationale: based on the actual state of the computation and the richness of
the supporting libraries there may exists alternative routes to solve a query.
Approach: Operator rewriting depends on properties. No general technique.
Impact: high

@- Demand Driven Interpreter (DDoptimizer) (tactics)
Goal: to use the best interpreter and libraries geared at the task at hand
Rationale: Interpretation of a query plan can be based on different
computational models. A demand driven interpretation starts at the intended 
output and 'walks' backward through the flow graph to collect the pieces,
possibly in a pipelined fashion. (Vulcano model)
Approach: merely calls for a different implementation of the core operators
Impact: high

@- Iterator Strength Reduction (ISRoptimizer)
Goal: to reduce the cost of iterator execution by moving instructions
out of the loop.
Rationale: although iteration at the MAL level should be avoided due to
the inherent low performance compared to built-in operators, it is not
forbidden. In that case we should confine the iterator block to the minimal
work needed.
Approach: inspect the flowgraph for each iterator and move instructions around.
Impact: low

@- Code Inliner (CIoptimizer)
Goal: to reduce the calling depth of the interpreter and to obtain
a better starting point for code squeezing
Rationale: substitution of code blocks (or macro expansion) leads to
longer linear code sequences. This provides opportunities for squeezing.
Moreover, at runtime building and managing a stackframe is rather expensive.
This should be avoided for functions called repeatedly.
Approach: use a property attached to functions or automatic for small ones.
Impact: medium


@- Garbage Collector (GCoptimizer)
Goal: to release resources as quickly as possible
Rationale: BATs referenced from a MAL program keep resources locked.
Approach: In cooperation with a resource scheduler we should identify those
that can be released quickly.
Impact: large

@- Foreign Key replacements (FKoptimizer)
Goal: to improve multi-attribute joins over foreign key constraints
Rationale: the code produced by the SQL frontend involves foreign key 
constraints, which provides many opportunities for speedy code.
Impact: large

@+ What is the dependency between optimizers?
The optimizers are highly targeted to a particular problem.
Aside from the resources available to invest in plan optimization,
optimizers are partly dependent and may interfere.

To aid selection of the components of interest, we have grouped
them in a preferred order of deployment.
@T
\begin{verbatim}

Group A:
	Code Inliner (CIoptimizer)
	Static expression evaluator. (SXoptimizer)
	Strength Reduction (SRoptimizer)

Group B:
	Common Expression Optimizer (CXoptimizer)
	Query Evaluation Maps (QMoptimizer)

Group C:
	Selection Push Down (SPoptimizer)
	Join Path Optimizer (JPoptimizer)
	Operator Cost Reduction (OCoptimizer)
	Operator Sort (OSoptimizer)
	Foreign Key handling (FKoptimizer)
	Aggregate Groups (AGoptimizer)
	Data Cube optimizer (DCoptimizer)

group D:
	Code Parallizer (CPoptimizer)
	Result Cacher (RCoptimizer)

group E:
	Expression Compiler (ECoptimizer)
	Dynamic Query Scheduler (QSoptimizer)
	Vector Execution (VEoptimizer)
	Staged Execution (SEoptimizer)

group F:
	Alias Removal (ARoptimizer)
	Dead Code Removal (DCoptimizer)
	Garbage Collector (GCoptimizer)

\end{verbatim}
@-
Alias removal can be applied after each other optimization step.
@+ Optimizer building blocks
@- Lifespan analysis
The variables have a lifespan in the code blocks, denoted by properties
beginLifespan,endLifespan. The beginLifespan denotes the intruction where
it receives its first value, the endLifespan the last instruction in which 
it was used as operand or target.

In many cases, we have to determine if the lifespan interferes with 
a optimization decision being prepared.

@- Flow analysis
In many optimization rules, the data flow dependency between statements is
of crucial importance. The MAL language provides a multi-source, multi-sink
dataflow network. Optimizers typically extract part of the workflow and use
the language properties to enumerate semantic equivalent solutions, which
under a given cost model turns out to result in better performance.

@- Common subexpression optimalization 
A special case of flow analysis is to remove common sub-expressions.
A recurring situation is to find operator calls which depend on the same
argments, and whose arguments have not been changed. For example
@T
\begin{verbatim}
t0 := select(A,0,100);
t2 := select(A,0,100);
\end{verbatim}
@
Evidently, T2 is an alias for t0 unless inbetween the two statements A was
updated. A program block can be analysed for such recurring situations,
provided it knows the side-effects of operators.

@- Static evaluation
Some instructions are independent of the execution context. In particular,
expressions over side-effect free functions with constant parameters could
be evaluated before the program block is considered further.

@- Pattern replacement
A major task for an optimizer is to select instruction (sequences) which
can and should be replaced with cheaper ones. The cost model underlying
this decision depends on the processing stage and the overall object.
For example, based on a symbolic analysis their may exist better 
implementations within the interpreter to perform the job (e.g. hashjoin vs
mergejoin). Alternative, expensive intermediates may be cached for later use.

@- Plan enumeration

@+ Optimizer hooks
The MAL language does not imply a specific optimizer to be used. Its programs
are merely a sequence of specifications, which is interpreted by an engine
specific to a given task. Activation of the engine is controlled by a 
scenario, which currently includes two hooks for optimization; a 
strategic optimizer and a tactical optimizer.

Both engines take a MAL program and produce a (new/modified) MAL program for 
execution by the lower layers. 

MAL programs end-up in the symbol table linked to a user session.
Optimizers have the freedom to change the code, provided it is known that
the plan derived is invariant to changes in the environment.
All others lead to alternative plans, which should be collected as a trail of
MAL program blocks. These trails can be inspected for a
posteriori analysis, at least in terms of some statistics on the properties
of the MAL program structures automatically.
Alternatively, the trail may be pruned and re-optimized when appropriate
from changes in the environment.

The optimizers can leave property values to assess their deployment and
possible choices.

@+ Optimizer structure
The best way to analyse a code block depends on the optimizer involved.
Some, e.g. Alias Removal, pushes the alias towards the end, while, e.g.
Common Expression, looks backwards for instructions 'already executed'.
The third category encompasses optimizer steps that are triggered by
individual operators, looking both ways. Can we bring all this under
one umbrella? or is it essential.

@+ Optimizer properties
Optimizers mostly analyse the structure of the MAL program, before it is
taken into execution. During this process, it will built and maintain 
a property list to pass information around between (independent) 
optimizer components.

Properties are stored kept with the variables, but for explanatory
and analysis purposes we also need to maintain the property transitions
with the statements.

@+ Optimizer focus
The first implementation of this optimizer is geared at a SQL front-end.
This involves ca 65 different operators, divided into the
catalog management (23) and query processing (42)
@h
/*
 * The contents of this file are subject to the Monet Public
 * License Version 1.1 (the "License"); you may not use this file
 * except in compliance with the License. You may obtain a copy of
 * the License at 
 * http://www.monetsolutions.com/Download/Licensing/MonetPL-1.1.html
 * 
 * Software distributed under the License is distributed on an "AS
 * IS" basis, WITHOUT WARRANTY OF ANY KIND, either express or
 * implied. See the License for the specific language governing
 * rights and limitations under the License.
 * 
 * The Original Code is the Monet Database System.
 * 
 * The Initial Developer of the Original Code is CWI.
 * Portions created by CWI are Copyright (C) 1997-2003 CWI.  
 * All Rights Reserved.
 * 
 * Contributor(s): Martin Kersten <Martin.Kersten@cwi.nl>
 */

#include "mal.h"
#include "mal_function.h"
#include "mal_client.h"
#include "mal_scenario.h"

#define DEBUG_MAL_OPTIMIZER 	/* show result */

#define isAlife(M,I,X)          ( (M)->var[I]->beginLifespan<=X && \
                                  (M)->var[I]->endLifespan>=X)
#define isSinglepoint(M,I)	( (M)->var[I]->beginLifespan== \
				  (M)->var[I]->endLifespan)

mal_export void debugOptimizers();
mal_export str CXoptimizer(Client cntxt,MalBlkPtr mb, int pc);
mal_export str ARoptimizer(Client cntxt,MalBlkPtr mb, int pc);
mal_export str DCoptimizer(Client cntxt,MalBlkPtr mb, int pc);
mal_export str SPoptimizer(Client cntxt,MalBlkPtr mb, int pc);
mal_export str RRoptimizer(Client cntxt,MalBlkPtr mb, int pc);
mal_export str MALoptimizer(Client c);

mal_export void setLifespan(MalBlkPtr mb);
@+ Optimizer scenario
The large number of query transformers calls for a flexible scheme for
the deploy them. The approach taken is to make all optimizers visible
at the language level as a MAL pattern. Then (semantic) optimizer merely
inspects a MAL block for their occurrences and activitates it.

Furthermore, the default optimizer scheme can be associated with
a client record. The strategic optimizer merely prepends each query with 
this scheme before it searches/activates the optimizer routines.

The optimizer routines have access to the client context, the MAL block,
and the program counter where it should start optimizing. Each query
transformer should remove itself from the MAL block;

The optimizer terminates when no optimizer transformer call remains.
[Some of the optimizers above should be moved to the tactic level]

Note all optimizer instructions are executed only once. This means that the
instruction can be removed from further consideration. However, in the case
that a designated function is selected for optimization (e.g. 
CXoptimizer(Admin,qry)) the pc is assumed 0. The first instruction always
denotes the signature and can not be removed.

@+ Rescheduling optimizers
@c
#include "mal_optimizer.h"
#include "mal_interpreter.h"	/* for showErrors() */

int isInvariant(MalBlkPtr mb, int pcf, int pcl, int varid);
int hasSideEffects(InstrPtr p);

void debugOptimizers(Client c, MalBlkPtr mb, int pc){
	c->debugoptimizer= c->debugoptimizer?0:1;
	if(pc) removeInstruction(mb,pc);
}

str MALoptimizer(Client c)
{	MalBlkPtr mb= c->curprg->def;
	InstrPtr p;
	int pc,qot=0, oldstop;
	str msg= NULL;

	if( c->state[OPTIMIZE]){
		/* prepend query with client specific optimizer scheme */
		/* unless overruled within the block itself */
		qot=0;
		for(pc=0, qot=0; pc< mb->stop; pc++){
			p= getInstrPtr(mb,pc);
			if( moduleId(p) && idcmp(moduleName(p),"optimizer")==0)
				qot++;
		}
		if( qot==0){
			/* preprend scheme */
		}
	} 
	setLifespan(mb);
	oldstop= mb->stop;
	do{
		qot=0;
		for(pc=0; pc< mb->stop; pc++){
			p= getInstrPtr(mb,pc);
			if( moduleId(p) && idcmp(moduleName(p),"optimizer")==0){
				qot++;
				if( p->fcn)
					msg= (str) (*p->fcn)(mb,0,p);
				if( msg) {
					showErrors(c);
					return msg;
				}
				pc--; /* optimizer statement has been removed*/
			}
		}
	} while(qot);
#ifdef DEBUG_MAL_OPTIMIZER
	if( c->debugoptimizer && oldstop!=mb->stop){
	stream_printf(GDKout,"Optimizer effect %d -> %d instructions\n",
		oldstop,mb->stop);
	}
#endif
	return 0;
}
@+ Lifespan analysis
The lifespan is calculated once at the beginning of the optimizer sequence.
It should either be maintained to reflect the most accurate situation while
optimizing the code base. In particular it means that any move/remove/addition
of an instruction calls for either a recalculation or delta propagation.
Unclear what will be the best strategy. For the time being we just recalc.
@c
void debugLifespan(MalBlkPtr mb){
	int i;
	for(i=0; i<mb->vtop; i++){
		VarPtr v= getVar(mb,i);
		if( isTmpVar(mb,i))
		printf("%c%d %d - %d\n", TMPMARKER, v->tmpindex,
				v->beginLifespan, v->endLifespan);
		else
		printf("%s %d - %d\n", v->name, 
				v->beginLifespan, v->endLifespan);
	}
}
void setLifespan(MalBlkPtr mb){
	int pc,k;
	InstrPtr p;

	for(k=0;k<mb->vtop;k++){
		VarPtr v= getVar(mb, k);
		v->beginLifespan = v->endLifespan=0;
	}
	for(pc=0;pc<mb->stop; pc++){
		p= getInstrPtr(mb,pc);
		for(k=0;k<p->argc; k++){
			VarPtr v= getVar(mb, p->argv[k]);
			if( v->beginLifespan==0) v->beginLifespan= pc;
			v->endLifespan = pc;
		}
	}
	/* debugLifespan(mb); */
}
@-
In many cases we should be assured that a variable is not used in
the instruction range identified. For, we may exchange some instructions that
might change its content.
@c
int isTouched(MalBlkPtr mb, int varid, int p1, int p2){
	int i,k;
	for(i=p1;i<p2;i++) {
		InstrPtr p= getInstrPtr(mb,i);
		for(k=0; k<p->argc; k++)
		if( p->argv[k]== varid) return TRUE;
	}
	return FALSE;
}
@+ Flow analysis
The flow graph plays a crucial role in many optimization steps.
It is unclear as yet what primitives and what storage structure is
most adequate. For the time being introduce the operations needed and
evaluate them directly against the program

The routine flowStep(pca,pcb) checks whether the output of instruction
pca flows directly into pcb, without its parameters being changed inbetween.
This calls for checking assignments as well as operators that use any of
the targets of pca, but which also change them (e.g. insert/delete bat)
TODO, now more restrictive then needed.
@c
int flowStep(MalBlkPtr mb, int pca, int pcb){
	InstrPtr pa,pb;
	int i,k,l;

	if( pca >pcb) return FALSE;
	if( pca+1 == pcb) return TRUE;

	pa= getInstrPtr(mb,pca);
	for(i= pca+1; i<pcb;i++){
		pb= getInstrPtr(mb,i);
		for(k=0;k<pa->retc;k++)
		for(l=0;l<pb->retc;l++)
		if( pa->argv[k] == pb->argv[l]) return FALSE;

		/* also be aware of operators with side effects */
		for(k=0;k<pa->retc;k++)
		for(l=pb->retc;l<pb->argc ;l++)
		if( pa->argv[k] == pb->argv[l] ) return FALSE;
	}
	return TRUE;
}

@+ Alias Removal
The alias removal walks through the program looking for simple
assignment statements, e.g. V:=W. It will replace all subsequent
occurrences of W by V and condense the instruction block.

Such replacements is only started when V is assigned a value only once,
while V and W are only read in the remainder of the code.

Since the iterators may cause a jump backwards, we have to maintain
its block structure and check for it. Instead, we merely check for possible
occurences of the variable within an iterator block.

During this process, we should be aware that parameters could be
changed as part of a call. They are marked as unsafe.
@c
int ARnxtAssignment(MalBlkPtr mb, int pc, int varid)
{	int i,k, blkcount=0;
	InstrPtr p,q;
	p= getInstrPtr(mb,pc);
	for(i=pc+1; i< mb->stop && isAlife(mb,varid,i); i++){
		q= getInstrPtr(mb,i);
		for(k=0; k < q->retc; k++)
		if( q->argv[k]== varid) {
			return i;
		}
		for(;k < q->argc; k++)
		if( q->argv[k]== varid && ! isInvariant(mb,pc,i,varid)) 
			return i;
		if( blockStart(p)) blkcount++;
		if( blockExit(p)) blkcount--;
		if( blkcount<0) return pc; /* it is part of a block */
	}
	return mb->stop;
}
void ARreplaceAlias(MalBlkPtr mb, int pc, int pcl, int src, int alias)
{	InstrPtr p;
	int k;
	for(; pc<pcl; pc++) {
		p= getInstrPtr(mb,pc);
		for(k= p->retc; k<p->argc; k++)
		if( p->argv[k]== src ) p->argv[k]= alias;
	}
}
int ARoptimizerStep(Client cntxt, MalBlkPtr mb, int pc)
{ 	int k,kn=0;
	InstrPtr p;
	p= getInstrPtr(mb,pc);
	if( moduleId(p) || functionId(p)) return pc;
	if( p->token != ASSIGNsymbol) return pc;
	if( blockStart(p) || blockExit(p) || blockCntrl(p)) return pc;

	for(k=0;k<p->retc; k++){
	   int m;
	   m= ARnxtAssignment(mb,pc,p->argv[k]);
	   if( m!=pc ){
		ARreplaceAlias(mb,pc+1,m,p->argv[k], p->argv[p->retc+k]);
		kn++;
#ifdef DEBUG_MAL_OPTIMIZER
		if( cntxt->debugoptimizer){
		stream_printf(GDKout,"Delete alias assignment\n");
		printInstruction(GDKout,mb,p,LIST_MAL_ALL);
		}
#endif
	   }
	}
	/* delete the instruction if all target have been replaced */
	if(kn == p->retc)
	{
		/* all target variables pushed through */
		if(pc) removeInstruction(mb,pc);
		return pc-1;
	}
	return pc;
}
str ARoptimizer(Client cntxt, MalBlkPtr mb, int pc)
{ 	int i;
	for(i=1;i< mb->stop; i++)
		i= ARoptimizerStep(cntxt,mb,i);
	/* remove the ARoptimizer request */
	if(pc) removeInstruction(mb,pc);
	return NULL;
}

@+ Common subexpression elimination
Common subexpression elimination merely involves a single scan through the 
program block to detect re-curring statements.
A naive implementation is given below, which changes the code block in place.

The key problem to be addressed is to make sure that the parameters involved
in the repeatative instruction are invariant. 

The analysis is rather crude. All functions with possible side-effects on
their arguments are marked as 'unsafe'. Their use within a MAL block breaks 
the dataflow graph for all objects involved (BATs, everything kept in boxes).
Example, `function insert(b:bat{+unsafe}, ...)`
Function whose side-effect may be dissastrous for any variable are marked
as 'corrupt'.
@c

int hasSameSignature(InstrPtr p, InstrPtr q){	
	if( q->retc != p->retc && q->argc != p->argc) return FALSE;
	if( functionId(q)==0 && functionId(p)!=0 ) return FALSE;
	if( functionId(q)!=0 && functionId(p)==0 ) return FALSE;
	if( functionId(q) && functionId(p) && idcmp(functionName(q),functionName(p)) ) 
		return FALSE;
	if( moduleId(q)==0 && moduleId(p)!=0 ) return FALSE;
	if( moduleId(q)!=0 && moduleId(p)==0 ) return FALSE;
	if( moduleId(q) && moduleId(p) && idcmp(moduleName(q),moduleName(p)))
		return FALSE;
	/* actually also check their types */
	return TRUE;
}

int hasSameArguments(InstrPtr p, InstrPtr q)
{	int k;
	for(k=p->retc; k<p->argc;k++)
	if( q->argv[k]!= p->argv[k])
		return FALSE;
	return TRUE;
}

@-
If two instructions have elements in common in their target list,
it means a variable is re-initialized and should not be considered
an alias.
@c
int hasCommonResults(InstrPtr p, InstrPtr q)
{
	int k,l;
	for(k= 0; k<p->retc; k++)
	for(l= 0; l<q->retc; l++)
	if( p->argv[k]== q->argv[l]) return TRUE;
	return FALSE;
}
@-
For each function it should be relatively easy to determine its
safety property. This calls for accessing the function MAL block
and to inspect the arguments of the signature.
@c
int isUnsafeFunction(MalBlkPtr mb,  InstrPtr q)
{
	Symbol s=0;
	Client c;
	mb =0; /* fool the compiler */
	if( q->fcn==0 || functionId(q)== 0) return FALSE;
	c= getClient();
	if( c ) s= getSymbol(c->nspace,q);
	/* check arguments for 'unsafe' property */
	return FALSE;
}
@-
Instructions are unsafe is one of the arguments is also mentioned
in the result list. Alternatively, the 'unsafe' property is set
for the function call itself.
@c
int isUnsafeInstruction(MalBlkPtr mb, InstrPtr q)
{	int j,k;
	mb=0; /* fool compiler */
	if( isUnsafeFunction(mb, q)) return TRUE;
	for(j=0; j<q->retc; j++)
	for(k=q->retc; k<q->argc; k++)
	if( q->argv[k] == q->argv[j]) return TRUE;
	return FALSE;
}
@-
The routine isInvariant determines if the variable V is not
changed in the instruction sequence identified by the range [pcf,pcl].
@c
int isInvariant(MalBlkPtr mb, int pcf, int pcl, int varid)
{
	mb=0; pcf=0;pcl=0;varid=0;
	return TRUE;
}
@-
Any instruction may block identification of a common
subexpression. It suffices to stumble upon an unsafe function 
whose parameter lists has a non-empty intersection with the
targeted instruction.
To illustrate, consider the sequence
@T
\begin{verbatim}
L1 := f(A,B,C);
...
G1 := g(D,E,F);
...
l2:= f(A,B,C);
...
L2:= h()
\end{verbatim}
@
The instruction G1:=g(D,E,F) is blocking if G1 is an alias for {A,B,C}.
Alternatively, function g() may be unsafe and {D,E,F} has a non-empty
intersection with {A,B,C}. An alias can only be used later on for
readonly (and not be used for a function with sideeffects)
@c
int safetyBarrier(Client cntxt,MalBlkPtr mb,InstrPtr p, InstrPtr q)
{
	int i,j;
	for(j=0;j<q->retc; j++)
	for(i=p->retc; i<p->argc;i++)
	if( p->argv[i]== q->argv[j]) {
#ifdef DEBUG_MAL_OPTIMIZER2
	if( cntxt->debugoptimizer){
	stream_printf(GDKout,"Found assignment barrier for \n");
	printInstruction(GDKout,mb,p,LIST_MAL_ALL);
	printInstruction(GDKout,mb,q,LIST_MAL_ALL);
	}
#endif
		return TRUE;
	}

	if( isUnsafeFunction(mb,q)){
		for(i=p->retc; i<p->argc; i++)
		for(j=q->retc; j<q->argc; j++)
		if( p->argv[i]== q->argv[j]) {
#ifdef DEBUG_MAL_OPTIMIZER
	if( cntxt->debugoptimizer){
	stream_printf(GDKout,"Found overlapping assignment barrier for \n");
	printInstruction(GDKout,mb,q,LIST_MAL_ALL);
	}
#endif
			/* TODO check safety property of the argument */
			return TRUE;
		}
	}
	return FALSE;
}
int isUpdated(MalBlkPtr mb, int pc)
{	InstrPtr p,q;
	int j,k;

	p= getInstrPtr(mb,pc);
	for(pc++; pc< mb->stop; pc++){
		q= getInstrPtr(mb,pc);
		/* target is later assigned a new value */
		for(j=0;j<p->retc; j++)
		for(k=0;k<q->retc; k++)
		if( p->argv[j]==q->argv[k]) {
			int c=0;

			if( p->argc!= q->argc) return TRUE;

			/* instruction q may not be a common expression */
			/* TO WEAK, test stability of its arguments */
			for(j=0;j<p->argc;j++)
			if( p->argv[j]==q->argv[k] && 
			    isInvariant(mb,0,pc,q->argv[k])) c++;
			return c!= p->argc;
		}

		/* result is used in an unsafe function*/
		for(j=0; j<p->retc; j++)
		for(k=q->retc; k<q->argc; k++)
		if( p->argv[j]==q->argv[k] && hasSideEffects(q)) return TRUE;
	}
	return FALSE;
}
@-
The common subexpression optimizer locates backwards the identical 
instructions. 
It stops as soon as it has found an identical one. Before we can replace the 
expression with the variable(s) of the previous one, we should assure that
we haven;t passed a safety barrier.

The implementation below is rather expensive for large MAL block.
The search can be improved significantly when a dataflow graph
is maintained for all variables. For, equality of instruction implies that
all variables have been used before in a similar context.

Note, we skip the first instruction because it signifies the signature.
The last instruction signifies the end.
@c
str CXoptimizer(Client cntxt, MalBlkPtr mb, int pc)
{ 	int i,j,k;
	InstrPtr p,q;

	for(i=1; i< mb->stop-1; i++){
		p= getInstrPtr(mb,i);
		if( p->retc!= p->argc)
		for(j= i-1; j>=1; j--) {
			if( safetyBarrier(cntxt,mb,p,q=getInstrPtr(mb,j)) )
				goto nxtCommonSubExpression;
			if( hasSameSignature(p,q) && 
			    hasSameArguments(p,q) &&
			   !isUpdated(mb,i) &&
			   !hasCommonResults(p,q) &&
			   !hasSideEffects(p) ){
#ifdef DEBUG_MAL_OPTIMIZER
	if( cntxt->debugoptimizer){
	stream_printf(GDKout,"Found a common expression %d <-> %d\n",j,i);
	printInstruction(GDKout,mb,q,LIST_MAL_ALL);
	printInstruction(GDKout,mb,p,LIST_MAL_ALL);
	}
#endif
				clrFunction(p);
				p->token= ASSIGNsymbol;
				p->argc= p->retc+q->retc;
				for(k=0; k<q->retc; k++)
				p->argv[p->retc+k]= q->argv[k];
#ifdef DEBUG_MAL_OPTIMIZER
	if( cntxt->debugoptimizer){
	printInstruction(GDKout,mb,p,LIST_MAL_ALL);
	}
#endif
				i= ARoptimizerStep(cntxt,mb,i);
				goto nxtCommonSubExpression;
			} 
		}
		nxtCommonSubExpression: ;
	}
	/* remove the CXoptimizer request */
	if(pc) removeInstruction(mb,pc);
	return NULL;
}

@+ Dead Coder Removal
Dead code fragments are recognized by assignments to variables
whose value is not consumed any more. Note that the DCR should
not be used for testing, because it will trim most programs to
an empty list.

Dead code can be detected running backwards from RETURN statements
and marking all variables used as arguments as relevant. In parallel,
we built a list of instruction that should appear in the final result.
The new code block is than built in one scan.

A source of side effect is the affected control flow in barrier blocks.
They should be retained in the first phase. After we have removed all
remaining code, we may wish to get rid of empty iterator blocks as well.
[This refinement left for the future]

We should also be aware of instructions that produce side effects
to the environment, e.g. printing. Such (possibly recursive)
functions should be marked with a property (sideeffects)
(For now we recognize a few important ones)

The assigments in an iterator also requires care, because
the REDO statement may turn an instruction into a source for
previouse ones. 
@c
int hasSideEffects(InstrPtr p){
	if( blockStart(p) || blockExit(p) || blockCntrl(p)) return TRUE;
	if(functionId(p) && strncmp("print",functionName(p),5)==0) return TRUE;
	if(functionId(p) && strncmp("fprint",functionName(p),6)==0) return TRUE;
	if(functionId(p) && idcmp("deposit",functionName(p))==0) return TRUE;
	if(functionId(p) && idcmp("insert",functionName(p))==0) return TRUE;
	if(functionId(p) && idcmp("prelude",functionName(p))==0) return TRUE;
	if(functionId(p) && idcmp("decimal_prelude",functionName(p))==0) return TRUE;
	return FALSE;
}
str DCoptimizer(Client cntxt, MalBlkPtr mb, int pc)
{	int i,j,k,dc=0,se;
	InstrPtr p;
	int *varused;
	int *pcused;
	pc=0;	/* to fool compilers */

	varused= GDKmalloc(mb->vtop * sizeof(int));
	for(i=0;i<mb->vtop;i++) varused[i]=0;

	pcused= GDKmalloc(mb->stop * sizeof(int));
	for(i=0;i<mb->stop;i++) pcused[i]=0;

	for(i=mb->stop-1; i>=0; i--){
		p= getInstrPtr(mb,i);
		switch( p->token){
		case FUNCTIONsymbol:
		case COMMANDsymbol:
		case STREAMsymbol:
		case ENDDEFsymbol: 
			pcused[i]=1;
			for(k=0; k<p->retc;k++)
				varused[p->argv[k]]=1;
			break;
		case EXITsymbol:
			stream_printf(cntxt->fdout,"#Handle DCR in iterator\n");
		case RETURNsymbol:
			pcused[i]=1;
			for(k=0; k<p->retc;k++)
				varused[p->argv[k]]=1;
			break;
		default:
			se=0;
			for(k=0; k< p->argc; k++)
				if( varused[p->argv[k]]) se++;
			/* do not deal with dead barrier blocks */
			if( hasSideEffects(p) || se){
				for(k=0; k<p->argc;k++) varused[p->argv[k]]=1;
				pcused[i]=1;
			} else dc++; 
		}
	}
#ifdef DEBUG_MAL_OPTIMIZER
	if( cntxt->debugoptimizer){
	if(dc){
	stream_printf(GDKout,"Dead code variables \n");
	for(i=0;i< mb->vtop; i++)
		if( varused[i]==0) 
			stream_printf(cntxt->fdout,"%s,", getVarName(mb,i));
	stream_printf(cntxt->fdout,"\nDead code instructions \n");
	for(i=1; i< mb->stop; i++)
	if( pcused[i]==0)
	printInstruction(cntxt->fdout,mb, getInstrPtr(mb,i), LIST_MAL_ALL);
	stream_printf(cntxt->fdout,"End of DCoptimizer\n");
	}}
#endif
	/* compress the code block */
	for(i=j=1;i< mb->stop;i++){
		if(pcused[i]){
			mb->stmt[j]= mb->stmt[i];
			j++;
		} else {
			p = getInstrPtr(mb,i);	
			freeInstruction(p);
		}
	}
	mb->stop=j; 
	GDKfree(varused);
	GDKfree(pcused);
	/* remove the DCoptimizer request */
	/* removeInstruction(mb,pc); was dead code ! */
	return NULL;
}

@+ Select Push Down heuristic
One of the oldest optimizer tricks in relation processing is
to push a selection predicate through another operator.
This trick is rather complicated to apply to a MAL block, due to
anomalies introduced by the binary datamodel. This leads to a rather
complex compilation of e.g.  (tables r(a,b), s(c,d)
@T
\begin{verbatim}
create table r( a int, b int);
create table s( c int, d int);
select r.a,s.d from r,s where r.a=s.c and r.a<10 and s.d>5;
\end{verbatim}
The optimal code would be
\begin{verbatim}
\end{verbatim}
while the code block produced by the SQL front-end generates
\begin{verbatim}
\end{verbatim}
@-
The approach taken is to combine multiple MAL statements in a
single statement, or replacing/exchancing pairs based on the flow
graph restrictions.

Ignoring performance overhead for the time being, we model the rewrite
operations as separate routines first. The enclosing optimizer then merely
attempts to deploy them until it fails to find a match.
The following table summarizes those considered and implementated.
Predicates are modelled through the naming scheme.
The combinators all assume that the flow path between both operations
is safe.
@T
\begin{tabular}{l l l}
{ y:= reverse(x); \n
  z:= semijoin(R,x);} & z:= revsemijoin(x,R) \\
{ y:= reverse(x); \n
  z:= select(R,l,h);} & z:= revselect(x,R,l,h) \\
{ y:= semijoin(R,x); \n
  z:= select(y,l,h);} & z:= semiseselect(R,x,l,h) \\
{ y:= revsemijoin(x,R); \n
  z:= select(y,l,h);} & z:= revsemiselect(R,x,l,h) \\
{ y:= join(R,S); \n
  z:= semiselect(y,R,l,h);} & {y:= select(R,l,h):\n
			       z:= join(y,S) \\
{ y:= join(R,S); \n
  z:= revsemiselect(y,S,l,h);} & {y:= select(S,l,h):\n
			       z:= join(R,y) \\
{ y:= join(R,S); \n
  z:= semiselect(y,Z,l,h);} & ?????  \\
\end{tabular}
@-
During a final pass through the program, we can convert all combinators 
back into their elementary steps.
@= fndOperator
	(( moduleId(@1)==0 || (@2 && idcmp(moduleName(@1),@2)==0) ) &&
	     (functionId(@1)==0 || (@3 && idcmp(functionName(@1),@3)==0) ))
@-
A more complete implementation should als push the selection through
multiple operators. In particular, a reverse operator may obscure
the opportunity to perform the select push through. 

@c
int SPcombi000(MalBlkPtr mb, int pc1, int pc2)
{
	InstrPtr p,q;
	p= getInstrPtr(mb,pc1);
	q= getInstrPtr(mb,pc2);
	if( @:fndOperator(p,"bat","reverse")@ ){
		if( @:fndOperator(q,"algebra","semijoin")@ ){
			if( p->argv[0]== q->argv[2]){
				GDKfree(p->fcnname);
				GDKfree(p->modname); setModuleId(p, NULL);
				setFunctionId(p, GDKstrdup("reverse_semijoin"));
				p= pushArgument(mb,p,q->argv[1]);
				removeInstruction(mb,pc2);
				return 1;
			}
		}
		if( @:fndOperator(q,"algebra","select")@ ){
			if( p->argv[0]== q->argv[1]){
				GDKfree(p->fcnname);
				GDKfree(p->modname); setModuleId(p, NULL);
				setFunctionId(p, GDKstrdup("reverse_select"));
				p= pushArgument(mb,p,q->argv[1]);
				p= pushArgument(mb,p,q->argv[2]);
				p= pushArgument(mb,p,q->argv[3]);
				removeInstruction(mb,pc2);
				return 1;
			}
		}
	} else
	if( @:fndOperator(p,"algebra","semijoin")@ ){
		if( @:fndOperator(q,"algebra","select")@ ){
			if( p->argv[0]== q->argv[1]){
				GDKfree(p->fcnname);
				GDKfree(p->modname); setModuleId(p, NULL);
				setFunctionId(p, GDKstrdup("semijoin_select"));
				p= pushArgument(mb,p,q->argv[2]);
				p= pushArgument(mb,p,q->argv[3]);
				removeInstruction(mb,pc2);
				return 1;
			}
		}
	}
	return 0;
}
int SPsqueezer000(MalBlkPtr mb, int pc1, int pc2)
{
	InstrPtr p,q;
	p= getInstrPtr(mb,pc1);
	q= getInstrPtr(mb,pc2);
	return 0;
}
str SPoptimizer(Client cntxt, MalBlkPtr mb, int pc)
{	int i,k,combis=0,squeeze=0;
	InstrPtr p;

	/* process the combinators */
	for(i=0; i<mb->stop-1; i++){
		p= getInstrPtr(mb,i);
		for(k=i+1; k<mb->stop && isAlife(mb,p->argv[0],k); k++)
		if( SPcombi000(mb,i,k)){
#ifdef DEBUG_MAL_OPTIMIZER
			if( cntxt->debugoptimizer){
			stream_printf(GDKout,"Combinator found\n");
			printInstruction(GDKout,mb,getInstrPtr(mb,i),LIST_MAL_ALL);
			}
#endif
			combis++;
			k--; /* an instruction has been removed */
			setLifespan(mb); /* expensive but needed */
		}
	}
	/* process the squeezers */
	for(i=0; i<mb->stop-1; i++){
		p= getInstrPtr(mb,i);
		for(k=i+1; k<mb->stop && isAlife(mb,p->argv[0],k); k++)
		if( SPsqueezer000(mb,i,k)){
#ifdef DEBUG_MAL_OPTIMIZER
			if( cntxt->debugoptimizer){
			stream_printf(GDKout,"Squeezer found\n");
			printInstruction(GDKout,mb,getInstrPtr(mb,i),LIST_MAL_ALL);
			}
#endif
			squeeze++;
			k--; /* an instruction has been removed */
		}
	}

	/* remove the SPoptimizer request */
	if(pc) removeInstruction(mb,pc);
	return NULL;
}
@-
Pushing a selection geared at the left operand through the join operator
is more complex, because you can only recognize those instances when later
on the semijoin is recognized. The pattern we are looking for
@T
\begin{verbatim}
AD := join (AB, CD);
ZZ := semijoin (AB, AD);
Za := select(ZZ, l,h);
\end{verbatim}
@-
Note that this operation depends on SPoptimizer, because it already
pushes down the selection through the semijoin.
SHould be done differently
@c
@+ Reverse removal
Combinations of reversals should be removed. It should be called
whenever a new reversal is introduced.
@c
str RRoptimizer(Client cntxt, MalBlkPtr mb, int pc)
{	int i,k;
	InstrPtr q,p;

	for(i=1; i< mb->stop; i++){
		p = getInstrPtr(mb,i);
		if( @:fndOperator(p,"bat","reverse")@ ){
			for(k=i+1; k<mb->stop; k++){
				q= getInstrPtr(mb,k);
				if( @:fndOperator(q,"bat","reverse")@ &&
				    p->argv[0]== q->argv[1] && 
				   !isTouched(mb,p->argv[0],i+1,k)){
#ifdef DEBUG_MAL_OPTIMIZER
		if( cntxt->debugoptimizer){
			stream_printf(GDKout,"Reverse Removal\n");
			printInstruction(GDKout,mb,p,LIST_MAL_ALL);
			printInstruction(GDKout,mb,q,LIST_MAL_ALL);
		}
#endif
				ARreplaceAlias(mb,i,mb->stop,
					p->argv[0], p->argv[1]);
				ARreplaceAlias(mb,k+1,mb->stop,
					q->argv[0], p->argv[1]);
				removeInstruction(mb,k);
				if( pc>k) pc--;
				removeInstruction(mb,i); i--;
				if( pc>i) pc--;
				break;
				}
			}
		}
	}
	if(pc) removeInstruction(mb,pc);
	return NULL;
}
@+ Flow analysis
For each variable we should determine its scope of stability.
End-points in the flow graph are illustrative as dead-code,
that do not produce persistent data. It can be removed when
you know there are no side-effect.

Side-effect free evaluation is a property that should be known upfront.
For the time being, we assume it for all operations known to the system.
The property `unsafe` is reserved to identify cases where this does not hold.
Typically, a bun-insert operation is unsafe, as it changes one of the parameters.
@c
int showOutFlow(MalBlkPtr mb, int pc, int varid, stream *f){
	InstrPtr p;
	int i,k;
	for(i=pc+1; i<mb->stop-1; i++){
		p= getInstrPtr(mb,i);
		for(k=p->retc;k<p->argc;k++)
		if( p->argv[k]==varid) {
			stream_printf(f,"n%d -> n%d\n",pc,i);
		}
	}
	return 0;
}
@-
At a later stage we could extend the flow details with the status
of crucial properties, e.g. processing time, cost, size
@c
void showFlowDetails(MalBlkPtr mb, MalStkPtr stk, InstrPtr p, int pc, stream *f){
	str s,msg;
	stk=0; /* fool the compiler */
	msg= instruction2str(mb,p,0);
	stream_printf(f,"n%d [fontsize=8, shape=box, label=\"",pc);
	for(s=msg; *s; s++)
	if(*s =='"') stream_printf(f,"\\\""); else stream_printf(f,"%c",*s);
	stream_printf(f,"\"];\n");
	GDKfree(msg);
}
void showFlowGraph(MalBlkPtr mb, MalStkPtr stk, str fname){
	stream *f;
	InstrPtr p;
	int i,k;
	stk=0; /* fool the compiler */

	if(idcmp(fname,"stdout")==0) f= GDKout; else
	f= open_wastream(fname);
	p= getInstrPtr(mb,0);
	stream_printf(f,"digraph %s{\n", functionName(p));
	p= getInstrPtr(mb,0);
	showFlowDetails(mb,stk,p,0,f);
	for(k=p->retc;k<p->argc;k++){
		showOutFlow(mb,0,p->argv[k],f);
	}
	for(i=1;i<mb->stop-1;i++){
		p= getInstrPtr(mb,i);
		showFlowDetails(mb,stk,p,i,f);
		for(k=0;k<p->retc;k++){
			showOutFlow(mb,i,p->argv[k],f);
		}
	}
	stream_printf(f,"}\n");
	if(f!= GDKout) f->close(f);
}
@
Summarization of the data flow dependencies can be modelled as a dependency graph.
It can be made explicit or kept implicit using the operators needed.
We start with the latter. The primary steps to deal with is dead code removal.
@c
int removeDeadSink(MalBlkPtr mb, int pc, InstrPtr p){
	/* detect if the destination variable is not used anymor*/
	/* return if it worked out */
	mb=0; pc=0; p=0; /* fool the compiler */
	return FALSE;
}
int removeDeadSource(MalBlkPtr mb, int pc, InstrPtr p){
	/* detect if the source variable is not used anymor*/
	/* return if it worked out */
	mb=0; pc=0; p=0; /* fool the compiler */
	return FALSE;
}
@+ Barrier related optimizations
The barrier blocks provide several bottlenecks for program analysis.
In particular, properties of variables outside the block may depend
on the actual execution flow.

A few generic case can, however, be solved within the semantic context of
the MAL intermediate. This include evaluation of constant expressions,
and strength reduction, by moving possible expensive operations out of the
loop if their are safe.
int removeConstantExpression(MalBlkPtr mb, int pc, InstrPtr p){
	/* simple constant expressions within barrier blocks should be avoided*/
	/* return if it worked out */
	return FALSE;
}
int reduceBarrierStrength(MalBlkPtr mb, int pcfirst, int pclast){
	return FALSE;
}
@* Optimizer utilities
Building optimizer variants require several utilities to ease the life
of the developer. This includes primitives the walk through the
data dependency graph for specific elements and routines to change
the order of the original program.
@+ Path analysis
@+ Code reshuffling
The code reshuffling primitives change the MAL block preferred
execution sequence. Most query optimizers will first take a copy
of the MAL block before this irreversable step is taken.
The argument is the index of the instruction to be moved around to
the new location identified by the target.
The routines for this aspect are available from in mal_instruction.mx

@c
void moveConstantsFirst(MalBlkPtr mb){
	/* move all expression dealing with constants to the beginning */
	/* could be used to shortcut stack initialization */
	mb=0;
}
