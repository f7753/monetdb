% -*-LaTeX-*-
\documentclass[10pt,twocolumn,fleqn]{article}

%%\usepackage{a4wide}
%%\usepackage{amsthm}
\usepackage{times}
\usepackage{epsf}
\usepackage{graphicx}
\usepackage{epsfig}
\usepackage{graphics}
\usepackage{color}
\usepackage{url}

\begin{document}

\title{A compilation approach in M5.0}
\author{ Martin Kersten,{\small \textsc{CWI}, Netherlands}}
\date{}
\maketitle

\section{Introduction}
The x100 execution model is characterised by with the following properties:
\begin{itemize}
\item {\em pipelined execution}, the query execution is data driven using 
small, cache-optimized pipeline buffers and algorithms
\item{\em nsm aware processing}, the attributes necessary to evaluate a 
query term are loaded together (pre-processing/post-processing)
\item{\em minimal intermediate storage}, expression evaluation respects 
the limited size of the cache to avoid swapping temporary results and
to re-use scarce space where possible.
\end{itemize}

These experiments show that there is quite some speed to be obtained
using a different execution model. In the x100 case it is based on
an interpreter which processes vector (groups) rather than materializeing
complete BATs. The group size is chosen with care, so as to fit the cache.

\section{Monet 5.0 Compilation}
The interpreter underlying M V5 is about a factor 5 faster as in V 4.3, but
still this can be improved. 

An early experiment (2001) considered the following experiment:
\begin{verbatim}
t0:= alarm.usec();
barrier v:= nextElement(i,0:lng,1000000:lng);
        insert(b,i,i);
        redo v;
exit v;
t1:= alarm.usec();
c:=copy(b);
t2:= alarm.usec();
d:= new(lng,lng);
h:= 0:lng;
t:= 0:lng;
barrier mloop:= bunStream(b,h,t);
        B2:= find(b,h);
        B3:= find(c,h);
        cr:= B2+B3;
        insert(d,h,cr);
catch GDKerror;
        leave mloop;
exit GDKerror;
        redo mloop;
exit mloop;
t3:= alarm.usec();
\end{verbatim}
This experiment uses a BAT with one million elements and implements the
bulk addition operator. The execution time was 5.5 sec for construction
of B and C, while the multiplex was 14.6 seconds.

The equivalent experiment in V4.3 used 41.5 seconds to
built the bats B and C, while the multiplex addition took 59 sec.

The library function [+](c,d), which is available as hardcoded procedure
in the batcalc library only consumed about 150 milliseconds by overwriting
the initial argument. This is 90x faster than V5 and 390x faster as V4.3

At the same time a naive compilation of the MAL code to C was produced.
Compilation and execution of the complete program took 3.6 seconds using
an iterator (cursor) model. Furthermore, the intermediate result was constructed

This experiment confirmed that construction of intermediates remains a real
issues. The compiled version still was 20x slower.

Questions. The overhead incurred by construction of intermediates can easily
be removed in Monet using an accumulater evaluation model. 
One way is to switch to a 'bit'-vector model, to accumulate results over
single tables,  or a bit^2 model for representing the results of joins.
Depending on the filling level, one could dynamically decide when it
is cost-effective to materialize the oid columns.

\end{document}
