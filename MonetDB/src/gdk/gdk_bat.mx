@f gdk_bat
@a M. L. Kersten, P. Boncz
@* BAT Module
In this Chapter we describe the BAT implementation in more detail.
The routines mentioned are primarilly meant to simplify the library
implementation.

@+ BAT Construction
BATs are implemented in several blocks of memory, prepared for disk
storage and easy shipment over a network.

The BAT starts with a descriptor, which indicates the required BAT
library version and the BAT administration details.  In particular, it
describes the binary relationship maintained and the location of
fields required for storage.

The general layout of the BAT in this implementation is as follows.
Each BAT comes with a heap for the loc-size buns and, optionally,
with heaps to manage the variable-sized data items of both
dimensions.  The buns are assumed to be stored as loc-size
objects.  This is essentially an array of structs to store the
associations.  The size is determined at BAT creation time using an
upper bound on the number of elements to be accomodated.  In case of
overflow, its storage space is extended automatically.

The capacity of a BAT places an upper limit on the number of BUNs to
be stored initially. The actual space set aside may be quite large.
Moreover, the size is aligned to int boundaries to speedup access and
avoid some machine limitations.

Initialization of the variable parts rely on type specific routines
called atomHeap.
@{ 
@h
#ifndef _GDK_BAT_H_
#define _GDK_BAT_H_

#include "gdk.h"

gdk_export BAT *batcopy(BAT *b, int ht, int tt, int writeable);

#endif /* _GDK_BAT_H_ */
@c
#include "gdk_bat.h"
#include "gdk_delta.h"
#include "gdk_atoms.h"
#include "gdk_bbp.h"
#include "gdk_search.h"
#include "gdk_utils.h"

#define ALIGN(n,b)	((b)?(b)*(1+(((n)-1)/(b))):n)

BAT *BATcreatedesc(int ht, int tt) {
	BAT *bn;
@-
Alloc space for the BAT and its dependent records.
@c
	BATstore *bs = (BATstore*) GDKmalloc(sizeof(BATstore)); 
@-
assert needed in the kernel to get symbol eprintf resolved.
Else modules using assert fail to load.
@c
	assert(ht>=0 && tt>=0);
	memset((str)bs, 0, sizeof(BATstore)); 
	bn = &bs->B;
	bn->H = &bs->H;
	bn->T = &bs->T;
	bn->P = &bs->P;
	bn->U = &bs->U;
@-
Fill in basic column info
@c
	bn->htype = ht; 
	bn->ttype = tt;
	bn->hkey = FALSE;
	bn->tkey = FALSE;
	bn->GDKversion = GDKLIBRARY; 
	bn->batId = bs->fullid;
	bn->batBuns = &bn->U->buns;
	strcpy(bn->hident,"h");
	strcpy(bn->tident,"t");
	strcpy(bn->hatom, ATOMname(ht));
	strcpy(bn->tatom, ATOMname(tt));
	bn->halignflushed = bn->halign = OIDnew(2); 
	bn->talignflushed = bn->talign = bn->halign+1;
	bn->hseqbase = bn->tseqbase = oid_nil;
	bn->batPersistence = TRANSIENT;
	return bn;
}

int BATelmshift(BAT *b) {
        int sh, i = BUNsize(b) >> 1;
        for(sh=0; i != 0; sh++) {
                i >>= 1;
        }
	if (BUNsize(b) != (1 << sh)) {
		return -1;
	}
	return sh;
}

void BATsetdims(BAT *b) {
	if (ATOMalign(b->htype) >= ATOMalign(b->ttype)) {
		b->tloc = ALIGN(ATOMsize(b->htype),ATOMalign(b->htype));
		b->hloc = 0; 
		b->dims.bunwidth = b->tloc + ATOMsize(b->ttype);
		if (b->ttype == TYPE_void) b->tloc = 0;
	} else {
		b->hloc = ALIGN(ATOMsize(b->ttype), ATOMalign(b->htype)); 
		b->tloc = 0; 
		b->dims.bunwidth = b->hloc + ATOMsize(b->htype);
		if (b->htype == TYPE_void) b->hloc = 0;
	}
	b->dims.bunwidth = ALIGN(b->dims.bunwidth,ATOMalign(b->htype));
	b->dims.bunwidth = ALIGN(b->dims.bunwidth,ATOMalign(b->ttype));
	b->dims.bunshift = BATelmshift(b);
	b->hvarsized = BATatoms[b->htype].varsized;
	b->tvarsized = BATatoms[b->ttype].varsized;
}


BAT *BATnewstorage(int ht, int tt, int cap) {
 	BAT *bn = BATcreatedesc(ht, tt); 
	int hole_padding;
@-
Dimension info needs to be filled in. 
@c
	BATsetdims(bn);
@-
The hole is normally one tuple that is left free at the start of the heap. However, some 
modules take advantage of the first bun pointer of a bat being int-aligned (ddbench).
This is especially relevant in [void,chr] and [void,sht] combinations. Therefore, in such 
cases, we pad the hole with some extra elements (see also DELTAinit). 
@c
	hole_padding = MAX(sizeof(int),bn->dims.bunwidth)/bn->dims.bunwidth;
@- 
A heap comes with integer offsets to address elements. This way
we do not encounter unexpected results when we use mmap to (un)load
the store.
@c
	HEAPalloc(bn->batBuns, cap+hole_padding, bn->dims.bunwidth);	
	ATOMheap(ht,&bn->hheap, cap);
	ATOMheap(tt,&bn->theap, cap);
@-
The BAT is now given a 'unique' name and stored in the cache.
@c
	DELTAinit(bn);
	BBPcacheit(bn, TRUE);
	bn->batDirty = TRUE;

	return bn; 
}


@- 
The routine BATcreate merely calculates the expected size and performs 
some integrity checking.
Moreover, space is reserved for Delta management.
@c

BAT *BATnew(int ht, int tt, int cap) {
	int	i; 
	BAT	*b;

	ERRORcheck((ht < 0) || (ht > GDKatomcnt), "BATnew:ht error\n"); 
	ERRORcheck((tt < 0) || (tt > GDKatomcnt), "BATnew:tt error\n"); 

	i = ATOMsize(ht) + ATOMsize(tt); 
	ERRORcheck((i == 0), "BATnew: ht and tt cannot be void\n"); 

	/* add space for holes */
	cap = MAX(BATTINY, cap);
	cap += 2; 

	b = BATnewstorage(ht, tt, cap); 
	b->hsorted = ATOMlinear(ht); 
	b->tsorted = ATOMlinear(tt);

	return b;
}

int BATdestroy(BAT *b) {
	return BBPreclaim(b);
}

BAT *BATtmp(BAT *b, int keys)
{
	int	ht ,tt;
	int	cnt;
	BAT	*bn; 

	BATcheck(b, "BATtmp: BAT pointer required"); 
@-
Remap virtual oids (void) automatically to int (ATOMtype).
@c
	tt = BATttype(b);
	ht = BAThtype(b);

	cnt = BATbuncount(b) + 2; /* holes */
	bn = BATnewstorage(ht, tt, cnt); 
	if (bn == NULL) {
		return NULL; 
	}
	if (keys) {
		BAT *bm = BATmirror(bn);
		bm->tkey = bn->hkey = b->hkey; 
		bm->hkey = bn->tkey = b->tkey; 
	}
	return bn; 
}
@- 
If the BAT runs out of storage for BUNS it will reallocate space.
For memory mapped BATs we simple extend the administration after
having an assurance that the BAT still can be safely stored away.

@-
Most BAT operations use a BAT to assemble the result. In several cases
it is rather difficult to give a precise estimate of the required space.
The routine @%BATguess@ is used internally for this purpose.
It balances the cost of small BATs with their probability of occurrence.
Small results BATs are more likely then 100M BATs.

Likewise, the routine @%BATgrows@ provides a heuristic to enlarge the space.
@c
int BATguess(BAT *b) {
	int newcap;
	BATcheck(b,"BATguess");
	newcap = BATcount(b);
	if( newcap < 10 * BATTINY) return newcap;
	if( newcap < 50 * BATTINY) return newcap/2;
	if( newcap < 100 * BATTINY) return newcap/10;
	return newcap/100;
}

int BATgrows(BAT *b) {
	int oldcap, newcap;
	BATcheck(b,"BATgrows");

	newcap = oldcap = BATcapacity(b);
	if (newcap < BATTINY) newcap = 2 * BATTINY; else
	if (newcap < 10 * BATTINY ) newcap = 4 * newcap; else
	if( newcap < 50 * BATTINY ) newcap = 2 * newcap; else
		newcap = newcap * BATMARGIN; 
	if (newcap == oldcap)
		newcap += 10;

	/* if we can extend in reserved space, do not miss the opportunity */
	if (b->batBuns->size + BUNsize(b) <= b->batBuns->maxsize) {
		int rescap = oldcap + (b->batBuns->maxsize - b->batBuns->size)/BUNsize(b) - 1;
		newcap = MIN(newcap,rescap);
	}
	return newcap;
}
@-
The routine should ensure that the BAT keeps its location
in the BAT buffer.

Overflow in the other heaps are dealt with in the atom  routines.
Here we merely copy their references into the new administration space.

@c
BAT *BATextend(BAT *b, int newcap) {
	int	hole_padding, heap_size; 

	BATcheck(b, "BATextend"); 
@- 
The main issue is to properly predict the new BAT size.
storage overflow. The assumption taken is that capacity
overflow is rare. It is changed only when the position
of the next available BUN surpasses the free area marker.
Be aware that the newcap should be greater than the old
value, otherwise you may easily corrupt the administration of
malloc.
@c
	if (newcap <= BATbuncount(b)) {
	    return b;
	}
@-
like in BATnew, add sufficient space for a hole, allowing for
extra padding so the first BUN will be (at least) int-aligned.
@c
	hole_padding = MAX(sizeof(int),b->dims.bunwidth)/b->dims.bunwidth;
	heap_size = BUNsize(b) * (newcap + hole_padding); 

	DELTAsave(b);
	HEAPextend(b->batBuns, heap_size);
	DELTAload(b);

	IDXdestroy(b); 
	HASHdestroy(b); 

	return b; 
}

@-
Reduce the size of a BAT (presumably before saving)
The buns heap is saved very efficiently to disk (only what is in use).
so we do not need to do anything.
The head and tail heaps are copied, reallocated and inserted.
For accelerator heaps there is no solution yet..

@c
void BATreduce(BAT *b, int percentage) {
	int p = ((100*BUNindex(b, b->batDeleted)) / 
		(BUNindex(b, b->batBuns->free) - BUNindex(b, b->batDeleted)));

	if (percentage == 0 || p <= percentage) {
		return;
	}
	IODEBUG {
		THRprintf(GDKerr, "reduce bat %s to %d\n",b->batId, p);
	}
}
@} 


@+ BAT destruction
@-
BATclear quickly removes all elements from a BAT. It must respect the
transaction rules; so stable elements must be moved to the "deleted" 
section of the BAT (they cannot be fully deleted yet). For the elements
that really disappear, we must free heapspace and unfix the atoms if
they have fix/unfix handles. As an optimization, in the case of no stable
elements, we quickly empty the heaps by copying a standard small empty image 
over them.

Also, the BATclear must take care of search acclerators. The builtin search
accelerators are disposable, so BATclear kills them. Also it considers that
the quickest way to rebuild an empty user accelerator is to destroy the
old and build new. The accelerators are only preserved for very small BATs.
@c
@{
BAT *BATclear(BAT *b) {	
	int hacc, tacc, bs=BUNsize(b);
	BUN p, q;

	if (BATcount(b) < 20) {
		/* small BAT: delete all elements by hand */
		BATloopDEL(b, p, q, bs) {
			p = BUNdelete(b,p);
		}
		return b;
	}

	/* kill all search accelerators */
	if (b->hidx_heap) {
		IDXremove(b);
	}
	if (b->tidx_heap) {
		IDXremove(BATmirror(b));
	}
	if (b->hhash_heap) {
		HASHremove(b);
	}
	if (b->thash_heap) {
		HASHremove(BATmirror(b));
	}
	if ((hacc = b->hacctype) > 0) {
		ACCdestroy(b->hacctype, b, &b->haccelerator);
	}
	if ((tacc = b->tacctype) > 0) {
		ACCdestroy(b->tacctype, b, &b->taccelerator);
	}

	/* we must dispose of all inserted atoms */
	if (b->batDeleted == b->batHole && b->batHole == b->batInserted - bs && 
	    BATatoms[b->htype].atomDel == NULL && 
	    BATatoms[b->ttype].atomDel == NULL)
	{
		/* no stable elements: we do a quick heap clean */
		/* need to clean heap which keep data even though the
		   BUNs got removed. This means reinitialize when
		   free > 0
		*/
		int cap = 0;
		if (b->hheap.free > 0){
			HEAPfree(&b->hheap);
			ATOMheap(b->htype, &b->hheap, cap);
		}
		if (b->theap.free > 0){
			HEAPfree(&b->theap);
			ATOMheap(b->ttype, &b->theap, cap);
		}
	} else {
		/* do heap-delete of all inserted atoms */
		void (*hatmdel)(Heap*,int*) = BATatoms[b->htype].atomDel;
		void (*tatmdel)(Heap*,int*) = BATatoms[b->ttype].atomDel;

		if (hatmdel || tatmdel) 
		for(p=b->batInserted, q=BUNlast(b); p < q; p += bs) {
			if (hatmdel) (*hatmdel)(&b->hheap, (int*) BUNhloc(b,p));
			if (tatmdel) (*tatmdel)(&b->theap, (int*) BUNtloc(b,p));
		}
	}

	/* the deleted-section is made to include all stable elements */
	memcpy(b->batHole, b->batInserted - bs, bs);
	b->batHole = b->batInserted - bs;
	b->batBuns->free = b->batInserted - b->batBuns->base;
	b->batDirty = TRUE;

	/* the persistent accelerators are rebuilt on the now empty BAT */
	if (hacc && BATaccelerators[hacc].accSave) {
		ACCbuild(hacc, b, &b->haccelerator, 0);
	}
	if (tacc && BATaccelerators[tacc].accSave) {
		ACCbuild(tacc, b, &b->taccelerator, 0);
	}
	return b; 
}

int BATfree(BAT *b) {
	/* deallocate all memory for a bat */
	int bs=BUNsize(b);
	BUN p, q;

	/* we must dispose of all inserted atoms */
	if (BBP_plevel(b->batCacheid) <= 0 &&
 	    (BATatoms[b->htype].atomDel != NULL || 
	    BATatoms[b->ttype].atomDel != NULL))
	{
		/* do heap-delete of all inserted atoms */
		void (*hatmdel)(Heap*,int*) = BATatoms[b->htype].atomDel;
		void (*tatmdel)(Heap*,int*) = BATatoms[b->ttype].atomDel;

		if (hatmdel || tatmdel) 
		for(p=b->batInserted, q=BUNlast(b); p < q; p += bs) {
			if (hatmdel) (*hatmdel)(&b->hheap, (int*) BUNhloc(b,p));
			if (tatmdel) (*tatmdel)(&b->theap, (int*) BUNtloc(b,p));
		}
	}

	BATreset(b);
	ACCunloadall(b);
        DELTAsave(b); /* convert to disk format */

	if (b->batBuns->base) {
		HEAPfree(b->batBuns);
	}
	if (b->theap.base) {
		HEAPfree(&b->theap);
	}
	if (b->hheap.base) {
		HEAPfree(&b->hheap);
	}
	GDKfree(BATmirror(b));

	return 0;
}

@}
@+ BAT copying
@T
The @%BATcopy@ command takes a BAT and produces a writable copy of it.

The @%BATrcopy@ command takes a BAT and produces a read-only copy of it.
This allows it to make important space optimizations.

The new BAT is always in memory allocated by @%BATcopy@, the user does 
not have to do any memory allocation. 
This routine could benefit from efficient OS memory management support.

The routine assumes that the atom heaps can simply be copied as well.
@c
BAT *batcopy(BAT *b, int ht, int tt, int writeable) {
	BAT *bn;
	BATcheck(b, "batcopy");

	/* optimization: return a view (itself) on a readonly bat */
        if (BATrestricted(b) && !writeable) {
		return VIEWcreate(b);
	} else {
		int xx, yy;
		BUN p, q, r;

		if (!writeable) {
			if (tt && BAThvoid(b)) ht = TYPE_void;
			if (ht && BATtvoid(b)) tt = TYPE_void;
		}
		if (ht == TYPE_void && tt == TYPE_void) {
			tt = TYPE_oid;
		}
		bn = BATnew(ht, tt, BATcount(b));
@-
In case we are dealing with fixed size atoms, it suffices to
ensure enough space (already done by BATnew) and a fast memory
copy of the valid BUN sequence.
@c
                if(!VIEWparent(b) &&
		   (ht <TYPE_str && tt<TYPE_str) &&
                  !(ht==TYPE_bat || ht== TYPE_ptr) &&
                  !(tt==TYPE_bat || tt== TYPE_ptr) &&
		    b->dims.headloc == bn->dims.headloc && 
		    BUNsize(b) == BUNsize(bn)  ){
                        memcpy( (char*)BUNfirst(bn),
                                (char*)BUNfirst(b),
                                BATcount(b)* BUNsize(b) );
                        bn->batDirty = 1;
                        bn->batDirtybuns= 1;
                        bn->batDirtydesc = 1;
                        bn->batBuns->free += BUNsize(b)*BATcount(b);
                        bn->hseqbase = b->hseqbase;
                        bn->tseqbase = b->tseqbase;
		} else {
			r  = BUNfirst(bn);
			yy = BUNsize(bn);
			BATloopFast(b, p, q, xx) {
				ptr h = BUNhead(b,p);
				ptr t = BUNtail(b,p);
				bunfastins_nocheck(bn, r, h, t, yy);
				r += yy;
			}
		}
		bn->hsorted = BAThordered(b);
		bn->tsorted = BATtordered(b);
		ALIGNset(bn,b);
	}
	return bn;
}

BAT *BATcopy(BAT *b) {
	BAT *bn = batcopy(b, b->htype, b->ttype, TRUE);
	BATsetaccess(bn, BAT_WRITE);
	return bn;
}

BAT *BATrcopy(BAT *b) {
	return batcopy(b, b->htype, b->ttype, FALSE);
}

@+ BAT Unit Manipulation
Binary units (tuples) are the elements stored in BATs. We
discuss here BUN insert, replace and delete.

The below are help macro's that actually move the BUNs
around and adapt search accellerator structures.
 
@{
@h
#define hashins(h,i,v,n) HASHins(h,i,v)
#define hashdel(h,i,v,n) HASHdel(h,i,v,n)

@= bun_move
        if (bs == 8) {
                *(lng*) @2 = *(lng*) @1;
        } else if (bs == 4) {
                *(int*) @2 = *(int*) @1;
        } else {
                str _dst=(str)@2, _src=(str)@1, _end=_src+bs;
                while(_src<_end) *(_dst++) = *(_src++);
        } 
@= acc_init
        if (b->@1acctype == 0) {
                @1accmov = NULL;
		@1accins = @1accdel = NULL;
        } else {
                @1accmov = BATaccelerators[b->@1acctype].accMove;
                @1accdel = BATaccelerators[b->@1acctype].accDelete;
                @1accins = BATaccelerators[b->@1acctype].accInsert;
        }
@= hacc_update
	if (hacc@1) {
		(*hacc@1)(&b->haccelerator, @4, b, BUN@2(b,@3));
	}
	if (b->hhash_heap) {
		hash@1(b->hhash, @4, BUN@2(b, @3), @3 < last); 
	} 
@= tacc_update
	if (tacc@1) {
		(*tacc@1)(&b->taccelerator, @4, bm, BUN@2(b,@3));
	}
	if (b->thash_heap) {
		hash@1(b->thash, @4, BUN@2(b, @3), @3 < last); 
	} 
@= acc_move
	if (haccmov) { 
		(*haccmov)(&b->haccelerator, @3, @4, b, BUNhead(b,@1));
	} else if (haccdel) {
		(*haccdel)(&b->haccelerator, @3, b, BUNhead(b,@1));
	}
	if (b->hhash_heap) {
		HASHmove(b->hhash, @3, @4, BUNhead(b, @1), @1 < last); 
	}

	if (taccmov) {
		(*taccmov)(&b->taccelerator, @3, @4, bm, BUNtail(b,@1));
	} else if (taccdel) {
		(*taccdel)(&b->taccelerator, @3, bm, BUNtail(b,@1));
	}
	if (b->thash_heap) {
		HASHmove(b->thash, @3, @4, BUNtail(b, @1), @1 < last); 
	}

	@:bun_move(@1,@2)@

	if (haccmov == NULL && haccins) {
		(*haccins)(&b->haccelerator, @4, b, BUNhead(b,@2));
	}
	if (taccmov == NULL && taccins) {
		(*taccins)(&b->taccelerator, @4, bm, BUNtail(b,@2));
	}


@- BUN Insertion
Insertion into a BAT is split into two operations @%BUNins@ and
@%BUNfastins@.  The former should be used when integrity enforcement
and index maintenance is required.  The latter is used to quickly
insert the BUN into the result without any addition check.
For those cases where speed is required, the type decoding can
be circumvented by asking for a BUN using @%BATbunalloc@ and fill
it directly. See gdk.mx for the bunfastins(b,h,t) macros.
@c
BAT *BUNfastins(BAT *b, ptr h, ptr t) {	
	bunfastins(b, h, t);
	if (!b->batDirty) b->batDirty = TRUE;
	return b;
}


@- 
The interface routine should also perform integrity checks.
Null values should have been obtained at a higher level.
This code assumes that new elements are appended to the BUN list.
@c
INLINE BAT *BUNinplace(BAT *b, BUN p, ptr h, ptr t);

BAT *BUNins(BAT *b, ptr h, ptr t) {	
	BUN p;
	BAT *bm;

	BATcheck(b, "BUNins"); 
	BATcheck(h, "BUNins: head value is nil\n"); 
	bm = BBP_cache(-b->batCacheid);

	if (b->batSet && BUNlocate(b, h, t)) {
	    return b;
	}
	if ((b->hkey & BOUND2BTRUE) && (p=BUNfnd(b,h))) {
	    BUNinplace(b, p, h, t); 
	} else if ((b->tkey & BOUND2BTRUE) && (p=BUNfnd(bm,t))) {
	    BUNinplace(bm, p, t, h); 
	} else { 
	    unsigned int i, bunsize;
	    ALIGNins(b, "BUNins"); 
	    b->batDirty = 1; 
	    if (b->hidx_heap || b->tidx_heap) {
		IDXdestroy(b); 
	    }
	    bunsize = BUNsize(b);
	    p = BUNlast(b); /* insert at end */
	    i = BUNindex(b, p); 
	    if (p-bunsize > b->batHole) {
		if (b->htype != TYPE_void) {
		    int cmp = 0;

		    if (b->hsorted&1) {
			ptr prv = BUNhead(b,p-bunsize);
		        cmp = atom_CMP(h, prv, b->htype);
			if (cmp < 0) {
				b->H->nosorted = i;
		        	b->hsorted = FALSE;
			} else if (cmp && b->hdense && *(oid*)h!=1+*(oid*)prv) {
				b->H->nodense = i;
		        	b->hdense = FALSE;
		    	} 
		    }
		    if (b->hkey == TRUE && cmp <= 0) {
			b->H->nokey[0] = i-1;
			b->H->nokey[1] = i;
			b->hkey = bm->tkey = b->hdense = FALSE;
		    }
	    	}
		if (b->ttype != TYPE_void) {
		    int cmp = 0;

		    if (b->tsorted&1) {
			ptr prv = BUNtail(b,p-bunsize);
		        cmp = atom_CMP(t, prv, b->ttype);
			if (cmp < 0) {
				b->T->nosorted = i;
		        	b->tsorted = FALSE;
			} else if (cmp && b->tdense && *(oid*)t!=1+*(oid*)prv) {
				b->T->nodense = i;
		        	b->tdense = FALSE;
		    	} 
		    }
		    if (b->tkey == TRUE && cmp <= 0) {
			b->T->nokey[0] = i-1;
			b->T->nokey[1] = i;
			b->tkey = bm->hkey = b->tdense = FALSE;
		    }
	    	}
	    } else {
		if (b->htype == TYPE_oid) {
			b->hkey = bm->tkey |= b->hdense = TRUE;
			b->hseqbase = bm->tseqbase = *(oid*) h;
		} else if (b->htype) {
			b->hkey = bm->tkey |= TRUE;
		}
		if (b->ttype == TYPE_oid) {
			b->tkey = bm->hkey |= b->tdense = TRUE;
			b->tseqbase = bm->hseqbase = *(oid*) t;
		} else if (b->ttype) {
			b->tkey = bm->hkey |= TRUE;
		}
	    }
            bunfastins(b, h, t);

	    /* first adapt the hashes; then the user-defined accelerators.
             * REASON: some accelerator updates (qsignature) use the hashes! 
  	     */
	    if (b->hhash_heap) {
		HASHins(b->hhash, i, h); 
	    } 
	    if (b->thash_heap) {
		HASHins(b->thash, i, t); 
	    } 
	    if (b->hacctype) {
		ACCins(b->hacctype, b, &b->haccelerator, i, h); 
	    }
	    if (b->tacctype) {
		ACCins(b->tacctype, BATmirror(b), &b->taccelerator,i,t);
	    }
	}
	return b; 
}

@- BUN Delete
Deletes should maintain the BAT as a contiguous array. This
implementation permits using a BATloop for(;;) construction
to use the BUNdelete routines, by not modifying what is in
front of the deleted bun. 

This routine returns the next BUN in b after deletion of p.
@T
Note: to cause less trouble when updating BATs with void columns
the delete policy has been changed. Deleted volatile elements 
are now being overwritten by the last element; instead of causing 
a cascade of moves. The sequential deletability property
is changed somewhat: instead of doing 
{\small\tt BATloop(b,p,q) BUNdelete(b,p)}
one now must do:
{\small\tt BATloopDEL(b,p) p = BUNdelete(b,p)}.
@
@c
BUN BUNdelete(BAT *b, BUN p) {
	int     sh, st;
	unsigned int idx1, idx2; 
	BAT*	bm = BBP_cache(-b->batCacheid);
	int 	bs = BUNsize(b);
	BUN	l, last = BUNlast(b) - bs; 
        void    (*haccdel)(Heap*, int, BAT*, ptr);
	void	(*taccdel)(Heap*, int, BAT*, ptr);
	void 	(*haccins)(Heap*, int, BAT*, ptr);
	void	(*taccins)(Heap*, int, BAT*, ptr);
        void    (*haccmov)(Heap*, int, int, BAT*, ptr);
	void	(*taccmov)(Heap*, int, int, BAT*, ptr);

	@:acc_init(h)@
	@:acc_init(t)@
 
	if (p == NULL) {
		return p; 
	}
	ALIGNdel(b, "BUNdelete"); /* zap alignment info */

	if (b->hidx_heap || b->tidx_heap) {
		IDXdestroy(b); /* get rid of range index */
	}
	sh = ATOMsize(b->htype);
	st = ATOMsize(b->ttype);

@- Committed Delete. 
The (committed) bun is moved into the hole, and the first 
bun is moved to its old place. The "hole" pointer is incremented.
@c
	if (p < b->batInserted) {
		l = DELTAhole(b); 
		idx1 = BUNindex(b, p); 
		@:hacc_update(del,head,p,idx1)@
		@:tacc_update(del,tail,p,idx1)@
		@:bun_move(p, l)@
		DELTAnexthole(b); 
		l = DELTAhole(b); 
		if (p != l) {
			idx2 = BUNindex(b, l); 
			@:acc_move(l, p, idx2, idx1)@
			if (b->hsorted) {
				b->hsorted = FALSE;
				b->H->nosorted = idx1;
			}
			if (b->tsorted) {
				b->tsorted = FALSE;
				b->T->nosorted = idx1;
			}
		} else {
			if (BAThdense(b)) {
				bm->tseqbase = ++b->hseqbase;
			} 
			if (BATtdense(b)) {
				bm->hseqbase = ++b->tseqbase;
			} 
		}
	} else {
@- Uncommitted Delete.
This bun was not committed, and should therefore disappear. The 
last inserted bun (if present) is copied over it. 
@c
        	void (*hatmdel)(Heap*, int*) = BATatoms[b->htype].atomDel;
		void (*tatmdel)(Heap*, int*) = BATatoms[b->ttype].atomDel;

		if (hatmdel) {
			(*hatmdel)(&b->hheap, (int*) BUNhloc(b,p));
		}
		if (tatmdel) {
			(*tatmdel)(&b->theap, (int*) BUNtloc(b,p));
		}
		idx1 = BUNindex(b, p); 
		@:hacc_update(del,head,p,idx1)@
		@:tacc_update(del,tail,p,idx1)@
		idx2 = BUNindex(b, last);
		if (p != last) {
			@:acc_move(last, p, idx2, idx1)@
			if (b->hsorted) {
				b->hsorted = FALSE;
				b->H->nosorted = idx1;
			}
			if (b->tsorted) {
				b->tsorted = FALSE;
				b->H->nosorted = idx1;
			}
		}
		b->batBuns->free -= bs;
		p = ((char*)p)-bs;
	}
	b->batDirty = 1; /* bat is dirty */
	return p; 
}

BAT *BUNdel (BAT *b, ptr x, ptr y) {
	BUN	p; 

	BATcheck(b, "BUNdel"); 
	BATcheck(x, "BUNdel: head value is nil\n"); 

	if ((p = BUNlocate(b, x, y)) != NULL) {
		ALIGNdel(b, "BUNdel"); /* zap alignment info */
		BUNdelete(b, p); 
		return b;
	}
	return 0;
}

@- 
The routine @%BUNdelHead@ is similar, but removes all BUNs whose head matches
the argument passed.
@c
BAT *BUNdelHead(BAT *b, ptr x) {
	BUN	p; 

	BATcheck(b, "BUNdelHead"); 
	
	if (x == NULL) {
		x = ATOMnilptr(b->htype); 
	}
	if ((p = BUNfnd(b, x)) != NULL) {
		ALIGNdel(b, "BUNdelHead"); /* zap alignment info */
		do {
			BUNdelete(b, p); 
		} while ((p = BUNfnd(b, x)) != NULL);
	}
	return b; 
}
@
Deletion of strings leads to garbage on the variable stack.
This can be removed by compaction of the BAT through copying it.

@-  BUN replace
The last operation in this context is BUN replace. It assumes that
the header denotes a key. The old value association is destroyed (if it
exists in the first place) and the new value takes its place.

In order to make updates on void columns workable; replaces on them 
are always done in-place. Performing them without bun-movements 
greatly simplifies the problem. The 'downside' is that when transaction
managament has to be performed, replaced values should be saved 
explicitly.

@= uncommit_replace
	@:tacc_update(del,t@1,p,pit)@
	ATOMreplace(b->ttype, &b->theap, BUNtloc(b,p), t);
	@:tacc_update(ins,t@1,p,pit)@
	if (BATtordered(b)) {
	    int bs = BUNsize(b), tt = b->ttype;
	    BUN prv = p - bs;
	    BUN nxt = p + bs;
	    if (prv <= b->batHole) prv = NULL;
	    if (nxt > last) nxt = NULL;

	    if ((prv && ATOMcmp(tt, t, BUNt@1(b,prv)) < 0) ||
	        (nxt && ATOMcmp(tt, t, BUNt@1(b,nxt)) > 0)) 
	    {
		b->tsorted = FALSE;
		b->T->nosorted = pit;
	    } else if (b->ttype != TYPE_void && b->tdense &&
			((prv && (1+*(oid*) BUNtloc(b,prv)) != *(oid*) t) ||
			 (nxt && *(oid*) BUNtloc(b,nxt) != (1+*(oid*) t))))
	    {
		b->tdense = FALSE;
		b->T->nodense = pit;
	    }
	}
@c
INLINE 
BAT *BUNinplace(BAT *b, BUN p, ptr h, ptr t) {
	if (p>=b->batInserted || (b->htype==TYPE_void && b->hseqbase!=oid_nil)){
  		/* uncommitted BUN, or void elements */
		/* NO REPLACE DELTA MANAGEMENT ON VOID COLUMNS!! */
		BUN last = BUNlast(b) - BUNsize(b);
		void (*taccins)() = BATaccelerators[b->tacctype].accInsert;
		void (*taccdel)() = BATaccelerators[b->tacctype].accDelete;
		BAT *bm = BBP_cache(-b->batCacheid);
		unsigned int pit = BUNindex(b, p); 

		ALIGNdelT(b, "BUNreplace"); /* zap alignment info */
		if (b->tvarsized) { 
			@:uncommit_replace(var)@
		} else {
			@:uncommit_replace(loc)@
		}
		if (b->tkey && !(b->tkey&BOUND2BTRUE)) {
			BATkey(bm, FALSE);
		}
		b->batDirtybuns = b->theapdirty = TRUE;
	} else {
  		/* committed BUN */
		BUNdelete(b, p); 
		BUNins(b, h, t); 
	}
	return b;
}

BAT *BUNreplace(BAT *b, ptr h, ptr t) {
	BUN	p; 

	BATcheck(b, "BUNreplace\n"); 
	BATcheck(h, "BUNreplace: head value is nil\n"); 
	BATcheck(t, "BUNreplace: tail value is nil\n"); 

	if (!(p=BUNfnd(b, h))) 
		return b;

	ERRORcheck((b->ttype == TYPE_void), 
		"BUNreplace: cannot update void column\n"); 

	if ((b->tkey&BOUND2BTRUE) && BUNfnd(BATmirror(b),t)) {	
		return b;
	}
	return BUNinplace(b, p, h, t);
}

@- BUN Lookup
Location of a BUN using a value should use the available indices
to speed up access. If indices are lacking then a hash index
is constructed under the assumption that 1) multiple access to the BAT 
can be expected and 2) building the hash is only slightly more expensive
than the full linear scan.
NULL is returned if no such element could be found.
In those cases where the type is known and a hash index is available,
one should use the inline functions to speed-up processing.
@c
BUN BUNfnd(BAT *b, ptr v) {
	BUN 	r;

	if (BAThvoid(b)) {
		BUNfndVOID(r,b,v);
		return r; 
	} 
	if (!b->hhash_heap) {
		if (BAThordered(b)&1) return (BUN) SORTfnd(b, v); 
		if (b->hidx_heap) return (BUN) IDXfnd(b, v); 
	} 
	switch(ATOMstorage(b->htype)) {
	case TYPE_chr: HASHfnd_chr(r,b,v); break; 
	case TYPE_sht: HASHfnd_sht(r,b,v); break;
	case TYPE_int:
	case TYPE_flt: HASHfnd_int(r,b,v); break;
	case TYPE_dbl: 
	case TYPE_lng: HASHfnd_lng(r,b,v); break;
	case TYPE_str: HASHfnd_str(r,b,v); break;
	default:       HASHfnd(r,b,v);
	}
	return r;
}

@= swapif
if (@1) {
	ptr _p=x; x=y; y=_p; 
	b = BATmirror(b);
}	
@c
BUN BUNlocate(BAT *b, ptr x, ptr y) {
	BUN	p = NULL, q = NULL; 
	int	h, (*cmp)();

	BATcheck(b, "BUNlocate: BAT parameter");
	BATcheck(x, "BUNlocate: value parameter");

	@:swapif(b->htype == TYPE_void && b->hseqbase == oid_nil && *(oid*)x == oid_nil)@
	if (y==NULL || (b->ttype==TYPE_void && 
	    b->tseqbase == oid_nil && *(oid*)y==oid_nil)) 
	{
		return BUNfnd(b,x);
	} 

	/* positional lookup */
	@:swapif(BATtdense(b))@
	if (BAThdense(b)) {
		int i = *(oid*) x - b->hseqbase;
		cmp= BATatoms[b->ttype].atomCmp; 

		if (i >= 0 && i < BATcount(b)) {
			i += BUNindex(b,BUNfirst(b));
			p = BUNptr(b, i);
			if ((*cmp)(y, BUNtail(b, p)) == 0) return p; 
		}
		return NULL; 
	}

	/* binary search */
	@:swapif((BAThordered(b)&1) && !(BATtordered(b)&1))@
	if (BATtordered(b)) {
		cmp = BATatoms[b->htype].atomCmp; 

		SORTloop(b,p,q,y,y,h) {
			if ((*cmp)(x, BUNhead(b, p)) == 0) return p; 
		}
		return NULL; 
	}

	/* Ttree search */
	@:swapif(b->tidx_heap && b->hidx_heap == NULL)@
	if (b->hidx_heap) {
		BUN *pi, *qi;
		cmp = BATatoms[b->ttype].atomCmp; 

		IDXrng(b, x, y, &pi, &qi);
		IDXloop(b, pi, qi) {
			if ((*cmp)(y, BUNtail(b, *pi)) == 0) return p; 
		}
		return NULL; 
	}

	/* hash-table lookup */
	@:swapif(b->thash_heap && b->hhash_heap == NULL)@
	cmp = BATatoms[b->ttype].atomCmp; 
	(void) BATprepareHash(b);
	HASHloop(b, b->hhash, h, x) {
	    p = BUNptr(b, h); 
	    if ((*cmp)(y, BUNtail(b, p)) == 0) return p; 
	}
	return 0; 
}



@+ BAT Property Management

The function @%BATcount@ returns the number of active elements in a BAT.
Counting is type independent.
It can be implemented quickly, because the system ensures a dense
BUN list.
@{
@c
int BATcount (BAT *b) {
	int     f;
	int     l;
 
	BATcheck(b, "BATcount");
	f = BUNindex(b, BUNfirst(b));
	l = BUNindex(b, BUNlast(b));
	return (l - f);
}
@-
The alternative routine is @%BATbuncount@, which calculates the
total buns in use.
@c
int BATbuncount (BAT *b)
{
        int     f;
 
        BATcheck(b, "BATbuncount");
        f = b->batBuns->size - (BUNfirst(b) - b->batBuns->base);
 
        return f / BUNsize(b);
}

size_t BATvmsize(BAT *b, int dirty) {
	if (b->batDirty) dirty = 0;
        return  ((dirty == 0 || b->batDirtybuns)?HEAPvmsize(b->batBuns):0) +
                ((dirty == 0 || b->batDirtybuns)?HEAPvmsize(b->hhash_heap):0) +
                ((dirty == 0 || b->batDirtybuns)?HEAPvmsize(b->thash_heap):0) +
                ((dirty == 0 || b->batDirtybuns)?HEAPvmsize(b->hidx_heap):0) +
                ((dirty == 0 || b->batDirtybuns)?HEAPvmsize(b->tidx_heap):0) +
                ((dirty == 0 || b->hheapdirty)?HEAPvmsize(&b->hheap):0) +
                ((dirty == 0 || b->theapdirty)?HEAPvmsize(&b->theap):0) +
                ((dirty == 0 || b->haccdirty)?HEAPvmsize(&b->haccelerator):0) +
                ((dirty == 0 || b->taccdirty)?HEAPvmsize(&b->taccelerator):0);
}

size_t BATmemsize(BAT *b, int dirty) {
	if (b->batDirty) dirty = 0;
        return  ((dirty == 0 || b->batDirtydesc)?sizeof(BATstore):0) +
                ((dirty == 0 || b->batDirtybuns)?HEAPmemsize(b->batBuns):0) +
                ((dirty == 0 || b->batDirtybuns)?HEAPmemsize(b->hhash_heap):0) +
                ((dirty == 0 || b->batDirtybuns)?HEAPmemsize(b->thash_heap):0) +
                ((dirty == 0 || b->batDirtybuns)?HEAPmemsize(b->hidx_heap):0) +
                ((dirty == 0 || b->batDirtybuns)?HEAPmemsize(b->tidx_heap):0) +
                ((dirty == 0 || b->hheapdirty)?HEAPmemsize(&b->hheap):0) +
                ((dirty == 0 || b->theapdirty)?HEAPmemsize(&b->theap):0) +
                ((dirty == 0 || b->haccdirty)?HEAPmemsize(&b->haccelerator):0) +
                ((dirty == 0 || b->taccdirty)?HEAPmemsize(&b->taccelerator):0);
}
@
@}
@-
The key and name properties can be changed at any time.
Keyed dimensions are automatically supported by an auxilary hash-based
access structure to speed up searching. Turning off the key integrity 
property does not cause the index to disappear. It can still be used to
speed-up retrieval. The routine @%BATkey@ sets the key property of the
association head. 

@{
@c
BAT *BATkey(BAT *b, int flag) {
	bat parent = VIEWparentcol(b);

	if (b->htype == TYPE_void) {
		if (b->hseqbase == oid_nil && flag == BOUND2BTRUE) {
                        GDKerror("BATkey: nil-column cannot be kept unique.\n");
		}
		if (b->hseqbase == oid_nil || flag == FALSE) {
                        return b;
                }
		flag = TRUE; /* we only allow TRUE on dense void bats */
        }
        if (flag) flag |= (1|b->hkey);
        if (b->hkey != flag) b->batDirtydesc = TRUE;
        BATmirror(b)->tkey = b->hkey = flag;
	if (flag && parent && ALIGNsynced(b,BBP_cache(parent)))
		BATkey(BBP_cache(parent),TRUE);
        return b;
}


BAT *BATset(BAT *b, int flag) {
	BATcheck(b, "BATset"); 
	if (b->htype == TYPE_void) {
		if (b->hseqbase == oid_nil && flag == BOUND2BTRUE) 
			BATkey(BATmirror(b), flag);
	} else if (b->ttype == TYPE_void) {
		if (b->tseqbase == oid_nil && flag == BOUND2BTRUE) 
			BATkey(b, flag);
	} else {
		if (flag) flag =TRUE;
		if (b->batSet != flag) b->batDirtydesc = TRUE; 
		b->batSet = flag;
	}
	return b; 
}

@= mmap_write
    if (@2.base != NULL && @2.storage == STORE_MMAP && @2.filename != NULL) {
	@1 = STORE_PRIV; action = 2;
    } else @1 = @2.storage;
@= mmap_read
    if (@2.base != NULL && @2.storage == STORE_PRIV && @2.filename != NULL) {
	if (@2.copied) {
		action = 0;
	} else {
		@1 = STORE_MMAP; action = 1;
	}
    } else @1 = @2.storage;
@c
BAT *BATsetaccess(BAT *b, int mode) {
	BATcheck(b, "BATsetaccess"); 

	if (b->batRestricted != mode) {
   	    int action=0, m1=0, m2=0, m3=0, m4=0, m5=0;	
	    bat bid = ABS(b->batCacheid);
 
	    if (VIEWparent(b) && mode != BAT_READ) {
		VIEWreset(b);
	    }  
/*
	    MT_set_lock(GDKswapLock[bid&BBPLOCKMASK], "BATsetaccess");
*/
	    if (b->batSharecnt && mode != BAT_READ) {
	        GDKwarning("BATsetaccess: %s has %d views; deliver a copy.\n", b->batId, b->batSharecnt);
/*
	        MT_unset_lock(GDKswapLock[bid&BBPLOCKMASK], "BATsetaccess");
*/
	        b = BATsetaccess(batcopy(b,b->htype,b->ttype,TRUE),mode); 
		if (b->batStamp > 0) b->batStamp = -b->batStamp; /* prevent MIL setaccess */
	    } else {
/*
	        MT_unset_lock(GDKswapLock[bid&BBPLOCKMASK], "BATsetaccess");
*/
		
		if (mode == BAT_READ) {
		    @:mmap_read(m1,(*b->batBuns))@
		    @:mmap_read(m2,b->hheap)@
		    @:mmap_read(m3,b->theap)@
		    @:mmap_read(m4,b->haccelerator)@
		    @:mmap_read(m5,b->haccelerator)@
	 	} else { /* BAT_APPEND || BAT_WRITE */
		    if (mode == BAT_WRITE) {
		    	@:mmap_write(m1,(*b->batBuns))@
		    }
		    if (mode == BAT_WRITE || b->htype != TYPE_str || GDK_ELIMDOUBLES((&b->hheap))) {
		    	@:mmap_write(m2,b->hheap)@
		    }
		    if (mode == BAT_WRITE || b->ttype != TYPE_str || GDK_ELIMDOUBLES((&b->theap))) {
		    	@:mmap_write(m3,b->theap)@
		    }
		    @:mmap_write(m4,b->haccelerator)@
		    @:mmap_write(m5,b->haccelerator)@
		}
	    }
	    b->batRestricted = mode;
	    b->batDirtydesc = TRUE;
	    if (action) {
		BATmmap(b, m1, m2, m3, m4, m5);
		if (action == 2) {
			str s = BBPname(b->batCacheid);
			BBPsave(b);
			BATfree(b);
			b = BATload(s);
		}
	    }
	}
	return b;
}

int BATgetaccess(BAT *b) {
	BATcheck(b, "BATgetaccess"); 
	return b->batRestricted;
}

@- 
BATs have a logical name that is indepent of their 
location in the file system (this depends on batCacheid).
The dimensions of the BAT can be given a separate name.
It helps front-ends in identifying the column of interest.
The new name should be recognizable as an identifier.
Otherwise interaction through the front-ends becomes
complicated.
@c
int BATname(BAT *b, str nme) {
	BATcheck(b, "BATname"); 
	return BBPrename(b->batCacheid, nme); 
}

str BATrename(BAT *b, str nme) {
	int ret = BATname(b, nme); 

	if (ret == 1) {
		GDKerror("BATrename: identifier expected: %s\n",nme);
	} else if (ret == BBPRENAME_ALREADY) {
		GDKerror("BATrename: name is in use: '%s'.\n", nme); 
	} else if (ret == BBPRENAME_ILLEGAL) {
		GDKerror("BATrename: illegal temporary name: '%s'\n", nme); 
	} else if (ret == BBPRENAME_LONG) {
		GDKerror("BATrename: name too long: '%s'\n", nme); 
	}
	return BBPname(b->batCacheid); 
}



BAT *BATroles(BAT *b, str hnme,str tnme) {
	int i;

	BATcheck(b,"BATroles");
	if( (i = strlen(hnme)) >= IDLENGTH - 1) {
		GDKerror("BATroles:head name too long\n");
		hnme[IDLENGTH-1] = 0;
		i = IDLENGTH-1;
	}
	memcpy(b->hident,hnme,i+1);
	if( (i = strlen(tnme)) >= IDLENGTH - 1) {
		GDKerror("BATroles:tail name too long\n");
		tnme[IDLENGTH-1] = 0;
		i = IDLENGTH-1;
	}
	memcpy(b->tident,tnme,i+1);
	return b;
}

BAT *BATmode(BAT *b, int mode) {
	BATcheck(b, "BATmode"); 

	MT_set_lock(GDKtmLock, "BATmode"); 
	if ((b->batPersistence&mode) == 0){
		b->batPersistence = mode;
		BBPdirty(1);
		if (mode&PERSISTENT) {
			if (VIEWparent(b)) {
				VIEWreset(b);
			}
			BBPpersistent(b->batCacheid, TRUE);
		} else {
			BBPtransient(b->batCacheid, TRUE);
		}
	}
	MT_unset_lock(GDKtmLock, "BATmode"); 
	return b; 
}


int BATkeytst(BAT *b, ptr h, ptr t) {
	BUN p = NULL; 

	BATcheck(b, "BATkeytst"); 
	if (b->hkey && b->htype && h) {
		p = BUNfnd(b, h); 
	}
	if (b->tkey && b->ttype && t) {
		p = BUNfnd(BATmirror(b), t); 
	}
	return (p != NULL); 
}

BAT *BATseqbase(BAT *b, oid o) {
	BATcheck(b, "BATseqbase"); 
	if (ATOMtype(b->htype) == TYPE_oid) {
		BAT* m = BATmirror(b);
        	if (b->hseqbase != o) {
        		b->batDirtydesc = TRUE;
			/* zap alignment if column is changed by new seqbase */
			if (b->htype == TYPE_void) b->halign = m->talign = 0; 
		}
        	m->tseqbase = b->hseqbase = o;

		/* adapt keyness */
		if (BAThvoid(b)) {
        	    if (o == oid_nil) {
               		if (b->hkey) m->tkey = b->hkey = FALSE;
        	    } else {
               		if (!b->hkey) m->tkey = b->hkey = TRUE;
		    }
		}
	}
	return b;
}

@- BATpropcheck

This is a low-cost routine that smartly tries to deduce as 
much properties possible on the head column of its BAT parameter.

with PROPDEBUG (-d8) enabled, it is also a powerful tool
to check whether all properties of a BAT are set correctly.

It uses efficient algorithms to either prove or disprove
the validity of the hkey, hsorted and hdense properties.

If each such property is already set, we know already for certain 
and do not have to check. If in the course of this routine we find 
proof that the property does not hold, we record this proof
using special fields in the BAT descriptor. 
This means that a subsequent execution of this routine 
does not have to check the property exhaustively anymore.

This routine now guarantees that any property that could be set 
on the BAT head column, is set after execution. Hence it can be
used for determining with certainty whether the head column of a 
BAT is sorted, key or dense. 
@c
BAT* BATpropcheck_(BAT* b, int sanity_check) {
	int disprove_dense, disprove_sorted, disprove_key = TRUE;
	int dense_bak = 0, key_bak = 0, sorted_bak = 0;
	oid seq_bak = 0;
	int xx, yy, tpe;
	BUN p, q, r;
	ptr last;

	BATcheck(b, "BATpropcheck: BAT parameter"); 
	if (b->halign == 0) {
		b->batDirtydesc = 1; b->halign = OIDnew(1);
	}
	tpe = b->htype;
	yy = BUNindex(b, BUNfirst(b));
	xx = BUNindex(b, BUNlast(b));
	disprove_sorted = ATOMlinear(tpe);
@- 
check if duplicated properties are equal
@c
if (sanity_check) {
	BAT *bm = BATmirror(b);
	if (BAThvoid(b) && b->hseqbase != bm->tseqbase) {
		oid o = (b->htype && yy != xx)?*(oid*) BUNhloc(b,BUNfirst(b)):oid_nil;
		GDKerror("BATpropcheck: BAT %d set inconsistent hseqbase=%d\n", b->batCacheid, o);
		b->hseqbase = bm->tseqbase = o; b->batDirty = TRUE;
	}
	if (b->GDKversion != bm->GDKversion || b->U != bm->U || b->P != bm->P ||
	    b->H != bm->T || b->htype != bm->ttype || b->hloc != bm->tloc || 
	    b->dims.headvarsized != bm->dims.tailvarsized  ||
	    b->dims.bunshift != bm->dims.bunshift ||
	    b->dims.bunwidth != bm->dims.bunwidth || b->batBuns->size <= 0 ||
	    b->batDeleted < b->batBuns->base || b->batHole < b->batDeleted ||
	    b->batHole > b->batInserted || b->batBuns->free > b->batBuns->size||
	    b->batInserted > (b->batBuns->base + b->batBuns->free))
	{
		GDKfatal("BATpropcheck: BAT %d has inconsistent descriptor\n", b->batCacheid);
	}
	if (b->hhash_heap != bm->thash_heap || b->hidx_heap != bm->tidx_heap) {
		GDKerror("BATpropcheck: BAT %d has inconsistent accrefs\n", b->batCacheid);
		ACCremoveall(b); 
		b->batDirty = TRUE;
	}
	if (b->dims.headkey != bm->dims.tailkey) {
		GDKerror("BATpropcheck: BAT %d recovered hkey\n",b->batCacheid);
		b->dims.headkey = bm->dims.tailkey = b->batDirty = TRUE;
	}
	if (BAThdense(b) && !b->hkey) {
		GDKerror("BATpropcheck: BAT %d is dense but not key!?\n", 
			   b->batCacheid);
	}
} 	
	if (BAThdense(b) && !b->hkey) BATkey(b,TRUE);
@-
quick check on trivial cases (void columns, 0 or 1 tuple bats).
@c
	if (tpe == TYPE_void) {
		return b;
	}
	if (yy+1 >= xx) {
		if (ATOMlinear(tpe) && !(b->hsorted&1)) {
			XPROPDEBUG GDKwarning("BATpropcheck: BAT %s(%d) with %d typles is (h)sorted!\n",
						b->batId,b->batCacheid,BATcount(b));
			b->hsorted = b->batDirtydesc = TRUE;
		}
		if (yy > xx && !b->hkey) {
			XPROPDEBUG GDKwarning("BATpropcheck: BAT %s(%d) with %d typles is (h)key!\n",
						b->batId,b->batCacheid,BATcount(b));
			BATkey(b,TRUE);
		}
		if (yy > xx && tpe == TYPE_oid && !BAThdense(b)) {
			XPROPDEBUG GDKwarning("BATpropcheck: [oid,?]-BAT %s(%d) with %d typles is (h)dense!\n",
						b->batId,b->batCacheid,BATcount(b));
			b->hdense = b->batDirtydesc = TRUE; 
			BATseqbase(b, *(oid*) BUNhloc(b,BUNfirst(b)));
		}
		return b;
	}
@-
first propagate already known properties. that will save some effort.
@c
	if (VIEWparentcol(b)) {
		/* quickly propagate properties from parent to child */
		BAT *parent = BBP_cache(VIEWparent(b));

		if ((BAThordered(parent)&1) && !(BAThordered(b)&1)) {
			XPROPDEBUG GDKwarning("BATpropcheck: BAT %s(%d) inherits (h)sorted from BAT %s(%d)!\n",
						b->batId,b->batCacheid,parent->batId,parent->batCacheid);
			b->hsorted = b->batDirtydesc = TRUE;
		}
		if (parent->hkey && !b->hkey) {
			XPROPDEBUG GDKwarning("BATpropcheck: BAT %s(%d) inherits (h)key from BAT %s(%d)!\n",
						b->batId,b->batCacheid,parent->batId,parent->batCacheid);
			BATkey(b,TRUE);
		}
		if (BAThdense(parent) && tpe == TYPE_oid && !BAThdense(b)) {
			XPROPDEBUG GDKwarning("BATpropcheck: [oid,?]-BAT %s(%d) inherits (h)dense from BAT %s(%d)!\n",
						b->batId,b->batCacheid,parent->batId,parent->batCacheid);
			b->hdense = b->batDirtydesc = TRUE; 
			BATseqbase(b, *(oid*) BUNhloc(b,BUNfirst(b)));
		}
	}
	disprove_dense = (tpe == TYPE_oid);

	if (sanity_check) {
		dense_bak = BAThdense(b);
		seq_bak = b->hseqbase;
		sorted_bak = BAThordered(b);
		key_bak = b->hkey;
		BATkey(b,FALSE);
		b->hsorted = FALSE;
		b->hdense = FALSE;
	} else if (b->hdense) {
		disprove_dense = FALSE;
	}
@-
check whether whatever we want need to prove was already disproven 
@c
	if (disprove_key) {
	if (b->hkey || ((b->H->nokey[0] != b->H->nokey[1]) && 
	    (b->H->nokey[0] >= yy) && (b->H->nokey[0] < xx) &&
	    (b->H->nokey[1] >= yy) && (b->H->nokey[1] < xx) &&
	    ATOMcmp(tpe, BUNhead(b,BUNptr(b,b->H->nokey[0])), 
                         BUNhead(b,BUNptr(b,b->H->nokey[1]))) == 0)) 
	{
		disprove_key = FALSE;
	} else {
		b->H->nokey[0] = b->H->nokey[1] = -1;
	}}
	if (disprove_sorted) {
	if ((BAThordered(b)&1) || ATOMlinear(tpe)==0 ||
	   ((b->H->nosorted > yy) && (b->H->nosorted < xx) &&
	    ATOMcmp(tpe, BUNhead(b, BUNptr(b,b->H->nosorted-1)), 
                         BUNhead(b, BUNptr(b,b->H->nosorted))) > 0))
	{
		disprove_sorted = FALSE;
	} else {
		b->H->nosorted = -1;
	}}
	if (disprove_dense) {
	if ((b->hsorted == FALSE && disprove_sorted == FALSE) || 
	   ((b->H->nodense > yy) && (b->H->nodense < xx) &&
	    (*(oid*) BUNhloc(b, BUNptr(b,b->H->nodense-1))+1 != 
             *(oid*) BUNhloc(b, BUNptr(b,b->H->nodense)))))
	{
		disprove_dense = FALSE;
	} else {
		b->H->nodense = -1;
	}}
@-
still got something to prove? If not, we're done.
@c
	if (!(disprove_sorted || disprove_key || disprove_dense)) {
		goto exit;
	}
@-
Prepare to scan.
@c
	p = BUNfirst(b); q = BUNlast(b);
	last = BUNhead(b,p); xx = BUNsize(b);
@-
disprove_dense is only set for oid columns, as the 'dense' property
is only relevant for this type..
@c
	if (disprove_dense) while ((p += xx) < q) {
		ptr v = BUNhloc(b,p);
		if ((*(oid*) last + 1) != *(oid*) v) {
			disprove_dense = FALSE; 
			b->hdense = FALSE; 
			b->H->nodense = BUNindex(b,p);
			b->batDirtydesc = 1; 
			break;
		} last = v;
	} else p += xx;
@-
Merge scan check to see if head values are sorted (&key) 
@c
	switch(ATOMstorage(tpe)) {
	case TYPE_chr: @:merge_disprove(simple,chr,loc)@
	case TYPE_sht: @:merge_disprove(simple,sht,loc)@
	case TYPE_int: @:merge_disprove(simple,int,loc)@
	case TYPE_flt: @:merge_disprove(simple,flt,loc)@
	case TYPE_lng: @:merge_disprove(simple,lng,loc)@
	case TYPE_dbl: @:merge_disprove(simple,dbl,loc)@
	default:       @:merge_disprove(atom,tpe,ead)@
	}

@= merge_disprove
	if (disprove_sorted) while (p < q) {
		ptr v = BUNh@3(b,p);
		int ret = @1_CMP(v,last,@2);
		if (ret < 0) {
			disprove_sorted = FALSE;
			b->H->nosorted = BUNindex(b,p);
			b->batDirtydesc = 1; 
			break;
		} else if (ret == 0 && disprove_key) {
			b->H->nokey[0] = BUNindex(b,p)-1;
			b->H->nokey[1] = BUNindex(b,p);
			disprove_key = FALSE;
			b->batDirtydesc = 1; 
		} 
		p += xx; last = v;
	} break;
@-
check to see if head values are key.
We create a view on the bat as the hash table created is 
partial; hence inconsistent (it should also not molest
existing consistent hash tables). On this VIEW we can do a HASfnd
@c
	if (disprove_key && p < q) {
		BAT *bv = VIEWcreate(b);
		Heap *hp = HASHnew(&bv->hhash, tpe, BATcapacity(b), HASHmask(BATcount(b)));
		bv->hhash_heap = BATmirror(bv)->thash_heap = hp;

		switch(ATOMstorage(tpe)) {
		case TYPE_chr: @:hash_disprove(_chr,loc)@
		case TYPE_sht: @:hash_disprove(_sht,loc)@
		case TYPE_int:
		case TYPE_flt: @:hash_disprove(_int,loc)@
		case TYPE_lng:
		case TYPE_dbl: @:hash_disprove(_lng,loc)@
		default:       @:hash_disprove(,ead)@
		}

@= hash_disprove
		for(r=BUNfirst(b); r<p; r+=xx, yy++) {
			HASHins@1(bv->hhash, yy, BUNh@2(bv,r));
		}
		do {
			ptr v = BUNh@2(bv,p);
			HASHfnd@1(r,bv,v); /* purify: UMR */
			if (r != NULL) {
				b->H->nokey[0] = BUNindex(bv,r);
				b->H->nokey[1] = yy;
				disprove_key = FALSE;
				b->batDirtydesc = 1; 
				break;
			} 
			HASHins@1(bv->hhash, yy, v); yy++;
		} while((p += xx) < q);
		break;
@c
		BBPreclaim(bv);
	}
@-
failed to disprove on exhaustive check => succeeded to prove
@c
	if (disprove_key || disprove_dense) {
		BATkey(b, key_bak|TRUE); /* respect BOUND2BTRUE */
	}
	if (disprove_sorted || disprove_dense) {
		b->batDirtydesc = TRUE;
		b->hsorted = GDK_SORTED; 
	}
	if (disprove_dense) {
		b->batDirtydesc = b->hdense = TRUE; 
		BATseqbase(b, *(oid*) BUNhloc(b,BUNfirst(b)));
	}
exit:	if (sanity_check) {
		if (sorted_bak && !(BAThordered(b)&1)) 
		GDKwarning("BATpropcheck: BAT %s was incorrectly marked sorted!\n", b->batId);
		if (key_bak && !b->hkey) 
		GDKwarning("BATpropcheck: BAT %s was incorrectly marked keyed!\n", b->batId);
		if (dense_bak && disprove_dense) {
		   if(!BAThdense(b)) 
		   GDKwarning("BATpropcheck: BAT %s was incorrectly marked dense!\n", b->batId);
		   if (seq_bak != b->hseqbase) 
		   GDKwarning("BATpropcheck: BAT %s had incorrect seqbase!\n", b->batId);
		}
		XPROPDEBUG {
			if (!sorted_bak && (BAThordered(b)&1)) 
			GDKwarning("BATpropcheck: BAT %s was not marked sorted!\n", b->batId);
			if (!key_bak && b->hkey) 
			GDKwarning("BATpropcheck: BAT %s was not marked keyed!\n", b->batId);
			if (!dense_bak && disprove_dense) {
			   if(BAThdense(b)) 
			   GDKwarning("BATpropcheck: BAT %s was not marked dense!\n", b->batId);
			}
		}
	}
	return b; 
}

BAT *BATpropcheck(BAT *b) {
	return BATpropcheck_(b, GDKdebug&8);
}

@- BATrepair
@T
Due to course of time, we learned (the hard way) to appreciate the importance of consistency checks. 
More than often, unstable code seems to work well, turns out to save erroneous BAT images to disk. 
Or even worse, an unrelated incorrect pointer error in a totally unrelated part of the prigram
overwrites the memory image of a dirty BAT that is subsequently saved on disk.

When these BATs are the used in following sessions (sometimes in a much later point of time; even with 
another version of the program) these corrupted BAT images can produce all kinds of horrible crashes
that are very hard to explain -- as the original context in which the BAT was corrupted is typically
not available anymore.

We devised the -d2 for CHECKDEBUG, a debugging mode that will leads all BAT images when  they are 
loaded through a consistency check. PROPDEBUG automatically switches on CHECKDEBUG.

@= bunrepair
{	int idx = *(int*) BUNhloc(b,p);
	if (idx >= hr.minpos && idx < hr.maxpos && (idx&alignmask) == 0) {
		idx = (idx - hr.minpos) >> alignshift;  /* compute bitidx */
		mask = 1 << (idx&31); 
		pos = idx >> 5; 
		if (hr.validmask[pos] & mask) {
			continue; /* A-OK */
		}
	}
	if (corrections == NULL) {
		corrections = BATnew(TYPE_int, TYPE_int, 10);
	}
	BUNfndOID(r, corrections, BUNhloc(b,p));
	if (r == NULL) {
		BUNins(corrections, BUNhloc(b,p), &one); 
	} else {
		(*(int*) BUNtloc(corrections,r))++;
	}
	ATOMput(tpe, hp, (int*) BUNhloc(b,p), nilval);
}
@c
static int atomrepair(BAT *b) {
	int (*checkFcn)(Heap *h, HeapRepair *hr) = BATatoms[b->htype].atomHeapCheck;
	int mask, pos, one=1, ret, xx, tpe=b->htype;
	ptr nilval = ATOMnilptr(tpe);
	Heap *hp = &b->hheap;
	HeapRepair hr;
	BUN p, q, r;

	if (checkFcn == NULL) { 
		return TRUE;
	}
	ret = (*checkFcn)(hp, &hr);

	if (hr.validmask) {
		int alignshift = (hr.alignment==8)?3:2;
		int alignmask = (1 << alignshift) - 1;
		BAT *corrections = NULL;

		DELloop(b, p, q, xx) @:bunrepair@ 
		BATloopFast(b, p, q, xx) @:bunrepair@

		if (corrections) {
			BATloopFast(corrections, p, q, xx) {
				GDKerror("BATrepair(%s): corrected %d occurrences of illegal pos %d to nil.\n",
					b->batId, *(int*) BUNtloc(corrections,p), *(int*) BUNhloc(corrections,p));
			}
			BBPreclaim(corrections); 
			ret = FALSE;
		}
		GDKfree(hr.validmask);
	} else {
		GDKerror("BATrepair(%s): must correct *all* values to nil.\n", b->batId);
		HEAPfree(hp);
		ATOMheap(tpe, hp, BATcount(b));

		DELloop(b, p, q, xx) ATOMput(tpe, hp, (int*) BUNhloc(b,p), nilval);
		BATloopFast(b, p, q, xx) ATOMput(tpe, hp, (int*) BUNhloc(b,p), nilval);
		ret = FALSE;
	}
	return ret;
}

int BATrepair(BAT *b) {
	int ret = TRUE;
	if (b->hheap.base) ret &= atomrepair(b);
	if (b->theap.base) ret &= atomrepair(BATmirror(b));
	if (b->haccelerator.base) ret &= ACCrepair(b->hacctype, b, &b->haccelerator);
	if (b->taccelerator.base) ret &= ACCrepair(b->tacctype, BATmirror(b), &b->taccelerator);
	if (ret == FALSE) {
		b->batDirty = TRUE;
	}
	return ret;
}
@
@}
