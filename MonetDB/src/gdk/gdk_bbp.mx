@' The contents of this file are subject to the MonetDB Public
@' License Version 1.0 (the "License"); you may not use this file
@' except in compliance with the License. You may obtain a copy of
@' the License at
@' http://monetdb.cwi.nl/Legal/MonetDBLicense-1.0.html
@' 
@' Software distributed under the License is distributed on an "AS
@' IS" basis, WITHOUT WARRANTY OF ANY KIND, either express or
@' implied. See the License for the specific language governing
@' rights and limitations under the License.
@' 
@' The Original Code is the Monet Database System.
@' 
@' The Initial Developer of the Original Code is CWI.
@' Portions created by CWI are Copyright (C) 1997-2004 CWI.
@' All Rights Reserved.
@' 
@' Contributor(s):
@' 		Martin Kersten <Martin.Kersten@cwi.nl>
@' 		Peter Boncz <Peter.Boncz@cwi.nl>
@' 		Niels Nes <Niels.Nes@cwi.nl>
@' 		Stefan Manegold  <Stefan.Manegold@cwi.nl>

@f gdk_bbp
@a M. L. Kersten, P. Boncz, N. J. Nes
@* BAT Buffer Pool (BBP)
@T
The BATs created and loaded are collected in a BAT buffer pool.  

The Bat Buffer Pool has a number of functions:
\begin{description}

\item[administration and lookup]
Th BBP is a directory which contains status information about all known BATs. 
This interface may be used very heavily, by data-intensive applications.
To eliminate all overhead, read-only access to the BBP may be done by 
table-lookups. The integer index type for these lookups is @%bat@, as 
retrieved by @%BBPcacheid(b)@. The @%bat@ zero is reserved for the nil bat. 

\item[persistence]
The BBP is made persistent by saving it to the dictionary file 
called {\tt BBP.dir} in the database. The dictionary can always be 
reconstructed from the {\tt .desc} files. Its main role is to 
speed-up system restart, because now it requires just a few IOs 
instead of a complete directory scan and reading all descriptors
to find all BATs.

When the number of BATs rises, having all files in one directory
becomes a bottleneck.  The BBP therefore implements a scheme that distributes
alls BATs in a growing directory tree with at most 64 BATs stored in one node.

\item[buffer management]
The BBP is responsible for loading and saving of BATs to disk. It also 
contains routines to unload BATs from memory when memory resources 
get scarce. For this purpose, it administers BAT memory reference 
counts (to know which BATs can be unloaded) and BAT usage statistics 
(it unloads the least recently used BATs).

\item[recovery]
When the database is closed or during a run-time syncpoint, the system
tables must be written to disk in a safe way, that is immune for system 
failures (like disk full). To do so, the BBP implements an atomic commit and 
recovery protocol: first all files to be overwitten are moved to a BACKUP/
dir. If that succeeds, the writes are done. If that also fully succeeds
the BACKUP/ dir is renamed to DELETE\_ME/ and subsequently deleted.
If not, all files in BACKUP/ are moved back to their original location.

\item [unloading]
Bats which have a logical reference (ie. a lrefs > 0) but no memory
reference (refcnt == 0) can be unloaded. Unloading dirty bats means,
moving the original (commited version) to the BACKUP/ dir and saving
the bat. This complicates the commit and recovery/abort issues.
The commit has to check if the bat is already moved. And The recovery
has to always move back the files from the BACKUP/ dir.

\item [reference counting]
Bats use have two kinds of references: logical and physical (pointer) ones.
Both are administered with the BBPincref/BBPdecref routines. For 
backward compatability, we maintain BBPfix/BBPunfix as shorthands
for the adjusting the pointer references.

\item [share counting]
Views use the heaps of there parent bats. To save guard this, the
parent has a shared counter, which is incremented and decremented
using BBPshare and BBPunshare. These functions make sure the
parent is memory resident as required because of the 'pointer' sharing.
\end{description}
@h
#ifndef _GDK_BBP_H_
#define _GDK_BBP_H_
#include "gdk.h"

#define BBPINIT		2048
#define BBPMAXSIZE	1024*1024

#define BBPLOADED	1	/* set if bat in memory */
#define BBPSWAPPED	2	/* set if dirty bat is not in memory */
#define BBPTMP          4       /* set if non-persistent bat has image on disk */
#define BBPDELETED	16	/* set if bat persistent at last commit is now transient */
#define BBPEXISTING	32	/* set if bat was already persistent at end of last commit */
#define BBPNEW 		64	/* set if bat has become persistent since last commit */
#define BBPPERSISTENT	96      /* mask for currently persistent bats */
#define BBPSTATUS	127 

#define BBPUNLOADING	128 	/* set while we are unloading */
#define BBPLOADING	256 	/* set while we are loading */
#define BBPSAVING       512 	/* set while we are saving */
#define BBPWAITING      896	
#define BBPRENAMED	1024	/* set when bat is renamed in this transaction */

#define BBPTRIM_ALL	(((size_t)1) << (sizeof(size_t)*8 - 2)) /* very large positive size_t */
#define BBPLASTUSED(x)  ((x) & 0x7fffffff)  /* stamp is always a positive int */

gdk_export int  BBPin;	        /* BATs swapped into BBP  */
gdk_export int  BBPout;	        /* BATs swapped out of BBP */
gdk_export int  BBPsize;        /* current occupied size of BBP array */

/* global calls */ 
gdk_export void BBPinit      (void);
gdk_export void BBPexit      (void);
gdk_export int  BBPdir       (void);
 
/* update interface */ 
gdk_export void BBPclear     (bat bid);
gdk_export bat  BBPinsert    (BAT *b);
gdk_export void BBPcacheit   (BAT *b);
gdk_export void BBPuncacheit (bat bid, int unloaddesc);
gdk_export int  BBPreclaim   (BAT *b);
gdk_export int  BBPsave      (BAT *b);
gdk_export int  BBPrename    (bat bid, str nme);

gdk_export void BBP_insert(bat i);
gdk_export void BBP_delete(bat i);

/* query interface */ 
gdk_export bat  BBPindex     (str nme);
gdk_export BAT* BBPdescriptor(bat b);

/* swapping interface */ 
gdk_export void BBPrecover   (void);
gdk_export lng  BBPdiskscan  (void);
gdk_export int  BBPsync      (int commit);
gdk_export int  BBPincref    (bat b, int logical); 
gdk_export int  BBPdecref    (bat b, int logical);
gdk_export void BBPshare     (bat b);
gdk_export void BBPunshare   (bat b);
gdk_export int BBPresurrect (str name);
@
@c
#include "gdk.h"
#include "gdk_storage.h"

@- BBP global variables
The BBP has now a fixed address, so re-allocation due to a growing BBP 
caused by one thread does not disturb reads to the old entries by another.
This is implemented using anonymous virtual memory; extensions on the same 
address are guaranteed because a large non-committed VM area is requested 
initially. New slots in the BBP are found at O(1) by keeping a freelist
that uses the 'next' field in the BBPrec records.
@c
BBPrec*		BBP = NULL;		/* fixed base VM address of BBP array */
bat 		BBPmaxsize=BBPMAXSIZE;  /* size of non-commited VM BBP array */ 
bat 		BBPlimit = 0;		/* current committed VM BBP array */
bat		BBPsize = 0;		/* current used size of BBP array */ 
bat		BBP_free = 0;		/* first free slot in BBP array */

@- BBP hash index on name
the hash index uses a bucket index (int array) of size mask that is
tuned for perfect hashing (1 lookup). The bucket chain uses the 'next'
field in the BBPrec records.
@h
#define BBPnamecheck(s) (((s)[0]=='t' && (s)[1]=='m' && (s)[2]=='p' &&\
			  (s)[3]=='_')?atoi(s+4):0)

@c
bat*		BBP_hash = NULL;	/* BBP logical name hash buckets */
bat		BBP_mask = 0;		/* number of buckets = & mask */

#ifdef NATIVE_WIN32
#define LLFMT "%I64d"
#else
#define LLFMT "%lld"
#endif

static void BBPspin(bat bid, str debug, int event);
static int BBPfree(BAT *b);


void BBP_insert(bat i) {
	bat idx = (bat) (strHash(BBP_logical(i)) & BBP_mask);
	BBP_next(i) = BBP_hash[idx]; 
	BBP_hash[idx] = i;
} 

void BBP_delete(bat i) {
	bat *h = BBP_hash;
	str s = BBP_logical(i);
	bat idx = (bat) (strHash(s) & BBP_mask);

	for(h+=idx; (i=*h) != 0 ; h=&BBP_next(i)) {
		if (strcmp(BBP_logical(i), s) == 0) {
			*h = BBP_next(i); break;
		}
	}
} 

@-
other globals
@c
int		BBP_curstamp = 0; 	/* unique stamp for creation of a bat */
MT_Id		BBP_notrim = ~((MT_Id) 0);/* avoids BBPtrim when we really do not want it */
int		BBP_dirty = 0;		/* BBP structures modified? */
int		BBPin = 0;		/* bats loaded statistic */
int		BBPout = 0;		/* bats saved statistic */

@-
we put a simple limit of (BBPLOCKMASK+1)*BBP_desc_max (= 8192, currently) to the number
of BAT descriptors that can be cached. Reason is that each descriptor takes 1K, and big
DD repositories that are "in the air" for a long time may have hundreds of thousands
of BATs. While that is really a DD problem, this causes say 100MB of memory consumption
in the heap, which especially on NT can cause the heap to overflow.

We actually use multiple counters, because the BBPcacheit()/BBPuncacheit() that implement
this already hold the GDKswaplock, which is multiplexed on bat-id&BBPLOCKMASK. By having
one counter for each lock-group, we do not have to set/unset a lock for updating the count.

The swap algorithm is simple FIFO, which is not optimal, of course..
@h
extern int      BBP_desc_max, BBP_desc_count[BBPLOCKMASK+1];
@c
int             BBP_desc_max = 1024;
int             BBP_desc_count[BBPLOCKMASK+1] = {0};


@+ BBP Consistency and Concurrency
@T
While GDK provides the basic building blocks for an ACID system, in
itself it is not such a system, as we this would entail too much overhead
that is often not needed. Hence, some consistency control is left to the
user. The first important user constraint is that if a user updates a 
BAT, (s)he himself must assure that no-one else accesses this BAT. 

Concerning buffer management, the BBP carries out a swapping policy.
BATs are kept in memory till the memory is full. If the memory is full,
the malloc functions initiate BBP trim actions, that unload the coldest BATs 
that have a zero reference count. The second important user constraint 
is therefore that a user may only manipulate live BAT data in memory if it 
is sure that there is at least one reference count to that BAT.

The main BBP array is protected by two locks:
\begin{description}
\item[GDKcacheLock] 
this lock guards the free slot management in the BBP array.  The BBP 
operations that allocate a new slot for a new BAT (@%BBPinit@,@%BBPcacheit@), 
delete the slot of a destroyed BAT (@%BBPreclaim@), or rename a BAT 
(@%BBPrename@), hold this lock. It also protects all BAT (re)naming actions 
include (read and write) in the hash table with BAT names.
\item[GDKswapLock]
this lock guards the swap (loaded/unloaded) status of the BATs. Hence, all
BBP routines that influence the swapping policy, or actually carry out the
swapping policy itself, acquire this lock (e.g. @%BBPfix@,@%BBPunfix@).
Note that this also means that updates to the BBP\_status indicator array
must be protected by GDKswapLock. 

To reduce contention GDKswapLock was split into multiple locks; it is now 
an array of lock pointers which is accessed by GDKswapLock[ABS(bat)\&BBPLOCKMASK]
\end{description}

Routines that need both locks should first acquire the locks in the GDKswapLock 
array (in ascending order) and then GDKcacheLock (vz release them in reverse order).

To obtain maximum speed, read operations to existing elements in the BBP are 
unguarded. As said, it is the users responsability that the BAT that is being 
read is not being modified. BBP update actions that modify the BBP data structure 
itself are locked by the BBP functions themselves. Hence, multiple concurrent BBP read 
operations may be ungoing while at the same time at most one BBP write operation 
{\bf on a different BAT} is executing.  This holds for accesses to the public (quasi-)
arrays @%BBPcache@, @%BBPstatus@, @%BBPrefs@, @%BBPlogical@ and @%BBPphysical@. These 
arrays are called quasi as now they are actually stored together in one big BBPrec 
array called BBP, that is allocated in anonymous VM space, so we can reallocate 
this structure without changing the base address (a crucial feature if read 
actions are to go on unlocked while other entries in the BBP may be modified). 
@h
#define BBP_status_set(bid, mode, nme) {				\
		MT_set_lock(GDKstatusLock[(bid)&BBPLOCKMASK], nme); 	\
		BBP_status(bid) = mode;					\
		MT_unset_lock(GDKstatusLock[(bid)&BBPLOCKMASK], nme);	\
}

#define BBP_status_on(bid, flags, nme) \
		BBP_status_set(bid, BBP_status(bid) | flags, nme);

#define BBP_status_off(bid, flags, nme) \
		BBP_status_set(bid, BBP_status(bid) & ~(flags), nme);

#define BBP_unload_on(bid, nme) {						\
		MT_set_lock(GDKunloadLock, nme);				\
		if (BBPunloadCnt++ == 0) MT_set_lock(GDKunloadBarrier, nme);	\
		MT_unset_lock(GDKunloadLock, nme);				\
		BBP_status_on(bid, BBPUNLOADING, nme);				}

#define BBP_unload_off(bid, nme) {						\
		BBP_status_off(bid, BBPUNLOADING, nme);				\
		MT_set_lock(GDKunloadLock, nme);				\
		if (--BBPunloadCnt == 0) MT_unset_lock(GDKunloadBarrier, nme);	\
		MT_unset_lock(GDKunloadLock, nme);				}
@c
static MT_Id locked_by = 0;

static MT_Id BBP_getpid(void){
	MT_Id x = MT_getpid();
	return x;
}

static int BBPunloadCnt=0; 

void BBPlock(str nme) {
	int i;
	MT_set_lock(GDKtrimLock, nme);
	BBP_notrim = BBP_getpid();
	MT_set_lock(GDKcacheLock, nme);
	for(i=0; i<=BBPLOCKMASK; i++)
		MT_set_lock(GDKswapLock[i&BBPLOCKMASK], nme);
	locked_by = BBP_notrim;

	/* wait for all pending unloads to finish */
	MT_set_lock(GDKunloadBarrier, nme);
	MT_unset_lock(GDKunloadBarrier, nme);
}

void BBPunlock(str nme) {
	int i;
	for(i=BBPLOCKMASK; i>=0;  i--)
		MT_unset_lock(GDKswapLock[i&BBPLOCKMASK], nme);
	MT_unset_lock(GDKcacheLock, nme);
	BBP_notrim = 0;
	locked_by = 0;
	MT_unset_lock(GDKtrimLock, nme);
}


void BBPinithash(void) {
	bat i = BBPsize; 

	for(BBP_mask=1; (BBP_mask<<1) <= BBPlimit; BBP_mask<<=1);
	BBP_hash = (bat*) GDKmalloc(BBP_mask*sizeof(bat));
	memset(BBP_hash, 0, BBP_mask*sizeof(bat));
	BBP_mask--;

	while(--i > 0) {
		if (BBP_logical(i)) {
			if (BBPnamecheck(BBP_logical(i)) == 0) {
				BBP_insert(i);
			}
			if (BBP_logical(-i)) {
				BBP_insert(-i);
			}
		} else { 
			BBP_next(i) = BBP_free;	
			BBP_free = i;
		}
	}
}

void BBPextend(dbl factor, int buildhash) {
	int newsize = (int) (BBPlimit*factor);
	size_t maxsize = MAX(newsize*2,BBPmaxsize)*sizeof(BBPrec);

	BBP = (BBPrec*) GDKvmrealloc(BBP, BBPlimit*sizeof(BBPrec), newsize*sizeof(BBPrec), 
				     BBPmaxsize*sizeof(BBPrec), &maxsize); 
	if (BBP == NULL) GDKfatal("BBPextend failed\n");

    	memset(BBP+BBPlimit, 0, (newsize-BBPlimit)*sizeof(BBPrec));
	BBPlimit = newsize;
	BBPmaxsize = (int) (maxsize/sizeof(BBPrec));

	if (buildhash) {
		GDKfree(BBP_hash);	
		BBP_hash=NULL;
    		BBP_free = 0;
		BBPinithash();
	}
}

static INLINE
char *BBPparse(str *cur) {
	char *base, *c=*cur;
	
	for(c++; GDKisspace(*c); c++) ;
	for(base = c; !(GDKisspace(*c) || *c == ','); c++) ;
	*c = 0; *cur = c;
	return base;
}

@T
In order to start, we read the BBP.dir in the bat/ directory, BUT:
- if there is a BACKUP/ directory, we try to use that 
- if BBP.dir is lost, we try BBP.bak 
- if we do not use the original BBP.dir; move the previous to BBP.bak
@c
static int backuped_files;

static int prepare_backup(void) {
	int ret = 0;
	if (backuped_files == 0) {
		struct stat st;
		ret = GDKremovedir(DELDIR); /* remove previous DELETE_ME dir */
		if (ret == 0) {
			if (stat(BAKDIR, &st) == 0) {
				BBPrecover(); /* BAKDIR still exists, must finish recover first! */ 
			}
			ret = mkdir(BAKDIR, 0755);
			IODEBUG THRprintf(GDKerr, "mkdir %s = %d\n", BAKDIR, ret); 
		}
	} 
	if (ret == 0) backuped_files++;
	return ret;
}
	

void BBPinit(void) {
	FILE	*fp = GDKfilelocate("BBP", "rb", "dir");
	DIR     *recover = opendir(BAKDIR);
	char	*c, buffer[3000];
	int	ret, i=0, debug=GDKdebug;
	oid	BBPoid = 0;
	char	logical[1024], batname[1024];
	char	path[1024];
	int     max_stamp = 0, min_stamp = 0x7fffffff;
     
	/* try to obtain a BBP.dir */
	GDKfilepath(path, BATDIR, "BBP", "bak");
	if (recover) {
		/* if a BACKUP/ dir exist, we *MUST* use it */

		/* the recover is now the default as bat's get unloaded/mmaped
		   during transactions into the main BATDIR */
		if (fp) {
			fclose (fp);
			ret = unlink(path);
			THRprintf(GDKerr, "unlink %s = %d\n", path, ret);
			ret = GDKmove(BATDIR,"BBP","dir", BATDIR,"BBP","bak"); 
		}
		ret = GDKmove(BAKDIR,"BBP","dir", BATDIR,"BBP","dir");
		fp = ret?NULL:GDKfilelocate("BBP", "rb", "dir");
	}
	if (fp == NULL) {
		/* try to use a BBP.bak */
		struct stat st;
		if (stat(path, &st) == 0) {
			GDKwarning("BBPinit: reverting to dir saved in BBP.bak.\n");
			ret = GDKmove(BATDIR,"BBP","bak", BATDIR,"BBP","dir");
			fp = ret?NULL:GDKfilelocate("BBP", "rb", "dir");
		}
	}
	if ( fp == NULL) {
		/* give up: create an empty one */
		GDKwarning("BBPdir: initializing BBP.\n");
        	BBPdir();
		fp = GDKfilelocate("BBP", "rb", "dir");
	}
	if ( fp == NULL) {
		/* now it is time for real panic */
		GDKfatal("BBPinit: could not write %sBBP.dir\n", BATDIR); 
	}
	GDKdebug = debug;


	/* scan the BBP.dir to obtain its current size */
	BBPlimit = BBPINIT;
	BBPsize = 1;
	if ((c = fgets(buffer, 3000, fp)) != NULL){
		BBPoid = OIDread(c); 
		if ((c = strstr(c, "BBPsize")) != NULL) {
			sscanf(c, "BBPsize=%d", &i);
			i = (int) (i*BATMARGIN);
			if (i > BBPlimit) BBPlimit=i;
		} 
	}

    
	/* alloc structures; try to reserve as much space as possible */
	for (;;) {
		size_t size = (size_t) BBPlimit*sizeof(BBPrec);
		size_t maxsize = (size_t) BBPmaxsize*sizeof(BBPrec);

		BBP = (BBPrec*) GDKvmalloc(size, &maxsize);
		MT_alloc_register(BBP, maxsize, 'P');
		if (BBP && maxsize >= BBPmaxsize*sizeof(BBPrec)) {
			BBPmaxsize = (int) (maxsize/sizeof(BBPrec));
			break;
		}
		MT_alloc_register(BBP, maxsize, 'p');
		if (BBP) GDKvmfree(BBP, size, maxsize);
		if ((BBPmaxsize/=2) < BBPlimit) {
			GDKfatal("BBPinit: could not alloc arena\n"); 
		}
	} 
	memset(BBP, 0, BBPlimit*sizeof(BBPrec));

	/* scan the BBP.dir, and insert the BATs into the BBP */
	while((c = fgets(buffer, 3000, fp)) != NULL) {
		int j = 0;	
		while (*c != '[') c++;
		for (c++; GDKisspace(*c); c++ ) ;
		i = atoi(c);
		if (GDKisdigit(*c) &&  i > 0 ) {
			for(c++; *c != ','; c++) ;
			for(c++; GDKisspace(*c); c++ ) ;
			j = atoi(c);
			if (!GDKisdigit(*c) ) c--;
			else for(c++; *c != ','; c++) ;
		} else {
			GDKerror("BBPinit: ignore line %s\n", buffer);
			continue;
		}
		if ( i >= BBPsize) {
			BBPsize = i+1;
			if (BBPsize >= BBPlimit) BBPextend(BATMARGIN,FALSE);
		}
		strcpy(batname, BBPparse(&c));
		BBP_status_set(i, BBPEXISTING | (j & ~(BBPLOADED|BBPNEW)), "BBPinit");
		BBP_physical(i) = GDKstrdup(BBPparse(&c)); 
		BBP_lastused(i) = BBPLASTUSED(atoi(BBPparse(&c)));
		if (BBP_lastused(i) > max_stamp) max_stamp = BBP_lastused(i);
		if (BBP_lastused(i) < min_stamp) min_stamp = BBP_lastused(i);
		BBP_lrefs(i) = 0;
		BBP_lrefs(i) = 1; /* any BAT we encounter here is persistent, so has a logical reference */
		c = strchr(batname, '~');
		if (c && c == batname) {
			sprintf(logical, "tmp_%d", i);
		} else {
			if (c) *c = 0;
			strcpy(logical, batname); j++;
		}
		BBP_logical(i) = GDKstrdup(logical);
		i = -i;
		if (c && c[1]) {
			BBP_logical(i) = GDKstrdup(c+1); j++;
		} else {
			BBP_logical(i) = NULL;
		}
	} 
	fclose(fp); 

	/* normalize saved LRU stamps */
	if (min_stamp <= max_stamp) {
		for(i=1; i<BBPsize; i++)
			if (BBP_logical(i))
				BBP_lastused(i) -= min_stamp; 
		GDKsetstamp(max_stamp - min_stamp);
	}

	/* init hash table */
	BBPinithash();
	BBP_notrim = 0;

	if (BBPoid == 0) {
		OIDseed(OIDrand()); /* if not yet done, init oid */
	}
	if (recover) {
		closedir(recover);
		BBPrecover(); /* move files to the LEFTOVER/ dir */ 
	}

	/* cleanup any leftovers */
	BBPdiskscan(); 

	ret = prepare_backup();
	if (!ret){
		/* always move the BBP.dir to the BAKDIR, as unloads
		   and mmap's can happen at any time during a transaction
		 */
		ret = GDKmove( BATDIR,"BBP","dir", BAKDIR,"BBP","dir" );
	}
}

@- 
During the exit phase all non-persistent BATs are removed.
Upon exit the status of the BBP tables is saved on disk.
This function is called once and during the shutdown of the
server. Since shutdown may be issued from any thread (dangerous)
it may lead to interference in a parallel session.
@c

void BBPexit(void)
{
	bat  i;

	if (!BBP) return; /* AARGH */

	BBPlock("BBPexit"); /* stop all threads ever touching more descriptors */

	/* free all memory (just for leak-checking in Purify) */
	for(i=0; i<BBPsize; i++) {
		if (BBP_logical(i)) {
			BAT *b = BBP_cache(i);
			if (b) BATfree(b);
			BBPuncacheit(i,TRUE);
			GDKfree(BBP_logical(i));
		}
		if( BBP_physical(i)){
			GDKfree(BBP_physical(i));
			BBP_physical(i)=0;
		}
	}
	GDKfree(BBP_hash);
	BBP_hash= 0;
}

@-
The routine @%BBPdir@ creates the BAT pool dictionary file. 
It includes some information about the current state of affair in the pool.
The location in the buffer pool is saved for later use as well.
This is merely done for ease of debugging and of no importance to front-ends.
The tail of non-used entries is reclaimed as well. 
@c
static int new_bbpentry(stream *s, bat i) {
	int r = stream_printf(s, "[  %d, %d, %s", 
			(int) i, BBP_status(i)&BBPSTATUS, BBP_logical(i));
	if (r < 0) return r;
	if (BBP_logical(-i)) {
		r = stream_printf(s,"~%s", BBP_logical(-i));
		if (r < 0) return r;
	}
	return stream_printf(s, ", %s, %d ]\n", 
		BBP_physical(i), BBP_lastused(i));
}

int BBPdir(void) {	
	FILE *fp = NULL;
	stream *s = NULL;
	bat i;

	if (GDKdebug&17)
	THRprintf(GDKerr, "#BBPdir: writing BBP.dir (%d bats).\n", (int) BBPsize);
	IODEBUG {
		THRprintf(GDKerr, "BBPdir start oid=");
		OIDwrite(GDKerr);
		THRprintf(GDKerr, "\n");
	}
	fp = (FILE*) GDKfilelocate("BBP", "wb", "dir"); 
	if (fp)
		s = file_wastream(fp, "BBP.dir");
	if (s == NULL || OIDwrite(s) || 
	    stream_printf(s, " BBPsize=%d\n", (int) BBPsize) < 0) goto error;

	for (i = 1; i < BBPsize; i++)
	  if (BBP_status(i) & BBPPERSISTENT) {
	    if (new_bbpentry(s, i) < 0) goto error;
	    IODEBUG new_bbpentry(GDKerr, i);
	  }

	stream_close(s);
	stream_destroy(s);
	IODEBUG THRprintf(GDKerr, "BBPdir end\n");
	return 0;
error:	GDKsyserror("BBPdir failed:\n"); 
	return -1;
}

@+ BBP Readonly Interface

These interface functions do not change the BBP tables. If they only
access one specific BAT, the called must have ensured that no other thread
is modifying that BAT, therefore such functions do not need locking.
@- 
BBP index lookup by BAT name:
@c
static INLINE 
bat BBP_find(str nme, int lock) {
	bat i = BBPnamecheck(nme);
	if (i > 0) {
		/* for tmp_X BATs, we already know X */
		str s = BBP_logical(i);
		if (i >= BBPsize || s == NULL || strcmp(s,nme)) {
			i = 0;
		} 
	} else {
		/* must lock since hash-lookup traverses other BATs */
		if (lock) MT_set_lock(GDKcacheLock, "BBPindex");
		for(i=BBP_hash[strHash(nme)&BBP_mask]; i; i=BBP_next(i)) {
			if (strcmp(BBP_logical(i), nme) == 0) break;
		}
		if (lock) MT_unset_lock(GDKcacheLock, "BBPindex");
	}
	return i;
}

bat BBPindex(str nme) {
	return BBP_find(nme, TRUE);
}

BATstore* BBPgetdesc(bat i) {
        MT_Id pid = BBP_getpid();
	BAT *b = NULL;

	if (i < 0) i = -i;
	if (i) {
		str nme = BBP_physical(i);
        	b = BBP_cache(i);
        	if (b == NULL) {
			b = (BAT*) BBP_desc(i);
		}
    		if (b == NULL && nme) { 
                	b = (BAT*) BATloaddesc(nme);
			if (b == NULL) {
				GDKerror("BBPgetdesc: deleting illegal bat(%d) %s\n", i, nme);
				BBPclear(i);
			} else if (BBP_desc(i) == NULL) {
				if (pid != locked_by) 
					MT_set_lock(GDKswapLock[i&BBPLOCKMASK], "BBPgetdesc");
				BBP_desc(i) = (BATstore*) b;
				BBP_desc_count[i&BBPLOCKMASK]++;
				if (pid != locked_by) 
					MT_unset_lock(GDKswapLock[i&BBPLOCKMASK], "BBPgetdesc");
                        }
		}
		if (b) BBP_lastused(i) = BBPLASTUSED(GDKstamp());
    	}
	return (BATstore*) b;
}


str BBPlogical(bat bid, str buf) {
	if (buf == NULL) {
		 return NULL;
	} else if (BBPcheck(bid, "BBPlogical")) {
        	if (bid < 0 && BBP_logical(bid) == NULL) bid= -bid;
		strcpy(buf, BBP_logical(bid));
	} else {
		*buf = 0;
	}
	return buf;
}

str BBPphysical(bat bid, str buf) {
	if (buf == NULL) {
		 return NULL;
	} else if (BBPcheck(bid, "BBPphysical")) {
		strcpy(buf, BBP_physical(ABS(bid)));
	} else {
		*buf = 0;
	}
	return buf;
}


@+ BBP Update Interface
Operations to insert, delete, clear, and modify BBP entries.
Our policy for the BBP is to provide unlocked BBP access for 
speed, but still write operations have to be locked.

#ifdef DEBUG_THREADLOCAL_BATS
Create the shadow version (reversed) of a bat.
@c
BAT *BBPmirror(BAT *b)
{
	BAT *bn = (BAT*) GDKmalloc(sizeof(BAT));
	BBP_cache(-b->batCacheid) = bn;
	bn->GDKversion = b->GDKversion;
	bn->batId = b->batId;
	bn->batCacheid = -b->batCacheid;
	bn->batBuns = b->batBuns;
	bn->dims.headtype = b->dims.tailtype;
	bn->dims.tailtype = b->dims.headtype;
	bn->dims.headloc = b->dims.tailloc; 
	bn->dims.tailloc = b->dims.headloc; 
	bn->dims.headkey = b->dims.tailkey;
	bn->dims.tailkey = b->dims.headkey;
	bn->dims.headvarsized = b->dims.tailvarsized;
	bn->dims.tailvarsized = b->dims.headvarsized;
	bn->dims.bunwidth = b->dims.bunwidth;
	bn->dims.bunshift = b->dims.bunshift;
	bn->dims.hseq = b->dims.tseq;
	bn->dims.tseq = b->dims.hseq;
	bn->H = b->T; bn->T = b->H;
	bn->P = b->P; bn->U = b->U; 
	bn->hhash_heap = b->thash_heap; 
	bn->thash_heap = b->hhash_heap;
	bn->hidx_heap = b->tidx_heap; 
	bn->tidx_heap = b->hidx_heap;
	return bn;
}
@- 
An existing BAT is inserted into the BBP 
@c
static INLINE
str BBPsubdir_recursive(str s, bat i) {
	i >>= 6;
	if (i >= 64) {
		s = BBPsubdir_recursive(s, i);
	} i &= 63;
	*s++ = '0' + (i>>3);
	*s++ = '0' + (i&7);
	*s++ = DIR_SEP;
	return s;
}

static INLINE
void BBPgetsubdir(str s, bat i) {
	if (i >= 64) {
	    s = BBPsubdir_recursive(s, i);
	} *s = 0;
}

static INLINE
bat BBPgetentry(void) {
	bat i;
	/* find an empty slot */
	if (BBP_free <= 0) {
		if (++BBPsize >= BBPlimit) BBPextend(BATMARGIN,TRUE);
		else BBP_free = BBPsize-1;
	} 
	i = BBP_free; 
	BBP_free = BBP_next(BBP_free);
	return i;
}

bat BBPinsert(BAT *b) {
	MT_Id pid = BBP_getpid();
	long_str dirname;
	bat i;
		
        if (pid != locked_by) {
                MT_set_lock(GDKcacheLock, "BBPinsert");
        }
 	i = BBPgetentry();
	sprintf(b->batId, "tmp_%d", (int)i); /* make a unique temporary name */
	BBPgetsubdir(dirname, i);

	if (++BBP_curstamp < 0) BBP_curstamp = 0;
        b->batCacheid = i;
        b->batStamp = BBP_curstamp;
        b->creator_tid = pid;

	BBP_status_set(i, 0, "BBPentry");
	BBP_cache(i) = NULL;
	BBP_desc(i) = NULL;
        BBP_refs(i) = 1; /* new bats have 1 pin */
	BBP_lrefs(i) = 0; /* ie. no logical refs */
       	BBP_logical(i) = GDKstrdup(b->batId);
       	BBP_logical(-i) = NULL;
	BBP_physical(i) = (str) GDKmalloc(strlen(dirname) + strLen(b->batId) - 4);
	GDKfilepath(BBP_physical(i), dirname, b->batId+4, NULL);

        BATDEBUG THRprintf(GDKerr, "%d = new %s(%s,%s)\n", 
				(int) i, b->batId, ATOMname(b->htype), ATOMname(b->ttype));
        if (pid != locked_by) {
                MT_unset_lock(GDKcacheLock, "BBPinsert");
        }
	return i;
}

void BBPcacheit(BAT* b) {
	MT_Id pid = BBP_getpid();
        bat i = 0;
	int mode;
        BAT *bm;

        if (pid != locked_by) {
                MT_set_lock(GDKtrimLock, "BBPcacheit");
                BBP_notrim = pid;
        }
        if (b->batId[0]) {
                i = b->batCacheid;
        } else {
                i = BBPinsert(b); /* bat was not previously entered */
        }
        if (pid != locked_by) {
                MT_set_lock(GDKswapLock[i&BBPLOCKMASK], "BBPcacheit");
        }
	mode = (BBP_status(i) | BBPLOADED) & ~BBPWAITING;
	BBP_status_set(i, mode, "BBPcacheit");
        BBP_lastused(i) = BBPLASTUSED(GDKstamp() + ((mode==BBPLOADED)?150:0));
        if (BBP_desc(i) == NULL) BBP_desc_count[ABS(i)&BBPLOCKMASK]++;
        BBP_cache(i) = b;
        BBP_cache(-i) = bm = BBPmirror(b);
        BBP_desc(i) = (BATstore*) ((i>0)?b:bm);

        if (pid != locked_by) {
                MT_unset_lock(GDKswapLock[i&BBPLOCKMASK], "BBPcacheit");
                BBP_notrim = 0;
                MT_unset_lock(GDKtrimLock, "BBPcacheit");
        }
}

@
@%BBPuncacheit@ changes the BBP status to swapped out.  Currently only 
used in BBPfree (bat swapped out) and BBPclear (bat destroyed forever).
@c
void BBPuncacheit(bat i, int unloaddesc) {
	MT_Id pid = BBP_getpid();
	if (i < 0) i = -i;
	if (BBPcheck(i, "BBPuncacheit")) {
		BAT *b = BBPcache(i);
		if (pid != locked_by) 
			MT_set_lock(GDKswapLock[i&BBPLOCKMASK], "BBPuncacheit");
		if (b) {
			BATDEBUG {
				THRprintf(GDKerr, "uncache %d (%s)\n", (int) i, BBP_logical(i)); 
			}
			if (unloaddesc || BBP_desc_count[i&BBPLOCKMASK] > BBP_desc_max) {
				BBP_desc_count[i&BBPLOCKMASK]--;
				GDKfree(BBP_desc(i));
				BBP_desc(i) = NULL;
			}
		}
		BBP_cache(i) = BBP_cache(-i) = NULL; 
		BBP_status_off(i, BBPLOADED, "BBPuncacheit");
		if (pid != locked_by) 
			MT_unset_lock(GDKswapLock[i&BBPLOCKMASK], "BBPuncacheit");
	}
}

@- BBP delete
@%BBPclear@ removes a BAT from the BBP directory forever.
@c
void BBPclear(bat i) {
	MT_Id pid = BBP_getpid();

	if (BBPcheck(i, "BBPclear")) {
		i = ABS(i);
		if (pid != locked_by) 
			MT_set_lock(GDKcacheLock, "BBPclear"); 
		BATDEBUG {
			THRprintf(GDKerr, "clear %d (%s)\n", (int) i, BBP_logical(i)); 
		}
		BBPuncacheit(i, TRUE);
		if (BBPnamecheck(BBP_logical(i)) == 0) {
			BBP_delete(i);
		} 
		if (BBP_logical(-i)) {
			BBP_delete(-i);
			GDKfree(BBP_logical(-i));
			BBP_logical(-i) = NULL;
		}
		GDKfree(BBP_logical(i));
		BBP_logical(i) = NULL;
		GDKfree(BBP_physical(i));
		BBP_physical(i) = NULL;
		BBP_status_set(i, 0, "BBPclear");
		BBP_refs(i) = 0; 
		BBP_lrefs(i) = 0; 
		BBP_next(i) = BBP_free;	
		BBP_free = i;
		if (pid != locked_by) 
			MT_unset_lock(GDKcacheLock, "BBPclear"); 
	}
}

static
void BBPspin(bat i, str s, int event) {
	if (BBPcheck(i,"BBPspin") && (BBP_status(i)&event)) {
		lng spin = LL_CONSTANT(0);
		while(BBP_status(i)&event) { 
			MT_sleep_ms(1);
			spin++;
		}
		BATDEBUG THRprintf(GDKout, "BBPspin(%d,%s,%d): " LLFMT " loops\n", (int) i, s, event, spin);
	}
}

@- BBP rename
The default logical name of a BAT is tmp_X, where X is the batCacheid.

Each BAT has a logical name that is globally unique. Its reverse view can
also be assigned a name, that also has to be globally unique. The batId is 
often the same as the logical BAT name, but can in fact be different as it
does not have to be globally unique. The batId is used as column name when
printing multi-column tables from multiple BATs. Given that role, it clearly 
is not always unique.

Apart from being globally unique, new logical bat names cannot be of the 
form tmp_X, unless X is the batCacheid.

Physical names consist of a directory name followed by a logical name suffix. 
The directory name is derived from the batCacheid, and is currently organized 
in a hierarchy that puts max 64 bats in each directory (see BBPgetsubdir). 

Concerning the physical suffix: it is almost always bat_X. This saves us
a whole lot of trouble, as bat_X is always unique and no conflicts can occur.
Other suffixes are only supported in order just for backward compatibility with 
old repositories (you won't see them anymore in new repositories).
@c
int BBPrename(bat bid, str nme) {
	BAT *b = BBPdescriptor(bid);
	long_str dirname;
	bat tmpid=0,i;

	if (b == NULL) return 0;

	/* If name stays same, do nothing */
	if(BBP_logical(bid) && strcmp(BBP_logical(bid),nme) == 0)
		return 0;

	BBPgetsubdir(dirname, ABS(bid));

	strncpy(b->batId,nme,IDLENGTH); /* batId is private, nonunique ID */
	b->batId[IDLENGTH-1]=0;
	if ((tmpid=BBPnamecheck(nme)) && (bid < 0 || tmpid != bid)){
		return BBPRENAME_ILLEGAL;
	}
        if (strlen(dirname) + strLen(nme) >= IDLENGTH) {
		return BBPRENAME_LONG;
        }
	MT_set_lock(GDKtrimLock, "BBPrename"); 
	MT_set_lock(GDKcacheLock, "BBPrename"); 
 	i = BBP_find(nme, FALSE);
 	if (i != 0) {
		MT_unset_lock(GDKcacheLock, "BBPrename"); 
		MT_unset_lock(GDKtrimLock, "BBPrename"); 
		return BBPRENAME_ALREADY;
	} 
	BBP_notrim = BBP_getpid();

	/* carry through the name change */
	if (BBP_logical(bid) && BBPnamecheck(BBP_logical(bid)) == 0) {
		BBP_delete(bid);
	}
	GDKfree(BBP_logical(bid));
	BBP_logical(bid) = GDKstrdup(nme); 
	if (tmpid == 0) {
		BBP_insert(bid);
	}
	b->batDirtydesc = 1;
        if (b->batPersistence == PERSISTENT) {
		BBP_status_on(ABS(bid), BBPRENAMED, "BBPrename");
		BBPdirty(1);
	}
	MT_unset_lock(GDKcacheLock, "BBPrename"); 
	BBP_notrim = 0;
	MT_unset_lock(GDKtrimLock, "BBPrename"); 
	return 0;
}

@+ BBP swapping Policy
The BAT can be moved back to disk using the routine @%BBPfree@.
It frees the storage for other BATs. After this call BAT* references
maintained for the BAT are wrong.
We should keep track of dirty unloaded BATs. They may have to be committed
later on, which may include reading them in again.
@
BBPswappable: may this bat be unloaded?
Only real bats without memory references can be unloaded.
@h
#define BBPswappable(b) ((b) && BBP_refs((b)->batCacheid) == 0)
#define BBPtrimmable(b) (BBPswappable(b) && VIEWparent(b) == 0 && (BBP_status((b)->batCacheid)&BBPWAITING) == 0)
#define BBPdesctrimmable(bid) (BBP_desc(bid) != NULL && BBP_refs(bid) == 0 && (BBP_status(bid)&BBPWAITING) == 0)

#endif /* _GDK_BBP_H_ */
@- 
The @%BBP_ref@ contains the amount of live references to a BAT.
These might be in recursive BATs, C or MIL variables.  The count is 
incremented with @%BBPfix@ and decremented with @%BBPunfix@.
@c
int BBPincref(bat i, int logical) {
	MT_Id pid = BBP_getpid();
	int refs = 0;

	if (i == bat_nil) {
		/* Stefan: May this happen? Or should we better call GDKerror(), here? */
		/* GDKerror("BBPincref() called with bat_nil!\n"); */
		return refs;
	}
	if (i < 0) i = -i;
	if (i < BBPsize && BBP_logical(i)) { /* no BBPcheck as BBPresurrect should not provoke an GDKerror */
		for (;;) {
			if (pid != locked_by) 
				MT_set_lock(GDKswapLock[i&BBPLOCKMASK], "BBPincref"); 
			if (BBP_status(i) & BBPUNLOADING) { /* must wait for unload, then reload */
				if (pid != locked_by) 
					MT_unset_lock(GDKswapLock[i&BBPLOCKMASK], "BBPincref spin wait"); 
				BBPspin(i, "BBPincref", BBPWAITING);
			} else { 
				break;
			}
		}
		/* got the lock; but BBPresurrect must be prepared that the bat was destroyed in the meantime */
                if (BBP_logical(i)) { 
			if (logical) {
				refs = ++BBP_lrefs(i);
			} else {
				refs = ++BBP_refs(i);
			}
		}
		if (pid != locked_by) 
			MT_unset_lock(GDKswapLock[i&BBPLOCKMASK], "BBPfix"); 
	}
	return refs;
}

int BBPdecref(bat i, int logical) {
	MT_Id pid = BBP_getpid();
	int refs = 0, swap = 0;
	BAT *b;

	if (BBPcheck(i, "BBPdecref") == 0) {
		return -1;
	}
	if (i < 0) i = -i;
        if(pid != locked_by) 
		MT_set_lock(GDKswapLock[i&BBPLOCKMASK], "BBPdecref");

	/* decrement references by one */
	if (logical) {
		if (BBP_lrefs(i) == 0) {
			GDKerror("BBPdecref(%s) does not have logical references.\n", BBPname(i));
		} else {
			refs = --BBP_lrefs(i);
		}
	} else {
		if (BBP_refs(i) == 0) {
			GDKerror("BBPdecref(%s) does not have pointer fixes.\n", BBPname(i));
		} else {
			refs = --BBP_refs(i);
		}
	}

	/* we destroy transients asap and unload persistent bats only if they have been made cold */
	b = BBP_cache(i);
	if (BBP_refs(i) > 0 || (BBP_lrefs(i) > 0 && BBP_lastused(i) != 0)) {
		/* bat cannot be swapped out. renew its last usage stamp for the BBP LRU policy */
		int sec = BBPLASTUSED(GDKstamp());
		if (sec > BBPLASTUSED(BBP_lastused(i))) BBP_lastused(i) = sec;
        } else if (b && b->batKeeparound == TRUE) {
                /* bat could have been swapped out but user requested not to do so. Also renew its last usage stamp. */
                MEMDEBUG THRprintf(GDKerr, "BBPdecref: keeping %s for resurrection (mode=%d).\n", BBPname(b->batCacheid), b->batPersistence);
                BBP_lastused(i) = BBPLASTUSED(GDKstamp());
	} else if (b || (BBP_status(i)&BBPTMP)) {
		/* bat will be unloaded now. set the UNLOADING bit while locked so no other thread thinks its available anymore */
		BBP_unload_on(i, "BBPdecref");
		swap = TRUE;
	}
        
	/* unlock before re-locking in unload; as saving a dirty persistent bat may take a long time */
	if (pid != locked_by) 
		MT_unset_lock(GDKswapLock[i&BBPLOCKMASK], "BBPdecref");

        if (swap) {
                b = BBPquickdesc(i, TRUE);
                if (b) BBPfree(b); /* free memory (if loaded) and delete from disk (if transient but saved) */
		BBP_unload_off(i, "BBPdecref");
	}
	return refs;
}

void BBPshare(bat parent) {
	MT_Id pid = BBP_getpid();
	int fix = 0;

	if (pid != locked_by) 
        	MT_set_lock(GDKswapLock[parent&BBPLOCKMASK], "BBPshare");
        if (++BBP_cache(parent)->batSharecnt == 1) 
		fix = 1;
	if (pid != locked_by) 
        	MT_unset_lock(GDKswapLock[parent&BBPLOCKMASK], "BBPshare");
	if (fix) BBPfix(parent);
}

void BBPunshare(bat parent) {
	MT_Id pid = BBP_getpid();
	int unfix = 0;

	if (pid != locked_by) 
		MT_set_lock(GDKswapLock[parent&BBPLOCKMASK], "BBPunshare");
        if (--BBP_cache(parent)->batSharecnt == 0) 
		unfix = 1;
	if (pid != locked_by) 
		MT_unset_lock(GDKswapLock[parent&BBPLOCKMASK], "BBPunshare");
	if (unfix) BBPunfix(parent);
}

@
Resurrect retrieves a BAT with a zero refcount from the dead. This routine can be
used for implementing a dynamic caching scheme for transient BATs on top of the BBP
caching mechanism.

While this would best be implemented with a duple (bid,stamp), in the DD case where
BATs get unique column names, a string lookup is also valid. Note that the string
name match must be reconfirmed inside the lock (theoretically, between the BBPindex()
and the BBPincref, the BAT could have been destroyed and its place filled by a new BAT).
@c
int BBPresurrect(str nme){
        bat bid = BBPindex(nme);
        if (BBPincref(bid, FALSE) > 0) {
                if (strcmp(nme, BBP_logical(bid)) != 0) {
                	BBPdecref(bid, FALSE); /* too late: replaced by some other bat (unlikely) */
                } else {
			return TRUE;
		}
        }
        return FALSE;
}

@- 
BBPreclaim is a user-exported function; the common way to destroy a BAT the hard way. 

Return values:
-1 = bat cannot be unloaded (it has more than your own memory fix)
 0 = unloaded succesfully
 1 = unload failed (due to write-to-disk failure)
@c
int BBPreclaim(BAT* b) {
	MT_Id pid = BBP_getpid();
	bat i = ABS(b->batCacheid);
	int ret = 0;

	if (pid != locked_by)
		MT_set_lock(GDKswapLock[i&BBPLOCKMASK], "BBPreclaim");

	BATDEBUG THRprintf(GDKerr, 
	    "BBPreclaim: bat(%d) view=%d lrefs=%d ref=%d stat=%d\n", 
			(int) b->batCacheid, b->batSharecnt, 
			BBP_lrefs(b->batCacheid), 
			BBP_refs(b->batCacheid), BBP_status(b->batCacheid));

	if (BBP_refs(b->batCacheid) > 1) {
		GDKerror("BBPreclaim(%d) refs > 1 (%d)\n", i, BBP_refs(i));
		ret = -1;
	} else {
		/* unload whatever the LRU in the BBP */
		BBP_refs(b->batCacheid) = 0;
		BBP_unload_on(i, "BBPreclaim"); 
	}
	if (pid != locked_by)
		MT_unset_lock(GDKswapLock[i&BBPLOCKMASK], "BBPreclaim");

	/* BBPfree potentially saves the BAT. Do this after releasing the short-term lock */
	if (ret == 0) {
		ret = BBPfree(b);
		BBP_unload_off(i, "BBPreclaim");
	}
	return ret;
}
@-
BBPdescriptor checks whether BAT needs loading and does so if necessary. You must
have at least one fix on the BAT before calling this.
@c
BAT *BBPdescriptor(bat i) {
	int load = FALSE;
	bat j = ABS(i);
	BAT *b = NULL;

        if (!BBPcheck(i, "BBPdescriptor")) {
		return NULL;
	}
	assert( BBP_refs(i) );
	if ((b = BBP_cache(i)) == NULL) {
		MT_Id pid = BBP_getpid();

		if (pid != locked_by)
			MT_set_lock(GDKswapLock[j&BBPLOCKMASK], "BBPdescriptor"); 
		while (BBP_status(j) & BBPWAITING) { /* wait for bat to be loaded by other thread */
			if (pid != locked_by)
				MT_unset_lock(GDKswapLock[j&BBPLOCKMASK], "BBPdescriptor"); 
			BBPspin(j, "BBPdescriptor", BBPWAITING);
			if (pid != locked_by)
				MT_set_lock(GDKswapLock[j&BBPLOCKMASK], "BBPdescriptor"); 
		}
		if (BBP_logical(j)) {
			b = BBP_cache(i);
			if (b == NULL) {
				load = TRUE;
				BBP_status_on(j, BBPLOADING, "BBPdescriptor");
			}
		}
		if (pid != locked_by)
			MT_unset_lock(GDKswapLock[j&BBPLOCKMASK], "BBPdescriptor"); 
	}
	if (load) {
		IODEBUG THRprintf(GDKerr, "load %s\n", BBPname(i));
		b = BATload_intern(i);
		BBPin++;

		/* clearing bits can be done without the lock */
		BBP_status_off(j, BBPLOADING, "BBPdescriptor");
	}
        return b;
}


static int file_move(str srcdir, str dstdir, str name, str ext) {
	int ret = 0;
	ret = GDKmove(srcdir, name, ext, dstdir, name, ext);
	if (ret == 0) {
		return 0;
	} else {
		long_str path;
		struct stat st;
		GDKfilepath(path, srcdir, name, ext);
		if (stat(path, &st)) {
			/* source file does not exist; the best recovery is to give an error but continue
		         * by considering the BAT as not saved; making sure that this time it does get saved.
                         */
			return 2; /* indicate something fishy, but not fatal */
		}
	}
	return 1;
}

/* returns 1 if the file exists */
static int file_exists(str dir, str name, str ext) 
{
	long_str path;
	struct stat st;

	GDKfilepath(path, dir, name, ext);
	return (stat(path, &st)==0);
}

static int heap_move(Heap* hp, str srcdir, str dstdir, str nme, str ext) {
	if (hp->filename && hp->storage == STORE_MMAP) {
		GDKwarning("heap_move: read-only %s.%s should not be dirty.\n", nme, ext);
	}  
	if (hp->filename && hp->storage == STORE_PRIV) {
		/* private mappings have an untouchable X.priv file; and write new versions to X.
		 * in order to be able to recover correctly, we create a precommit file X that is
                 * a link to X.priv (only if X does not exists yet). This X is backed up and 
                 * restored. Without doing this, a newly written X could survive the BBPrecover.
		 */
		long_str path;
		struct stat st;
		GDKfilepath(path, srcdir, nme, ext);
		if (stat(path, &st)) {
			/* would have worked if all implementations of 
			 * MAP_PRIVATE allowed moving the file away 
		         * while it was mmapped
			if (GDKmove(srcdir, hp->filename, NULL, srcdir, nme, ext)) return -1;
			*/
			/* new solution creates a dummy file in the 
			 * BACKUP(dstdir) recover should take care of
			 * copying back the X.priv over X.
			 */
			FILE *fd;
			long_str kill_ext;
			strcpy(kill_ext,ext);
			strcat(kill_ext,".kill");
			GDKfilepath(path,dstdir,nme,kill_ext);
			if ((fd=fopen(path,"w"))!=NULL){
				fclose(fd);
				return 0;
			} else {
				return 1;
			}
		}
	}
	return file_move(srcdir, dstdir, nme, ext);
}

@- backup_bat
backup_bat backups the bat to the BACKUP/ DIR. In case a 
backup exists no new backup is needed.

@c
static int backup_bat(BAT *b) {
	long_str srcdir, nme;
	str s = BBP_physical(b->batCacheid);
	int ret = 0;

	if (prepare_backup()) {
		return -1;
	}
	if (b->batCopiedtodisk == 0 || nme == NULL) {
		return 0;
	}
	/* determine location dir and physical suffix */ 
        strcpy(srcdir, BATDIR);
        strcat(srcdir, s);
	s = strrchr(srcdir, DIR_SEP);
	strcpy(nme, ++s);
	srcdir[s - srcdir] = 0;

        if (b->batDirty || b->batDirtydesc) {
		/* if a backup exists we are done */
		if (file_exists(BAKDIR, nme, "desc")){
			return 0;
		}
		ret |= file_move(srcdir, BAKDIR, nme, "desc");
		if (ret&1) return -1;
	}
        if (b->batDirty || b->batDirtybuns) {
                ret |= heap_move(b->batBuns, srcdir, BAKDIR, nme, "buns");
		if (ret&1) return -1;
        }
        if ((b->batDirty || b->hheapdirty) && b->htype && b->hvarsized) {
		ret |= heap_move(&b->hheap, srcdir, BAKDIR, nme, "hheap");
		if (ret&1) return -1;
        }
        if ((b->batDirty || b->theapdirty) && b->ttype && b->tvarsized) {
		ret |= heap_move(&b->theap, srcdir, BAKDIR, nme, "theap");
		if (ret&1) return -1;
        }
        if ((b->batDirty || b->haccdirty) && b->haccCopiedtodisk) {
		ret |= heap_move(&b->haccelerator, srcdir, BAKDIR, nme, "hacc");
		if (ret&1) return -1;
        }
        if ((b->batDirty || b->taccdirty) && b->taccCopiedtodisk) {
                ret |= heap_move(&b->taccelerator, srcdir, BAKDIR, nme, "tacc");
		if (ret&1) return -1;
        }
	if (ret) {
		b->batCopiedtodisk = b->haccCopiedtodisk = b->taccCopiedtodisk = 0;
	}
        return 0;
}

@-
In BBPsave executes unlocked; it just marks the BBP_status of the BAT to BBPsaving, so others
that want to save or unload this BAT must spin lock on the BBP_status field.
@c
extern void DESCclean(BAT*);

int BBPsave(BAT* b) {
	MT_Id pid = BBP_getpid();
	bat bid = ABS(b->batCacheid);
	int ret = 0;

	if (pid != locked_by)
		MT_set_lock(GDKswapLock[bid&BBPLOCKMASK], "BBPsave"); 
	if (BBP_lrefs(bid) == 0 || !BATdirty(b)) {
		/* do nothing */
		if (pid != locked_by)
			MT_unset_lock(GDKswapLock[bid&BBPLOCKMASK], "BBPsave"); 
	} else if (BBP_status(bid)&BBPSAVING) {
		/* wait until save in other thread completes */
		BBPspin(bid, "BBPsave", BBPSAVING);
		if (pid != locked_by)
			MT_unset_lock(GDKswapLock[bid&BBPLOCKMASK], "BBPsave"); 
	} else {
		/* save it */	
		int flags = BBPSAVING;

 		if (DELTAdirty(b)) {
			flags |= BBPSWAPPED;
			BBPdirty(1);
		}
 		if (b->batPersistence != PERSISTENT) {
			flags |= BBPTMP;
		}
		BBP_status_on(bid, flags, "BBPsave");
		if (pid != locked_by)
			MT_unset_lock(GDKswapLock[bid&BBPLOCKMASK], "BBPsave"); 

		IODEBUG THRprintf(GDKerr, "save %s\n", b->batId); 

		/* do the time-consuming work unlocked */
		if (BBP_status(bid) & BBPEXISTING)
			ret = backup_bat(b);
		if (ret == 0) {
			BATreduce(b,0);
			BBPout++; 
			ret = (BATsave(b) == NULL);
			if (ret == 0) {
				DESCclean(b);
			}
		}
		BBP_status_off(bid, BBPSAVING, "BBPsave");
	}
	return ret;
}


@-
TODO merge BBPfree with BATfree? Its function is to prepare a BAT for being
unloaded (or even destroyed, if the BAT is not persistent).
@c
static
int BBPfree(BAT *b) {
	int ret;
	bat bid = ABS(b->batCacheid), parent = VIEWparent(b);
	int destroy = BBP_lrefs(bid) == 0 && (BBP_status(bid)&BBPDELETED) == 0;

	assert(BBPswappable(b));
	if (!parent)
		assert(b->batSharecnt == 0);

	/* write dirty BATs before being unloaded */
	ret = BBPsave(b);
	if (ret) {
		return ret; /* error while saving: no go */
	}

	if (!parent) {
		if (destroy) { 
			/* bats that get destroyed must unfix their atoms */
			int (*hunfix)(ptr) = BATatoms[b->htype].atomUnfix;
			int (*tunfix)(ptr) = BATatoms[b->ttype].atomUnfix;
			BUN p, q;
			int xx;

			if (hunfix) {
				DELloop(b, p, q, xx) {
					(*hunfix)(BUNhead(b,p));
				}
				BATloopFast(b, p, q, xx) {
					(*hunfix)(BUNhead(b,p));
				}
			}
			if (tunfix) {
				DELloop(b, p, q, xx) {
					(*tunfix)(BUNtail(b,p));
				}
				BATloopFast(b, p, q, xx) {
					(*tunfix)(BUNtail(b,p));
				}
			}
			BATdelete(b); /* remove persistent info and free memory */
		} else if (BBP_cache(bid)) {
			BATfree(b); /* free memory */
		}
        } else {
		VIEWdestroy(b);
	}
	if (destroy) {
		BBPclear(bid); /* if destroyed; de-register from BBP */
	} else {
		BBPuncacheit(bid, b->batMapdirty); /* just mark unloaded */
	}
	if (parent)		/* parent released when completely done with child */
		BBPunshare(parent);
	return 0; 
}


@- trim
@T
BBPtrim unloads the least recently used BATs to free memory resources.
It gets passed targets in bytes of physical memory and logical
virtual memory resources to free. Overhead costs are reduced by
making just one scan, analyzing the first BBPMAXTRIM bats
and keeping the result in a list for later use (the oldest bat 
now is going to be the oldest bat in the future as well).
This list is sorted on last-used timestamp. BBPtrim keeps unloading
BATs till the targets are met or there are no more BATs to unload.

In determining whether a BAT will be unloaded, first it has
to be BBPswappable, and second its resources occupied must
be of the requested type. The algorithm actually makes two passes,
in the first only clean bats are unloaded (in order of their stamp).

In order to keep this under control with multiple threads all
running out of memory at the same time, we make sure that 
\begin{itemize}
\item 
just one thread does a BBPtrim at a time (by having a BBPtrimLock set).
\item
while decisions are made as to which bats to unload (1) the BBP is
scanned, and (2) unload decisions are made. Due to these properties,
the search\&decide phase of BBPtrim acquires both GDKcacheLock (due to (1))i
and all GDKswapLocks (due to (2)). They must be released during the actual 
unloading.  (as otherwise deadlock occurs => unloading a bat may e.g. kill 
an accelerator that is a BAT, which in turn requires BBP lock acquisition).
\item
to avoid further deadlock, the update functions in BBP that hold either 
GDKcacheLock or a GDKswapLock may never cause a BBPtrim (notice that BBPtrim 
could theoretically be set off just by allocating a little piece of memory, e.g. 
GDKstrdup()). If these routines must alloc memory, they must set the BBP\_notrim 
variable, aquiring the addition GDKtrimLock, in order to prevent such deadlock.
\item
the BBPtrim is atomic; only releases its locks when all BAT unload 
work is done. This ensures that if all memory requests that triggered
BBPtrim could possible be satified by unloading BATs, this will succeed.
\end{itemize}

The scan phase was optimized further in order to stop early when
it is apriori known that the targets are met (which is the case if the
BBPtrim is not due to memory shortage but due to the ndesc quota).
Note that scans may always stop before BBPsize as the BBPMAXTRIM is a fixed
number which may be smaller. As such, a mechanism was added to resume
a broken off scan at the point where scanning was broken off rather than
always starting at BBP[1] (this does more justage to the lower numbered 
bats and will more quickly find fresh unload candidates).

We also refined the swap criterium. If the BBPtrim was initiated due to:
- too much descriptors: small bats are unloaded first (from LRU cold to hot)  
- too little memory: big bats are unloaded first (from LRU cold to hot).
Unloading-first is enforced by subtracting 2^31 from the stamp in the
field where the candidates are sorted on.
@c
#define BBPMAXTRIM 40000
#define BBPSMALLBAT 1000

typedef struct {
	int lastused;	/* bat lastused stamp; sort on this field */
	bat bid;	/* bat id */
	int cnt;	/* bat count */
	int next;	/* next position in list */
} bbptrim_t;

bbptrim_t bbptrim[BBPMAXTRIM];
int bbptrimfirst = BBPMAXTRIM, bbptrimlast = 0, bbpunloadtail, bbpunload, bbptrimmax = BBPMAXTRIM, bbpscanstart = 1;


static bat BBPtrim_scan(int mem, int vm, int descs, bat bbppos, bat bbplim) {
	bbptrimlast = 0;
	bbptrimmax = BBPMAXTRIM;
	MEMDEBUG THRprintf(GDKerr, "TRIMSCAN: mem=%d vm=%d, descs=%d, start=%d, limit=%d\n", mem, vm, descs, (int) bbppos, (int) bbplim);
	if (bbppos < BBPsize) do { 
		if (BBP_logical(bbppos)) {
			BAT *b = BBP_cache(bbppos);
			int descswap = (b == NULL && BBPdesctrimmable(bbppos));

			if (BBPtrimmable(b) || (descs && descswap)) {
				/* when unloading for memory, treat small BATs with a preference over big ones.
				 * rationale: I/O penalty for cache miss is relatively higher for small bats 
				 */
				int swap_first = 0, cnt = -1;
				if (b) {
					cnt = BATcount(b);
					swap_first = (cnt >= BBPSMALLBAT);
				}

				/* however, when we are looking to decrease the amount of descriptors,
				 * try to put the small bats in front of the load list instead..
				 */
				if (descs) swap_first = !swap_first;

				/* subtract 2-billion to make sure the swap_first class bats are unloaded first */
				bbptrim[bbptrimlast].lastused = BBPLASTUSED(BBP_lastused(bbppos)) | (swap_first << 31);
				bbptrim[bbptrimlast].bid = bbppos;
				bbptrim[bbptrimlast].cnt = cnt; 
				if (++bbptrimlast == bbptrimmax) break;
			}
		}
		if (++bbppos == BBPsize) bbppos = 1; /* treat BBP as a circular buffer */
	} while(bbppos != bbplim);

	if (bbptrimlast > 0) {
		int i;
		GDKqsort(bbptrim, NULL, bbptrimlast, sizeof(bbptrim_t), TYPE_int, 0);
		for(i = bbptrimfirst = 0; i < bbptrimlast; i++) {
			MEMDEBUG THRprintf(GDKerr, "TRIMSCAN: %11d%c %9d=%s\t(#%d)\n", BBPLASTUSED(bbptrim[i].lastused), 
						(bbptrim[i].lastused&0x80000000)?'*':' ', i, BBPname(bbptrim[i].bid), bbptrim[i].cnt);   
			bbptrim[i].next = i+1;
		}
		bbptrim[bbptrimlast-1].next = BBPMAXTRIM;
	} else {
		bbptrimfirst = BBPMAXTRIM;
	}
	MEMDEBUG THRprintf(GDKerr, "TRIMSCAN: end at %d (size=%d)\n", bbppos, (int) BBPsize);
	return bbppos;
}


/* insert BATs to unload from bbptrim list into bbpunload list; rebuild bbptrimlist only with the useful leftovers */
static 
void BBPtrim_select(size_t *memtarget, size_t *vmtarget, int *ndescs, int dirty) {
	int bbptrimtail=BBPMAXTRIM, next=bbptrimfirst;

	MEMDEBUG THRprintf(GDKerr, "TRIMSELECT: dirty = %d, ndescs = %d\n", dirty, *ndescs);

	/* make the bbptrim-list empty; we will insert the untouched elements in it */
	bbptrimfirst = BBPMAXTRIM; 

	while(next != BBPMAXTRIM) {
		int cur = next;  /* cur is the entry in the old bbptrimlist we are processing */
		int untouched = BBPLASTUSED(BBP_lastused(bbptrim[cur].bid)) <= BBPLASTUSED(bbptrim[cur].lastused);
		BAT *b = BBP_cache(bbptrim[cur].bid);

		next = bbptrim[cur].next; /* do now, because we overwrite bbptrim[cur].next below */ 
		
		MEMDEBUG if (b) {
			THRprintf(GDKerr, "TRIMSELECT: candidate=%s BAT*=" PTRFMT "\n", BBPname(bbptrim[cur].bid), (void *) b);   
			THRprintf(GDKerr, "            (cnt=%d, mode=%d, refs=%d, wait=%d, parent=%d, lastused=%u,%u,%d)\n",
					bbptrim[cur].cnt, b->batPersistence, BBPrefs(b->batCacheid), (BBPstatus(b->batCacheid)&BBPWAITING)!=0, 
					VIEWparent(b), BBP_lastused(b->batCacheid), BBPLASTUSED(bbptrim[cur].lastused), bbptrim[cur].lastused);
		}
		/* recheck if conditions encountered by trimscan in the past still hold */
		if (*ndescs > 0 && b == NULL && BBPdesctrimmable(bbptrim[cur].bid) && untouched) {
			MEMDEBUG THRprintf(GDKerr, "TRIMSELECT: uncache %s descriptor (descs=%d)\n", BBPname(bbptrim[cur].bid), *ndescs);   
			GDKfree(BBP_desc(bbptrim[cur].bid));
			BBP_desc(bbptrim[cur].bid) = NULL;
			BBP_desc_count[bbptrim[cur].bid&BBPLOCKMASK]--;
			--(*ndescs);
		} else if (BBPtrimmable(b) && untouched) {
			size_t memdelta = BATmemsize(b,FALSE);
			size_t vmdelta  = BATvmsize(b,FALSE);
			size_t memdirty = BATmemsize(b,TRUE);
			size_t vmdirty  = BATvmsize(b,TRUE);

			if ((b->batPersistence == TRANSIENT || /* the BAT needs not be saved when unloaded, OR.. */
			     (vmdirty == 0 && memdirty <= sizeof(BATstore)) || /* the BAT is actually clean, OR.. */
                             dirty)  /* we are allowed to cause I/O (second run).. */
			&&						/* AND ... */
			    ((*memtarget > 0 && (memdelta > 0)) || (*vmtarget > 0 && (vmdelta > 0)) || 
					/* there is some reward in terms of memory requirements, OR.. */
				(*ndescs > 0 && (dirty || BATcount(b) < BBPSMALLBAT)))) 
		                	/* we *MUST* unload bats for the ndesc quota (in first run swap only small bats)..  */
			{
				/* only then we unload! */
				MEMDEBUG {
					THRprintf(GDKerr, "TRIMSELECT: unload %s [" SZFMT "," SZFMT "] bytes [" SZFMT "," SZFMT "] dirty\n",
						BBPname(b->batCacheid), 
						memdelta, vmdelta, memdirty, vmdirty);
				}
				BBP_unload_on(bbptrim[cur].bid, "BBPtrim_select");
				*memtarget = *memtarget > memdelta ? *memtarget - memdelta : 0;
				*vmtarget = *vmtarget > vmdelta ? *vmtarget - vmdelta : 0;
				if (*ndescs > 0) (*ndescs)--; /* one less obliged bat */ 

				/* add to bbpunload list */
				if (bbpunload == BBPMAXTRIM) {
					bbpunload = cur;
				} else {
				  	bbptrim[bbpunloadtail].next = cur;
				}
				bbptrim[cur].next = BBPMAXTRIM; 
				bbpunloadtail = cur; 
			} else if (!dirty) {
				/* do not unload now, but keep around; insert at the end of the new bbptrim list */
				MEMDEBUG {
					THRprintf(GDKerr, "TRIMSELECT: keep %s [" SZFMT "," SZFMT "] bytes [" SZFMT "," SZFMT "] dirty target(mem=" SZFMT " vm=" SZFMT " descs=%d)\n",
						BBPname(b->batCacheid), memdelta, vmdelta, memdirty, vmdirty, MAX(0,*memtarget), MAX(0,*vmtarget), *ndescs);
				}
				if (bbptrimtail == BBPMAXTRIM) {
					bbptrimfirst = cur;
				} else {
					bbptrim[bbptrimtail].next = cur; 
				}
				bbptrim[cur].next = BBPMAXTRIM;
				bbptrimtail = cur;
                        } else {
                                /* bats that even in the second (dirty) run are not selected, should be acquitted from the trimlist until a next scan */
                                MEMDEBUG THRprintf(GDKerr, "TRIMSELECT: delete %s from trimlist (does not match trim needs)\n", BBPname(bbptrim[cur].bid));
                        }
                } else {
                        /* BAT was touched (or unloaded) since trimscan =>  it is discarded from both lists */
                        MEMDEBUG THRprintf(GDKerr, "TRIMSELECT: delete %s from trimlist (has been %s)\n",
                                                BBPname(bbptrim[cur].bid), b?"touched since last scan":"unloaded already");
                }

		if (*memtarget == 0 && *vmtarget == 0 && *ndescs <= 0) {
			/* we're done; glue the rest of the old bbptrim list to the new bbptrim list */
			if (bbptrimtail == BBPMAXTRIM) {
				bbptrimfirst = next;
			} else {
				bbptrim[bbptrimtail].next = next; 
			} break;
		}
	}
	MEMDEBUG THRprintf(GDKerr, "TRIMSELECT: end\n");
}

void BBPtrim(size_t memtarget, size_t vmtarget) {
	int i, limit, scan, did_scan = FALSE, ndescs = 0;
	int msec=0, bats_written=0, bats_unloaded = 0; /* performance info */
	MT_Id t = BBP_getpid();

	PERFDEBUG msec = GDKms();

	if (BBP_notrim == t) return; /* avoid deadlock by one thread going here twice */

	MT_set_lock(GDKtrimLock, "BBPtrim"); 
	BBP_notrim = t;

       	for(i=0; i<=BBPLOCKMASK; i++) 
		ndescs += BBP_desc_count[i];
	if (ndescs < 0) ndescs = 0;
       
	/* recheck targets to see whether the work was already done by another thread */
	if (memtarget && memtarget != BBPTRIM_ALL) {
        	memtarget = GDKmem_inuse();
		if (memtarget > GDK_mem_maxsize)
			memtarget -= GDK_mem_maxsize;
		else
			memtarget = 0;
	}
	if (vmtarget && vmtarget != BBPTRIM_ALL) {
		vmtarget = GDKvm_cursize();
		if (vmtarget > GDK_vm_maxsize)
			vmtarget -= GDK_vm_maxsize;
		else
			vmtarget = 0;
	}
	MEMDEBUG THRprintf(GDKerr, "BBPTRIM_ENTER: memsize=" SZFMT ",vmsize=" SZFMT ",ndescs=%d\n", 
			GDKmem_cursize(), GDKvm_cursize(), ndescs);
	ndescs -= BBP_desc_max*(BBPLOCKMASK+1);
	MEMDEBUG THRprintf(GDKerr, "BBPTRIM: memtarget=" SZFMT " vmtarget=" SZFMT ",desctarget=%d\n", 
			memtarget, vmtarget, ndescs);
	PERFDEBUG THRprintf(GDKerr, "BBPtrim(mem=%d,vm=%d,descs=%d)\n", memtarget>0, vmtarget>0, ndescs>0); 

	scan = (bbptrimfirst == BBPMAXTRIM);
	if (bbpscanstart >= BBPsize) bbpscanstart = 1; /* sometimes, the BBP shrinks! */
	limit = bbpscanstart;

 	while(ndescs > 0  || memtarget > 0 || vmtarget > 0) {
		/* acquire the BBP locks */
		MT_set_lock(GDKcacheLock, "BBPtrim");
		for(i=0; i <= BBPLOCKMASK; i++)
			MT_set_lock(GDKswapLock[i & BBPLOCKMASK], "BBPtrim");

		/* gather a list of unload candidate BATs, but try to avoid scanning by reusing previous leftovers first */
		if (scan) {
			did_scan = TRUE;
			bbpscanstart = BBPtrim_scan((memtarget>0), (vmtarget>0), (ndescs>0), bbpscanstart, limit);
			scan = (bbpscanstart != limit);
		} else {
			scan = TRUE;
		}
	
		/* decide which of the candidates to unload using LRU */
		bbpunload = BBPMAXTRIM;
		BBPtrim_select(&memtarget, &vmtarget, &ndescs, FALSE); /* first try to select only clean BATs */
 		if (did_scan && (memtarget > 0 || vmtarget > 0 || ndescs > 0)) {
			BBPtrim_select(&memtarget, &vmtarget, &ndescs, TRUE); /* if that is not enough, also unload dirty BATs */
		}

		/* release the BBP locks */
                BBPunlock("BBPtrim");
		MT_unset_lock(GDKcacheLock, "BBPtrim");

		/* do the unload work unlocked */
		MEMDEBUG THRprintf(GDKerr, "BBPTRIM: %s\n", 
			(bbpunload!=BBPMAXTRIM)?" lastused   batid name":"no more unload candidates!");

		for(i=bbpunload; i!=BBPMAXTRIM; i = bbptrim[i].next) {
			BAT *b = BBP_cache(bbptrim[i].bid);
			MEMDEBUG THRprintf(GDKerr, "BBPTRIM: %9u %7d %s\n",
					bbptrim[i].lastused, (int) bbptrim[i].bid,
					BBPname(bbptrim[i].bid));
			bats_written += (b->batPersistence != TRANSIENT && BATdirty(b));
			bats_unloaded++;
			BBPfree(b);
			BBP_unload_off(bbptrim[i].bid, "BBPtrim");
		} 
		/* continue while we can scan for more candiates */
		if (!scan) break;
	}

	/* done trimming */
	MEMDEBUG  THRprintf(GDKerr, "BBPTRIM_EXIT: memsize=" SZFMT ",vmsize=" SZFMT "\n",
			    GDKmem_cursize(), GDKvm_cursize());
	PERFDEBUG THRprintf(GDKerr, "BBPtrim(did_scan=%d, bats_unloaded=%d, bats_written=%d) %d ms\n", 
			    did_scan, bats_unloaded, bats_written, GDKms() - msec); 
	BBP_notrim = 0;
	MT_unset_lock(GDKtrimLock, "BBPtrim"); 
}

void BBPhot(bat i) {
	MT_Id pid = BBP_getpid();
	if (i < 0) i = -i;
        if (BBPcheck(i, "BBPhot")) {
		if (pid != locked_by)
			MT_set_lock(GDKswapLock[i&BBPLOCKMASK], "BBPhot");
		BBP_lastused(i) = BBPLASTUSED(GDKstamp() + 30000);
		if (pid != locked_by)
			MT_unset_lock(GDKswapLock[i&BBPLOCKMASK], "BBPhot");
        }
}

void BBPcold(bat i) {
	MT_Id pid = BBP_getpid();
	if (i < 0) i = -i;
        if (BBPcheck(i, "BBPcold")) {
		MT_set_lock(GDKtrimLock, "BBPcold");
		if (pid != locked_by)
			MT_set_lock(GDKswapLock[i&BBPLOCKMASK], "BBPcold");
		/* make very cold and insert on top of trim list */
                BBP_lastused(i) = 0;
		if (BBP_cache(i) && bbptrimlast < bbptrimmax) {
			bbptrim[--bbptrimmax].lastused = 0;
			bbptrim[bbptrimmax].bid = i;
			bbptrim[bbptrimmax].next = bbptrimfirst;
			bbptrimfirst = bbptrimmax;
		}
		if (pid != locked_by)
			MT_unset_lock(GDKswapLock[i&BBPLOCKMASK], "BBPcold");
		MT_unset_lock(GDKtrimLock, "BBPcold");
        }
}

@-
BBPquickdesc loads a BAT descriptor without loading the entire BAT, of which the
result be used only for a *limited* number of purposes. Specifically, during the 
global sync/commit, we do not want to load any BATs that are not already loaded, both 
because this costs performance, and because getting into memory shortage during a commit 
is extremely dangerous, as the global sync has all the BBPlocks, so no BBPtrim() can be 
done to free memory when needed. Loading a BAT tends not to be required, since the commit 
actions mostly involve moving some pointers in the BAT descriptor. However, some column 
types do require loading the full bat. This is tested by the complexatom() routine. Such 
columns are those of which the type has an fix/unfix method, or those that have HeapDelete
methods. The HeapDelete actions are not always required and therefore the BBPquickdesc
is parametrized.
@c
static int complexatom(str s, int delaccess) {
        int t = ATOMindex(s);
	if (t >= 0 && (BATatoms[t].atomFix || (delaccess && BATatoms[t].atomDel))) {
		return TRUE;
	}
	return FALSE;
}

BAT *BBPquickdesc(bat bid, int delaccess) { 
        BAT *b = BBP_cache(bid);
        if(bid<0) {
            GDKerror("BBPquickdesc: called with negative batid.\n");
            return NULL;
        }
        if (b) {
		return b; /* already cached */
	}
	b = (BAT*) BBPgetdesc(bid);
        if (b == NULL || b->hacctype || (complexatom(b->hatom, delaccess)) 
                      || b->tacctype || (complexatom(b->tatom, delaccess)))
	{
                b = BATload_intern(bid);
		BBPin++;
        }
        return b;
}

static BAT *dirty_bat(bat i) {
	if (BBP_logical(i)) {
		BAT *b;
		BBPspin(i, "dirty_bat", BBPSAVING);
		b = BBP_cache(i);
		if (b != NULL) {
			if ((BBP_status(i)&BBPPERSISTENT) && BATdirty(b)) {
				return b; /* the bat is loaded, persistent and dirty */
			}
		} else if (BBP_status(i)&BBPSWAPPED) { 
		  	b = (BAT*) BBPquickdesc(i, TRUE);
			if (b && b->batDirtydesc) {
				return b; /* only the desc is loaded & dirty */
			}
		}
	}
	return NULL;
}

@+ Atomic Write
@T
The atomic BBPsync() function first safeguards the old images of all files 
to be written in BAKDIR. It then saves all files. If that succeeds
fully, BAKDIR is renamed to DELDIR. The rename is considered an 
atomic action. If it succeeds, the DELDIR is removed.
If something fails, the pre-sync status can be obtained by moving
back all backed up files; this is done by BBPrecover().

The BBP.dir is also moved into the BAKDIR.
@c
int BBPsync(int commit) {
	bat i;
	int ret=0, bbpdirty = 0; 
	int t0=0, t1=0;

	PERFDEBUG t0 = t1 = GDKms();

	if (!commit) {
		BBPlock("BBPsync");
		PERFDEBUG THRprintf(GDKerr, "BBPsync (lock time %d)\n", (t0=GDKms()) - t1);
	}
        /* PHASE 1: safeguard everything in BACKUP dir */
	if (commit) {
        	bbpdirty = BBP_dirty; 
		if (OIDdirty()) {
			bbpdirty = BBP_dirty = 1;
		}
	}
	if (ret == 0) {
		for (i = 1; i < BBPsize; i++) {
			BAT *b = dirty_bat(i);
			if (b != NULL && backup_bat(b)) break;
		} ret = (i != BBPsize);
	}
        PERFDEBUG THRprintf(GDKerr, "BBPsync (move time %d) %d files\n", 
				(t1=GDKms()) - t0, backuped_files);

	/* PHASE 2: save the repository */
	if (ret == 0) {
		for (i = 1; i < BBPsize; i++) {
			BAT *b = dirty_bat(i);
			if (b != NULL && BATsave(b) == NULL) break; /* write error */
		}
		ret = (i != BBPsize);
	}

        PERFDEBUG THRprintf(GDKerr, "BBPsync (write time %d)\n", (t0=GDKms()) - t1);

	if (ret == 0 && bbpdirty) {
		ret = BBPdir();
	} else if (!bbpdirty) {
		/* restore BBP.dir */
		ret = GDKmove( BAKDIR,"BBP","dir", BATDIR,"BBP","dir");
	}

        PERFDEBUG THRprintf(GDKerr, "BBPsync (dir time %d) %d bats\n", 
			(t1=GDKms()) - t0, BBPsize);

	if (bbpdirty == 0 && backuped_files == 0) {
		goto out;
	}
        if (ret == 0) {
	        /* atomic switchover */
		ret = rename(BAKDIR, DELDIR);
		if (ret) 
		GDKsyserror("BBPsync: rename(%s,%s) failed.\n", BAKDIR,DELDIR);
		IODEBUG THRprintf(GDKerr, "BBPsync: rename %s %s = %d\n", 
						BAKDIR, DELDIR, ret);
	}

	/* AFTERMATH */
        if (ret == 0) {
		for (i = 1; i < BBPsize; i++) {
			BAT *b = dirty_bat(i);
			if (b) DESCclean(b);
		}
		BBP_dirty = 0;
		ret = GDKremovedir(DELDIR);
        } else {
               	BBPrecover(); 
	}
out:

	backuped_files = 0;
	ret = prepare_backup();
	if (!ret){
		/* always move the BBP.dir to the BAKDIR, as unloads
		   and mmap's can happen at any time during a transaction
		 */
		ret = GDKmove( BATDIR,"BBP","dir", BAKDIR,"BBP","dir" );
	}

	if (!commit)
		BBPunlock("BBPsync");
        PERFDEBUG THRprintf(GDKerr, "BBPsync (ready time %d)\n", (t0=GDKms()) - t1);
	return ret;
}

@-
Recovery just moves all files back to their original location. this is an incremental
process: if something fails, just stop with still files left for moving in BACKUP/. 
The recovery process can resume later with the left over files.
@c
static int force_move(str srcdir, str dstdir, str name) { 
	char *p;
	long_str srcpath, dstpath;
	int ret = 0;

	if ((p=strrchr(name, '.'))!=NULL && strcmp(p,".kill") == 0){
		ptrdiff_t len = p-name;

		strncpy(srcpath,name,len);
		srcpath[len] = '\0';
		GDKfilepath(dstpath, dstdir, srcpath, NULL);
		ret = unlink(dstpath); /* clear destination */
		IODEBUG THRprintf(GDKerr, "unlink %s = %d\n", dstpath, ret);
		if (GDKcreatedir(dstdir)) ret = 0;
		ret = GDKmove(dstdir, srcpath, "priv", dstdir, srcpath, NULL);
		if (ret) GDKsyserror(
		    	"force_move: link(%s%c%s.priv,%s)=%d\n", 
			srcdir, DIR_SEP,srcpath, dstpath);
		IODEBUG THRprintf(GDKerr, 
			"link %s%c%s.priv %s = %d\n", 
			srcdir, DIR_SEP, srcpath, dstpath, ret);
		return ret;
	} 
	/* try to rename it */
	ret = GDKmove(srcdir, name, NULL, dstdir, name, NULL);
	IODEBUG THRprintf(GDKerr, "link %s %s = %d\n", srcpath, dstpath, ret);
	if (ret) {
		/* two legal possible causes: file exists or dir notexist */
		GDKfilepath(dstpath, dstdir, name, NULL);
		GDKfilepath(srcpath, srcdir, name, NULL);
		ret = unlink(dstpath); /* clear destination */
		IODEBUG THRprintf(GDKerr, "unlink %s = %d\n", dstpath, ret);
		if (GDKcreatedir(dstdir)) ret = 0;
		ret = GDKmove(srcdir, name, NULL, dstdir, name, NULL);
		if (ret) GDKsyserror(
			"force_move: link(%s,%s)=%d\n", srcpath, dstpath, ret);
		IODEBUG THRprintf(GDKerr, 
			"link %s %s = %d\n", srcpath, dstpath, ret);
	} 
	return ret;
}

void BBPrecover(void) {
	DIR *dirp = opendir(BAKDIR);
	struct dirent *dent;
	long_str path, dstpath;
	bat i;
	size_t j;
	int ret, dirseen=FALSE;
	str dstdir;

	if (dirp == NULL) {
		return; /* nothing to do */
	}
	strcpy(dstpath,BATDIR);
	dstdir = dstpath + strlen(dstpath);
        IODEBUG THRprintf(GDKerr, "BBPrecover(start)\n");
	GDKremovedir(LEFTDIR);	
	ret = mkdir(LEFTDIR, 0755);
	IODEBUG THRprintf(GDKerr, "mkdir %s = %d\n", LEFTDIR, ret); 

        /* move back all files */
	while((dent = readdir(dirp)) != NULL) {
		str q = strchr(dent->d_name,'.');
		if (q == dent->d_name) {
			int j;
			if (strcmp(dent->d_name, ".") == 0 ||
			    strcmp(dent->d_name, "..") == 0)
				continue;
			GDKfilepath(path, BAKDIR, dent->d_name, NULL); 
			j = unlink(path);
			IODEBUG THRprintf(GDKerr, "unlink %s = %d\n", path, j);
			continue;
		} else if (strcmp(dent->d_name, "BBP.dir") == 0) {
			dirseen = TRUE;
			continue;
		}
		if (q == NULL) q = dent->d_name + strlen(dent->d_name);
		if ((j = q - dent->d_name) + 1 > sizeof(path)) {
			/* name too long: ignore */
			continue;
		}
		strncpy(path, dent->d_name, j);
		path[j] = 0;
		if (GDKisdigit(*path)) {
			i = atoi(path);
		} else {
			i = BBP_find(path, FALSE);
			if (i < 0) i = -i;
		}
		if (i == 0 || i >= BBPsize || !BBP_logical(i)) {
			force_move(BAKDIR, LEFTDIR, dent->d_name);
		} else { 
			BBPgetsubdir(dstdir,i);
			ret += force_move(BAKDIR, dstpath, dent->d_name);
		}
	}
	closedir(dirp);
	if (dirseen && ret == 0) { /* we have a saved BBP.dir; it should be moved back!! */
		GDKfilepath(dstpath, BATDIR,"BBP","dir");
		GDKfilepath(path,  BAKDIR,"BBP","dir");

		/* recklessly remove the bat/BBP.dir: it belongs to a failed commit */
		ret = unlink(dstpath);
		IODEBUG THRprintf(GDKerr, "unlink(%s) = %d\n", dstpath, ret);

		/* move backup BBP.dir back */
		ret = rename(path,dstpath);
		IODEBUG THRprintf(GDKerr, "rename(%s,%s) = %d\n", path, dstpath, ret);
	}

	if (ret == 0) {
		ret = rmdir(BAKDIR);
		IODEBUG THRprintf(GDKerr, "rmdir %s = %d\n", BAKDIR, ret); 
	}
	if (ret)
	GDKerror("BBPrecover: recovery failed, will resume later."
                 "Please check whether your disk is full or write-protected.\n"); 

        IODEBUG THRprintf(GDKerr, "BBPrecover(end)\n");
}

@- diskscan
The BBPdiskscan routine walks through the BAT dir, cleans up leftovers, and measures disk occupancy. 
Leftovers are files that cannot belong to a BAT. in order to establish this for [ht]heap and [ht]acc files, 
the BAT descriptor is loaded in order to determine whether these files are still required. 

The routine gathers all bat sizes in a bat that contains bat-ids and bytesizes. The returnvalue is
the number of bytes of space freed.
@c
static int persistent_bat(bat bid) {
	if (bid >= 0 && bid < BBPsize && BBP_logical(bid)) {
		BAT *b = BBP_cache(bid);
		if (b == NULL || b->batCopiedtodisk) {
			return TRUE;
		}
	}
	return FALSE;
}

static int transient_acc(str nme) {
	/* in the future we should just use b->[ht]accCopiedtodisk, but due to a bug these 
         * fields might be FALSE while they should be TRUE, hence can't use them now (DS2.2.7)
         */
	int acctype = ACCindex(nme);
	if (acctype > 0) {
		return (BATaccelerators[acctype].accSave == NULL);
	}
	return FALSE;
}

static BAT* getdesc(int bid) {	
	BAT *b = (BAT*) BBPgetdesc(bid);
	if (b == NULL) BBPclear(bid);	
	return b;
}
	
lng BBPdiskscan_r(str parent) {
	str dir = parent?parent:BATDIR;
	DIR *dirp = opendir(dir);
	struct dirent *dent;
	long_str fullname;
	str dst = fullname, src = dir;
	lng ret, tot = LL_CONSTANT(0);

	if (dirp == NULL) {
		return LL_CONSTANT(-1); /* nothing to do */
	}
	while(*src) *dst++ = *src++;
	if (dst[-1] != DIR_SEP)
		*dst++ = DIR_SEP;

	while((dent = readdir(dirp)) != NULL) {
		str p = strchr(dent->d_name, '.');
		bat bid = atoi(dent->d_name);
		int r, ok = (p && bid), delete = FALSE;
		off_t filesize;
		struct stat st;

		if (dent->d_name[0] == '.')
			continue; /* ignore .dot files and directories (. ..) */
		if (parent == NULL && strncmp(dent->d_name, "BBP.", 4) == 0) {
			continue;
		}
		strcpy(dst, dent->d_name);
		if (p == NULL) {
			ret = BBPdiskscan_r(fullname);
			if (ret >= 0) {
				tot += ret; /* it was a directory; add subtotal */
				continue;
			}
		}
		r = stat(fullname, &st);
		if (r) {
			GDKsyserror("BBPdiskscan: stat(%s)", fullname);
			continue;
		} else {
			/* record the real disk occupancy; not just the bytesize */
			filesize = st.st_size;
		}

		/* if X exists, then X.priv can always be deleted */
		r = (int) strlen(fullname);
		if (r > 5 && strcmp(fullname+r-5, ".priv") == 0) {
			chr bak = fullname[r-5];
			fullname[r-5] = 0; /* cut off the .priv bit */
			delete = (stat(fullname, &st) == 0);
			fullname[r-5] = bak;
		}
		if (ok == FALSE || delete == TRUE || !persistent_bat(bid)) {
			delete = TRUE;
		} else if (strncmp(p+1, "hheap", 5) == 0) {
			BAT *b = getdesc(bid);
			delete = (b == NULL || b->hheap.size == 0) || (b->batCopiedtodisk == 0);
		} else if (strncmp(p+1, "theap", 5) == 0) {
			BAT *b = getdesc(bid);
			delete = (b == NULL || b->theap.size == 0) || (b->batCopiedtodisk == 0);
		} else if (strncmp(p+1, "hacc", 4) == 0) {
			BAT *b = getdesc(bid);
			delete = (b == NULL || b->hacctype == 0) || transient_acc(b->haccname);
		} else if (strncmp(p+1, "tacc", 4) == 0) {
			BAT *b = getdesc(bid);
			delete = (b == NULL || b->tacctype == 0) || transient_acc(b->taccname);
		} else if (strcmp(p+1, "desc") && strncmp(p+1, "buns", 4)) {
			ok = FALSE;
		}
		if (!ok) {
			/* found an unknown file; stop pruning in this subdir */
			GDKwarning("BBPdiskscan: unexpected file %s, leaving %s.\n", dent->d_name, dir);
			break;
		}
		if (delete) {
			r  = unlink(fullname);
			if (r) {
				GDKsyserror("BBPdiskscan: unlink(%s)", fullname);
			} else {
				tot += filesize;
			}
			IODEBUG THRprintf(GDKerr, "BBPcleanup: unlink(%s) = %d\n", fullname, r);
		}
		IODEBUG THRprintf(GDKerr, "BBPdiskscan: stat(%s) = %d\n", fullname, r);
	}
	closedir(dirp);
	return tot;
}

lng BBPdiskscan(void) {
	return BBPdiskscan_r(NULL);
}
@}

